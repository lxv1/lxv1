<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta http-equiv="Content-Style-Type" content="text/css">
  <title></title>
  <meta name="Generator" content="Cocoa HTML Writer">
  <meta name="CocoaVersion" content="2299">
  <style type="text/css">
    p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 23.0px Times; color: #0000e9; -webkit-text-stroke: #00000b}
    p.p2 {margin: 0.0px 0.0px 0.0px 0.0px; font: 18.0px Times; color: #000000; -webkit-text-stroke: #000000}
    p.p3 {margin: 0.0px 0.0px 0.0px 0.0px; font: 31.0px Times; color: #000000; -webkit-text-stroke: #000000}
    p.p4 {margin: 0.0px 0.0px 0.0px 0.0px; font: 18.0px Times; color: #000000; -webkit-text-stroke: #000000; min-height: 23.0px}
    p.p5 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #000000; -webkit-text-stroke: #000000}
    p.p6 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #00000b}
    p.p7 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica; color: #000000; -webkit-text-stroke: #000000}
    p.p8 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #000000}
    p.p9 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #00000b; -webkit-text-stroke: #000000}
    p.p10 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #00000b; -webkit-text-stroke: #00000b}
    p.p11 {margin: 0.0px 0.0px 0.0px 0.0px; text-align: center; font: 17.0px Times; color: #000000; -webkit-text-stroke: #000000}
    p.p12 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #00000b; min-height: 14.0px}
    p.p13 {margin: 0.0px 0.0px 0.0px 0.0px; text-align: center; font: 18.0px Times; color: #00000b; -webkit-text-stroke: #00000b}
    p.p14 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0b0b0b; -webkit-text-stroke: #0b0b0b}
    p.p15 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0b0b0b; -webkit-text-stroke: #0b0b0b; background-color: #ffffff}
    p.p16 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #00000b; -webkit-text-stroke: #0b0b0b}
    p.p17 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #0b0b0b}
    p.p18 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #00000b; -webkit-text-stroke: #00000b; min-height: 14.0px}
    p.p19 {margin: 0.0px 0.0px 0.0px 0.0px; text-align: center; font: 18.0px Times; color: #00000b; -webkit-text-stroke: #00000b; min-height: 23.0px}
    p.p20 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px 'Songti SC'; color: #0b0b0b; -webkit-text-stroke: #0b0b0b; background-color: #ffffff}
    p.p21 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px 'Songti SC'; color: #0b0b0b; -webkit-text-stroke: #0b0b0b}
    p.p22 {margin: 0.0px 0.0px 0.0px 0.0px; font: 11.0px Times; color: #0b0b0b; -webkit-text-stroke: #0b0b0b}
    p.p23 {margin: 0.0px 0.0px 0.0px 0.0px; font: 11.0px Times; color: #00000b; -webkit-text-stroke: #000000}
    p.p24 {margin: 0.0px 0.0px 0.0px 0.0px; font: 11.0px Times; color: #0000e9; -webkit-text-stroke: #00000b}
    p.p25 {margin: 0.0px 0.0px 0.0px 0.0px; font: 11.0px Times; color: #00000b; -webkit-text-stroke: #00000b}
    p.p26 {margin: 0.0px 0.0px 0.0px 0.0px; font: 11.0px Times; color: #0b0b0b; -webkit-text-stroke: #0b0b0b; background-color: #ffffff}
    p.p27 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #272727; -webkit-text-stroke: #272727}
    p.p28 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #0000e9}
    p.p29 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #17712f; -webkit-text-stroke: #17712f}
    p.p30 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #747474; -webkit-text-stroke: #747474}
    p.p31 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #244bf0; -webkit-text-stroke: #000000}
    p.p32 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #272727; -webkit-text-stroke: #272727; min-height: 14.0px}
    p.p33 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #17712f; -webkit-text-stroke: #000000}
    p.p34 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #272727; -webkit-text-stroke: #0b0b0b}
    p.p35 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #0000e9; background-color: #ffffff; min-height: 14.0px}
    p.p36 {margin: 0.0px 0.0px 0.0px 0.0px; font: 18.0px Helvetica; color: #0000e9; -webkit-text-stroke: #0000e9}
    p.p37 {margin: 0.0px 0.0px 0.0px 0.0px; font: 13.0px Helvetica; color: #17712f; -webkit-text-stroke: #000000}
    p.p38 {margin: 0.0px 0.0px 0.0px 0.0px; font: 13.0px Helvetica; color: #747474; -webkit-text-stroke: #747474}
    p.p39 {margin: 0.0px 0.0px 0.0px 0.0px; font: 13.0px Helvetica; color: #272727; -webkit-text-stroke: #272727}
    p.p40 {margin: 0.0px 0.0px 0.0px 0.0px; font: 13.0px Helvetica; color: #17712f; -webkit-text-stroke: #17712f}
    p.p41 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #0a0021; min-height: 14.0px}
    p.p42 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0b0b0b; -webkit-text-stroke: #0b0b0b; min-height: 14.0px}
    p.p43 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px 'Songti SC'; color: #000000; -webkit-text-stroke: #000000}
    p.p44 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #000000; -webkit-text-stroke: #000000; min-height: 14.0px}
    p.p45 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px 'Songti SC'; color: #0000e9; -webkit-text-stroke: #000000}
    p.p46 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px 'Songti SC'; color: #0000e9; -webkit-text-stroke: #00000b}
    p.p47 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #000000; -webkit-text-stroke: #00000b}
    p.p48 {margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Times; color: #000000; -webkit-text-stroke: #00000b}
    p.p49 {margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px 'Songti SC'; color: #0000e9; -webkit-text-stroke: #00000b}
    p.p50 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px 'Songti SC'; color: #000000; -webkit-text-stroke: #00000b}
    p.p51 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px 'Songti SC'; color: #00000b; -webkit-text-stroke: #00000b}
    p.p52 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px 'Songti SC'; color: #00000b; -webkit-text-stroke: #00000b; background-color: #ffffff}
    p.p53 {margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px 'Songti SC'; color: #0000e9; -webkit-text-stroke: #000000}
    p.p54 {margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Times; color: #000000; -webkit-text-stroke: #000000}
    p.p55 {margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Times; color: #0000e9; -webkit-text-stroke: #000000}
    p.p56 {margin: 0.0px 0.0px 0.0px 0.0px; font: 9.0px Times; color: #0000e9; -webkit-text-stroke: #000000}
    p.p57 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px 'Songti SC'; color: #17712f; -webkit-text-stroke: #17712f}
    p.p58 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #000000; color: rgba(0, 0, 0, 0.87); -webkit-text-stroke: rgba(0, 0, 0, 0.87)}
    p.p59 {margin: 0.0px 0.0px 0.0px 0.0px; text-align: center; font: 12.0px Times; color: #000000; -webkit-text-stroke: #000000}
    p.p60 {margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Times; color: #00000b; -webkit-text-stroke: #00000b}
    p.p61 {margin: 0.0px 0.0px 0.0px 0.0px; font: 17.0px Arial; color: #0000e9; -webkit-text-stroke: #00000b}
    p.p62 {margin: 0.0px 0.0px 0.0px 0.0px; font: 13.0px Arial; color: #0b0b0b; -webkit-text-stroke: #00000b}
    p.p63 {margin: 0.0px 0.0px 0.0px 0.0px; font: 13.0px Arial; color: #0000e9; -webkit-text-stroke: #00000b}
    p.p64 {margin: 0.0px 0.0px 0.0px 0.0px; font: 13.0px Arial; color: #0a000b; -webkit-text-stroke: #00000b}
    p.p65 {margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Times; color: #0000e9; -webkit-text-stroke: #00000b}
    p.p66 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0a000b; -webkit-text-stroke: #00000b}
    p.p67 {margin: 0.0px 0.0px 2.0px 0.0px; font: 12.0px Times; color: #0a000b; -webkit-text-stroke: #00000b}
    p.p68 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0b0b0b; -webkit-text-stroke: #00000b}
    p.p69 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0b0b0b; -webkit-text-stroke: #0b0b0b; background-color: #ffffff; min-height: 14.0px}
    p.p70 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #0b0b0b; background-color: #ffffff}
    p.p71 {margin: 0.0px 0.0px 0.0px 0.0px; font: 16.1px 'Helvetica Neue'; color: #0000e9; -webkit-text-stroke: #0a0a0b}
    p.p72 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px 'Helvetica Neue'; color: #0b0b0b; -webkit-text-stroke: #0b0b0b}
    p.p73 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.9px 'Helvetica Neue'; color: #0b0b0b; -webkit-text-stroke: #0b0b0b}
    p.p74 {margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px 'Helvetica Neue'; color: #0b0b0b; -webkit-text-stroke: #0b0b0b}
    p.p75 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #000000; -webkit-text-stroke: #0b0b0b}
    p.p76 {margin: 0.0px 0.0px 0.0px 0.0px; font: 13.0px Helvetica; color: #0b0b0b; -webkit-text-stroke: #0b0b0b}
    p.p77 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0b0b0b; -webkit-text-stroke: #000000}
    p.p78 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0b0b0b; -webkit-text-stroke: #000000; background-color: #ffffff}
    p.p79 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0a000e; -webkit-text-stroke: #0a000e}
    p.p80 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #000000; color: rgba(0, 0, 0, 0.87); -webkit-text-stroke: #0a000e}
    p.p81 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #0a000e}
    p.p82 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #17712f; -webkit-text-stroke: #0a000e}
    p.p83 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #747474; -webkit-text-stroke: #0a000e}
    p.p84 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #272727; -webkit-text-stroke: #0a000e}
    p.p85 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #244bf0; -webkit-text-stroke: #0a000e}
    p.p86 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #17712f; -webkit-text-stroke: #0b0b0b}
    p.p87 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #747474; -webkit-text-stroke: #0b0b0b}
    p.p88 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #000000; color: rgba(0, 0, 0, 0.87); -webkit-text-stroke: #0b0b0b}
    p.p89 {margin: 0.0px 0.0px 0.0px 0.0px; text-align: center; font: 14.0px Times; color: #00000b; -webkit-text-stroke: #00000b}
    p.p90 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0b0b0b; -webkit-text-stroke: #00000b; background-color: #ffffff}
    p.p91 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #00000b; -webkit-text-stroke: #00000b; background-color: #ffffff}
    p.p92 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #00000b; background-color: #ffffff}
    p.p93 {margin: 0.0px 0.0px 0.0px 0.0px; font: 16.1px 'Helvetica Neue'; color: #0000e9; -webkit-text-stroke: #00000b}
    p.p94 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px 'Helvetica Neue'; color: #000000; -webkit-text-stroke: #000000}
    p.p95 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.9px 'Helvetica Neue'; color: #000000; -webkit-text-stroke: #000000}
    p.p96 {margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px 'Helvetica Neue'; color: #000000; -webkit-text-stroke: #000000}
    p.p97 {margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px 'Helvetica Neue'; color: #00000b; -webkit-text-stroke: #00000b}
    p.p98 {margin: 0.0px 0.0px 0.0px 0.0px; font: 16.1px 'Helvetica Neue'; color: #0000e9; -webkit-text-stroke: #000000}
    p.p99 {margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px 'Apple SD Gothic Neo'; color: #0b0b0b; -webkit-text-stroke: #0b0b0b}
    p.p100 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px 'Songti SC'; color: #0b0b0b; -webkit-text-stroke: #000000}
    p.p101 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px AppleMyungjo; color: #0b0b0b; -webkit-text-stroke: #0b0b0b}
    p.p102 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #000000; -webkit-text-stroke: #0b0b0b; background-color: #ffffff}
    p.p103 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0b000b; -webkit-text-stroke: #0b000b}
    p.p104 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #000000; -webkit-text-stroke: #000000; background-color: #ffffff}
    p.p105 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0b000b; -webkit-text-stroke: #000000}
    p.p106 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0b0b0b; -webkit-text-stroke: #000000; background-color: #0b0b0b; min-height: 14.0px}
    p.p107 {margin: 0.0px 0.0px 3.8px 0.0px; font: 12.0px Times; color: #0b000b; -webkit-text-stroke: #000000}
    p.p108 {margin: 0.0px 0.0px 3.8px 0.0px; font: 12.0px Times; color: #0b0b0b; -webkit-text-stroke: #000000}
    p.p109 {margin: 0.0px 0.0px 3.8px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #000000}
    p.p110 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #0a000b}
    p.p111 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0b000b; -webkit-text-stroke: #0b0b0b}
    p.p112 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0b0b0b; color: rgba(11, 11, 11, 0.7); -webkit-text-stroke: rgba(11, 11, 11, 0.7)}
    p.p113 {margin: 0.0px 0.0px 0.0px 0.0px; font: 15.0px 'Helvetica Neue'; color: #0000e9; -webkit-text-stroke: #00000b; min-height: 17.0px}
    p.p114 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #00000b; background-color: #ffffff; min-height: 14.0px}
    p.p115 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0a000b; -webkit-text-stroke: #000000}
    p.p116 {margin: 0.0px 0.0px 2.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #00000b}
    p.p117 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0a000b; -webkit-text-stroke: #0a000b}
    p.p118 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0b0b0a; -webkit-text-stroke: #0b0b0a; background-color: #ffffff}
    p.p119 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #111111; -webkit-text-stroke: #111111}
    p.p120 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #0000d3}
    p.p121 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #134014; -webkit-text-stroke: #134014}
    p.p122 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #3d3d3d; -webkit-text-stroke: #3d3d3d}
    p.p123 {margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Helvetica; color: #000000; -webkit-text-stroke: #000000; min-height: 17.0px}
    p.p124 {margin: 0.0px 0.0px 0.0px 0.0px; font: 13.0px Times; color: #111111; -webkit-text-stroke: #111111; min-height: 16.0px}
    p.p125 {margin: 0.0px 0.0px 0.0px 0.0px; font: 13.0px Times; color: #111111; -webkit-text-stroke: #111111}
    p.p126 {margin: 0.0px 0.0px 0.0px 0.0px; font: 18.0px Times; color: #0000e9; -webkit-text-stroke: #0d00e1}
    p.p127 {margin: 0.0px 0.0px 0.0px 0.0px; font: 13.0px Times; color: #134014; -webkit-text-stroke: #134014}
    p.p128 {margin: 0.0px 0.0px 0.0px 0.0px; font: 13.0px Times; color: #3d3d3d; -webkit-text-stroke: #3d3d3d}
    p.p129 {margin: 0.0px 0.0px 0.0px 0.0px; font: 18.0px Times; color: #0d00e1; -webkit-text-stroke: #0d00e1}
    p.p130 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000dc; -webkit-text-stroke: #0d00e1}
    p.p131 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #0d00e1}
    p.p132 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0d00e1; -webkit-text-stroke: #0d00e1}
    p.p133 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0a003f; -webkit-text-stroke: #0a003f}
    p.p134 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #1d1d1d; -webkit-text-stroke: #0a003f}
    p.p135 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #0a003f}
    p.p136 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #176023; -webkit-text-stroke: #0a003f}
    p.p137 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #616161; -webkit-text-stroke: #0a003f}
    p.p138 {margin: 0.0px 0.0px 0.0px 0.0px; font: 13.0px Times; color: #111111; -webkit-text-stroke: #0a003f}
    p.p139 {margin: 0.0px 0.0px 0.0px 0.0px; font: 18.0px Times; color: #0d00e1; -webkit-text-stroke: #0a003f}
    p.p140 {margin: 0.0px 0.0px 0.0px 0.0px; font: 13.0px Times; color: #134014; -webkit-text-stroke: #0a003f}
    p.p141 {margin: 0.0px 0.0px 0.0px 0.0px; font: 13.0px Times; color: #3d3d3d; -webkit-text-stroke: #0a003f}
    p.p142 {margin: 0.0px 0.0px 0.0px 0.0px; text-align: center; font: 12.0px Times; color: #0b0b0b; -webkit-text-stroke: #00000b}
    p.p143 {margin: 0.0px 0.0px 0.0px 0.0px; text-align: center; font: 17.0px Times; color: #0b0b0b; -webkit-text-stroke: #00000b}
    p.p144 {margin: 0.0px 0.0px 0.0px 36.0px; text-indent: -36.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #000000; background-color: #ffffff}
    p.p145 {margin: 0.0px 0.0px 0.0px 36.0px; text-indent: -36.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #000000}
    p.p146 {margin: 0.0px 0.0px 0.0px 36.0px; text-indent: -36.0px; font: 12.0px Times; color: #0b0b0b; -webkit-text-stroke: #000000}
    p.p147 {margin: 0.0px 0.0px 0.0px 36.0px; text-indent: -36.0px; font: 12.0px Times; color: #0a000b; -webkit-text-stroke: #000000; background-color: #ffffff}
    p.p148 {margin: 0.0px 0.0px 3.8px 0.0px; font: 12.0px Times; color: #0b0b0b; -webkit-text-stroke: #0b0b0b}
    p.p149 {margin: 0.0px 0.0px 3.8px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #00000b}
    p.p150 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica; color: #0000e9; -webkit-text-stroke: #00000b}
    p.p151 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica; color: #0b0b0b; -webkit-text-stroke: #0b0b0b}
    p.p152 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Helvetica; color: #0b0b0b; -webkit-text-stroke: #0b0b0b; background-color: #ffffff}
    p.p153 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #000a0b; background-color: #ffffff}
    p.p154 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0b0b0b; -webkit-text-stroke: #000000; min-height: 14.0px}
    p.p155 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Courier; color: #000000; -webkit-text-stroke: #000000}
    p.p156 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Courier; color: #000000; -webkit-text-stroke: #00000b}
    p.p157 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Courier; color: #00000b; -webkit-text-stroke: #000000}
    p.p158 {margin: 0.0px 0.0px 0.0px 0.0px; font: 15.0px 'PT Sans'; color: #000000; -webkit-text-stroke: #000000}
    p.p159 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #00000b; -webkit-text-stroke: #0b0b0b; background-color: #ffffff}
    p.p160 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #000015; -webkit-text-stroke: #0b0b0b; background-color: #ffffff}
    p.p161 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px 'Songti SC'; color: #0000e9; -webkit-text-stroke: #00000b; background-color: #ffffff}
    p.p162 {margin: 0.0px 0.0px 0.0px 0.0px; text-align: center; font: 12.0px Times; color: #0b0b0b; -webkit-text-stroke: #0b0b0b; background-color: #ffffff; min-height: 14.0px}
    p.p163 {margin: 0.0px 0.0px 0.0px 0.0px; text-align: center; font: 12.0px Times; color: #0b0b0b; -webkit-text-stroke: #0b0b0b}
    p.p164 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0b000b; -webkit-text-stroke: #0b000b; background-color: #ffffff; min-height: 14.0px}
    p.p165 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0b000b; -webkit-text-stroke: #0b000b; min-height: 14.0px}
    p.p166 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0b000b; -webkit-text-stroke: #0b000b; background-color: #ffffff}
    p.p167 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #000000; -webkit-text-stroke: #0b0b0b; background-color: #0b0b0b; min-height: 14.0px}
    p.p168 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #000a0b; -webkit-text-stroke: #000a0b}
    p.p170 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000dc; -webkit-text-stroke: #000000}
    p.p171 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #111111; -webkit-text-stroke: #111111; min-height: 14.0px}
    p.p172 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0d00e1; -webkit-text-stroke: #000000}
    p.p173 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #111111; -webkit-text-stroke: #111111; background-color: #ffffff}
    p.p174 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0a003f; -webkit-text-stroke: #0a003f; min-height: 14.0px}
    p.p175 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px 'Songti SC'; color: #134014; -webkit-text-stroke: #134014}
    p.p176 {margin: 0.0px 0.0px 0.0px 0.0px; font: 13.0px Times; color: #161616; -webkit-text-stroke: #161616}
    p.p177 {margin: 0.0px 0.0px 0.0px 0.0px; font: 18.0px Times; color: #1300e7; -webkit-text-stroke: #000000}
    p.p178 {margin: 0.0px 0.0px 0.0px 0.0px; font: 13.0px Times; color: #0000e3; -webkit-text-stroke: #000000}
    p.p179 {margin: 0.0px 0.0px 0.0px 0.0px; font: 13.0px Times; color: #4e4e4e; -webkit-text-stroke: #4e4e4e}
    p.p180 {margin: 0.0px 0.0px 0.0px 0.0px; font: 18.0px Times; color: #0000e9; -webkit-text-stroke: #0000dc}
    p.p181 {margin: 0.0px 0.0px 0.0px 0.0px; font: 13.0px Times; color: #154f1a; -webkit-text-stroke: #154f1a}
    p.p182 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #000011}
    p.p183 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0a000b; -webkit-text-stroke: #0b0b0b}
    p.p184 {margin: 0.0px 0.0px 0.0px 0.0px; font: 16.8px 'Helvetica Neue'; color: #0000bd; -webkit-text-stroke: #0b0b0b}
    p.p185 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #00000e; background-color: #ffffff}
    p.p186 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #000054}
    p.p187 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #000067}
    p.p188 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #000067; -webkit-text-stroke: #000067}
    p.p189 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0b0012; -webkit-text-stroke: #000000}
    p.p190 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #00009f}
    p.p191 {margin: 0.0px 0.0px 0.0px 0.0px; font: 17.0px Helvetica; color: #0b0b0b; -webkit-text-stroke: #0b0b0b}
    p.p192 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #000000; color: rgba(0, 0, 0, 0.85); -webkit-text-stroke: #0b0b0b}
    p.p193 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #000000; -webkit-text-stroke: #0b0b0b; min-height: 14.0px}
    p.p194 {margin: 0.0px 0.0px 0.0px 0.0px; font: 17.0px Helvetica; color: #0000e9; -webkit-text-stroke: #0b0b0b}
    p.p195 {margin: 0.0px 0.0px 0.0px 0.0px; font: 17.0px Helvetica; color: #0b0b0b; -webkit-text-stroke: #000000}
    p.p196 {margin: 0.0px 0.0px 0.0px 0.0px; font: 17.0px Helvetica; color: #0000e9; -webkit-text-stroke: #000000}
    p.p197 {margin: 0.0px 0.0px 0.0px 0.0px; font: 17.0px Helvetica; color: #0b0b0b; -webkit-text-stroke: #000000; min-height: 20.0px}
    p.p198 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0e1e0d; -webkit-text-stroke: #0b0b0b}
    p.p199 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0a0015; -webkit-text-stroke: #0a0015}
    p.p200 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #0a0015}
    p.p201 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0e0045; -webkit-text-stroke: #0e0045}
    p.p202 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #101010; -webkit-text-stroke: #101010}
    p.p203 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #000000; color: rgba(0, 0, 0, 0.87); -webkit-text-stroke: #000000}
    p.p204 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0e0045; -webkit-text-stroke: #000000}
    p.p205 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #101010; -webkit-text-stroke: #000000}
    p.p206 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0c0c0c; -webkit-text-stroke: #0c0c0c; background-color: #ffffff}
    p.p207 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #0000c9}
    p.p208 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #113210; -webkit-text-stroke: #113210}
    p.p209 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #2e2e2e; -webkit-text-stroke: #2e2e2e}
    p.p210 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0e0e0e; -webkit-text-stroke: #0e0e0e}
    p.p211 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000d3; -webkit-text-stroke: #000000}
    p.p212 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0c0c0c; -webkit-text-stroke: #0c0c0c}
    p.p213 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0c0c0c; -webkit-text-stroke: #0c0c0c; min-height: 14.0px}
    p.p214 {margin: 0.0px 0.0px 0.0px 0.0px; font: 17.0px Times; color: #000000; -webkit-text-stroke: #000000}
    p.p215 {margin: 0.0px 0.0px 20.0px 0.0px; font: 15.0px Helvetica; color: #0b0b0b; -webkit-text-stroke: #0b0b0b}
    p.p216 {margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Arial; color: #0000e9; -webkit-text-stroke: #0b0b0b}
    p.p217 {margin: 0.0px 0.0px 0.0px 0.0px; font: 20.0px Arial; color: #0000e9; -webkit-text-stroke: #0a000b}
    p.p218 {margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Arial; color: #0b0b0b; -webkit-text-stroke: #0b0b0b}
    p.p219 {margin: 0.0px 0.0px 14.0px 0.0px; font: 14.0px Times; color: #00000b; -webkit-text-stroke: #00000b}
    p.p220 {margin: 0.0px 0.0px 14.0px 0.0px; text-align: center; font: 18.0px Times; color: #00000b; -webkit-text-stroke: #00000b}
    p.p221 {margin: 0.0px 0.0px 14.0px 0.0px; font: 14.0px Times; color: #0000e9; -webkit-text-stroke: #00000b}
    p.p222 {margin: 0.0px 0.0px 0.0px 0.0px; font: 28.0px Times; color: #0b0b0b; -webkit-text-stroke: #0b0b0b; background-color: #0b0b0b; min-height: 34.0px}
    p.p223 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0000e9; -webkit-text-stroke: #00000c; min-height: 14.0px}
    li.li47 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #000000; -webkit-text-stroke: #00000b}
    li.li169 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #000000; min-height: 14.0px}
    span.s1 {text-decoration: underline ; font-kerning: none}
    span.s2 {font-kerning: none}
    span.s3 {font: 12.0px Times; text-decoration: underline ; font-kerning: none}
    span.s4 {font-kerning: none; color: #000000}
    span.s5 {text-decoration: underline ; font-kerning: none; color: #00000b}
    span.s6 {font-kerning: none; color: #00000b}
    span.s7 {text-decoration: underline ; font-kerning: none; color: #0000e9}
    span.s8 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; color: #00000b}
    span.s9 {font: 12.0px Times; font-kerning: none}
    span.s10 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; color: #00000b; -webkit-text-stroke: 0px #00000b}
    span.s11 {font: 12.0px 'Songti SC'; font-kerning: none}
    span.s12 {font-kerning: none; color: #000000; -webkit-text-stroke: 0px #000000}
    span.s13 {text-decoration: underline ; font-kerning: none; color: #00000b; -webkit-text-stroke: 0px #00000b}
    span.s14 {font: 12.0px 'Songti SC'; font-kerning: none; color: #000000; -webkit-text-stroke: 0px #000000}
    span.s15 {font-kerning: none; color: #0b0b0b; -webkit-text-stroke: 0px #0b0b0b}
    span.s16 {text-decoration: underline ; font-kerning: none; color: #00000b; -webkit-text-stroke: 0px #000000}
    span.s17 {text-decoration: underline ; font-kerning: none; background-color: #ffffff}
    span.s18 {font-kerning: none; background-color: #ffffff}
    span.s19 {font: 12.0px 'Songti SC'; font-kerning: none; background-color: #ffffff}
    span.s20 {font-kerning: none; color: #0b0b0b}
    span.s21 {text-decoration: underline ; font-kerning: none; color: #00000b; background-color: #ffffff}
    span.s22 {text-decoration: underline ; font-kerning: none; color: #00000b; -webkit-text-stroke: 0px #0b0b0b}
    span.s23 {text-decoration: underline ; font-kerning: none; color: #0000e9; background-color: #ffffff}
    span.s24 {font: 15.0px Helvetica; font-kerning: none; color: #0b0b0b; -webkit-text-stroke: 0px #000000}
    span.s25 {text-decoration: underline ; font-kerning: none; -webkit-text-stroke: 0px #0b0b0b}
    span.s26 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; color: #0b0b0b; -webkit-text-stroke: 0px #0b0b0b}
    span.s27 {text-decoration: underline ; font-kerning: none; color: #0000e9; background-color: #ffffff; -webkit-text-stroke: 0px #00000b}
    span.s28 {font: 11.0px Times; text-decoration: underline ; font-kerning: none; color: #00000b; -webkit-text-stroke: 0px #000000}
    span.s29 {font: 11.0px 'Songti SC'; font-kerning: none; background-color: #ffffff}
    span.s30 {font-kerning: none; color: #0b0b0b; background-color: #ffffff; -webkit-text-stroke: 0px #0b0b0b}
    span.s31 {font: 11.0px 'Songti SC'; font-kerning: none; color: #0b0b0b; background-color: #ffffff; -webkit-text-stroke: 0px #0b0b0b}
    span.s32 {font: 11.0px 'Songti SC'; font-kerning: none}
    span.s33 {font: 11.0px 'Hiragino Mincho ProN'; font-kerning: none; background-color: #ffffff}
    span.s34 {font: 11.0px Times; font-kerning: none; background-color: #ffffff}
    span.s35 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; color: #00000b; -webkit-text-stroke: 0px #000000}
    span.s36 {font: 12.0px 'Songti SC'; font-kerning: none; color: #0b0b0b; background-color: #ffffff; -webkit-text-stroke: 0px #0b0b0b}
    span.s37 {font: 12.0px Times; font-kerning: none; color: #0b0b0b; -webkit-text-stroke: 0px #0b0b0b}
    span.s38 {text-decoration: underline ; font-kerning: none; color: #244bf0; -webkit-text-stroke: 0px #000000}
    span.s39 {text-decoration: underline ; font-kerning: none; color: #17712f; -webkit-text-stroke: 0px #000000}
    span.s40 {text-decoration: underline ; font-kerning: none; color: #0000e9; background-color: #ffffff; -webkit-text-stroke: 0px #0000e9}
    span.s41 {font-kerning: none; background-color: #ffffff; -webkit-text-stroke: 0px #17712f}
    span.s42 {text-decoration: underline ; font-kerning: none; -webkit-text-stroke: 0px #000000}
    span.s43 {font: 12.0px 'Songti SC'; font-kerning: none; background-color: #ffffff; -webkit-text-stroke: 0px #17712f}
    span.s44 {font-kerning: none; color: #101010; -webkit-text-stroke: 0px #101010}
    span.s45 {font-kerning: none; color: #101010; background-color: #ffffff; -webkit-text-stroke: 0px #101010}
    span.s46 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; -webkit-text-stroke: 0px #0000e9}
    span.s47 {font: 18.0px Helvetica; text-decoration: underline ; font-kerning: none; color: #244bf0; -webkit-text-stroke: 0px #000000}
    span.s48 {font: 13.0px Helvetica; text-decoration: underline ; font-kerning: none; -webkit-text-stroke: 0px #000000}
    span.s49 {font: 13.0px 'PingFang SC'; font-kerning: none; background-color: #ffffff; -webkit-text-stroke: 0px #17712f}
    span.s50 {font: 13.0px 'PingFang SC'; font-kerning: none; background-color: #ffffff}
    span.s51 {font: 13.0px Helvetica; text-decoration: underline ; font-kerning: none; color: #17712f; -webkit-text-stroke: 0px #000000}
    span.s52 {font: 13.0px Helvetica; font-kerning: none}
    span.s53 {text-decoration: underline ; font-kerning: none; -webkit-text-stroke: 0px #0a0021}
    span.s54 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; color: #0000e9; -webkit-text-stroke: 0px #00000b}
    span.s55 {font: 12.0px 'Hiragino Mincho ProN'; font-kerning: none}
    span.s56 {text-decoration: underline ; font-kerning: none; color: #0000e9; -webkit-text-stroke: 0px #00000b}
    span.s57 {font: 12.0px 'Songti SC'; text-decoration: underline ; font-kerning: none}
    span.s58 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; background-color: #ffff13}
    span.s59 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; background-color: #ffff13; -webkit-text-stroke: 0px #000000}
    span.s60 {font: 12.0px 'Songti SC'; text-decoration: underline ; font-kerning: none; -webkit-text-stroke: 0px #000000}
    span.s61 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; -webkit-text-stroke: 0px #000000}
    span.s62 {font: 12.0px Times; font-kerning: none; background-color: #ffff13}
    span.s63 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; color: #000000; background-color: #ffff13}
    span.s64 {font: 14.0px Times; text-decoration: underline ; font-kerning: none; background-color: #ffff13}
    span.s65 {font: 14.0px 'Songti SC'; text-decoration: underline ; font-kerning: none}
    span.s66 {font: 14.0px Times; text-decoration: underline ; font-kerning: none}
    span.s67 {font: 12.0px 'Songti SC'; text-decoration: underline ; font-kerning: none; color: #000000; background-color: #ffff13; -webkit-text-stroke: 0px #00000b}
    span.s68 {font: 12.0px 'Songti SC'; text-decoration: underline ; font-kerning: none; color: #00000b; -webkit-text-stroke: 0px #00000b}
    span.s69 {font: 12.0px Times; font-kerning: none; color: #000000}
    span.s70 {text-decoration: underline ; font-kerning: none; -webkit-text-stroke: 0px #00000b}
    span.s71 {font: 14.0px Times; text-decoration: underline ; font-kerning: none; color: #000000; background-color: #ffff13; -webkit-text-stroke: 0px #000000}
    span.s72 {font: 14.0px Times; text-decoration: underline ; font-kerning: none; -webkit-text-stroke: 0px #000000}
    span.s73 {font: 14.0px Times; font-kerning: none; color: #000000}
    span.s74 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; color: #000000; background-color: #ffff13; -webkit-text-stroke: 0px #000000}
    span.s75 {font: 9.0px Times; text-decoration: underline ; font-kerning: none; color: #000000; background-color: #ffff13; -webkit-text-stroke: 0px #000000}
    span.s76 {font: 9.0px Times; text-decoration: underline ; font-kerning: none; -webkit-text-stroke: 0px #000000}
    span.s77 {text-decoration: underline ; font-kerning: none; color: #000000; background-color: #ffff13}
    span.s78 {font: 12.0px AppleMyungjo; font-kerning: none; background-color: #ffffff}
    span.s79 {font: 12.0px Times; font-kerning: none; background-color: #ffffff}
    span.s80 {text-decoration: underline ; font-kerning: none; color: #0000e9; -webkit-text-stroke: 0px #0000e9}
    span.s81 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; color: #244bf0; background-color: #ffffff}
    span.s82 {font: 14.0px Times; text-decoration: underline ; font-kerning: none; color: #00000b}
    span.s83 {font: 14.0px Times; text-decoration: underline ; font-kerning: none; color: #000000; background-color: #ffff13}
    span.s84 {font: 14.0px Times; text-decoration: underline ; font-kerning: none; color: #00000b; background-color: #ffff13}
    span.s85 {font: 13.0px Arial; text-decoration: underline ; font-kerning: none}
    span.s86 {font: 17.0px Arial; text-decoration: underline ; font-kerning: none}
    span.s87 {font: 17.0px Arial; text-decoration: underline ; font-kerning: none; color: #0a000b}
    span.s88 {font: 13.0px Arial; text-decoration: underline ; font-kerning: none; color: #0b0b0b; -webkit-text-stroke: 0px #00000b}
    span.s89 {font-kerning: none; color: #0a000b}
    span.s90 {font: 1.0px Arial; font-kerning: none; color: #0b0b0b}
    span.s91 {font: 13.0px Arial; text-decoration: underline ; font-kerning: none; color: #0a000b}
    span.s92 {text-decoration: underline ; font-kerning: none; color: #0a000b; -webkit-text-stroke: 0px #00000b}
    span.s93 {font-kerning: none; color: #0b0b0b; background-color: #ffffff}
    span.s94 {text-decoration: underline ; font-kerning: none; color: #0a000b}
    span.s95 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; -webkit-text-stroke: 0px #0b0b0b}
    span.s96 {font: 16.1px 'Helvetica Neue'; text-decoration: underline ; font-kerning: none; color: #0a0a0b; -webkit-text-stroke: 0px #0a0a0b}
    span.s97 {font: 14.0px 'Helvetica Neue'; text-decoration: underline ; font-kerning: none; color: #0b0b0b; -webkit-text-stroke: 0px #0b0b0b}
    span.s98 {font-kerning: none; color: #00000b; -webkit-text-stroke: 0px #00000b}
    span.s99 {text-decoration: underline ; font-kerning: none; color: #00000b; background-color: #ffffff; -webkit-text-stroke: 0px #00000b}
    span.s100 {font-kerning: none; color: #0a000b; -webkit-text-stroke: 0px #0a000b}
    span.s101 {font: 12.0px 'Songti SC'; font-kerning: none; color: #0b0b0b; background-color: #ffffff}
    span.s102 {text-decoration: underline ; font-kerning: none; color: #244bf0; -webkit-text-stroke: 0px #0a000e}
    span.s103 {text-decoration: underline ; font-kerning: none; color: #17712f; -webkit-text-stroke: 0px #0a000e}
    span.s104 {text-decoration: underline ; font-kerning: none; color: #244bf0; -webkit-text-stroke: 0px #0b0b0b}
    span.s105 {text-decoration: underline ; font-kerning: none; color: #17712f}
    span.s106 {text-decoration: underline ; font-kerning: none; color: #0b0b0b; background-color: #ffff15; -webkit-text-stroke: 0px #00000b}
    span.s107 {text-decoration: underline ; font-kerning: none; color: #0b0b0b; -webkit-text-stroke: 0px #00000b}
    span.s108 {-webkit-text-stroke: 0px #000000}
    span.s109 {font: 16.1px 'Helvetica Neue'; text-decoration: underline ; font-kerning: none}
    span.s110 {font: 14.0px 'Helvetica Neue'; text-decoration: underline ; font-kerning: none; color: #00000b; -webkit-text-stroke: 0px #00000b}
    span.s111 {font: 16.1px 'Helvetica Neue'; text-decoration: underline ; font-kerning: none; color: #0b0b0b; -webkit-text-stroke: 0px #000000}
    span.s112 {font: 14.0px 'Helvetica Neue'; font-kerning: none}
    span.s113 {font: 12.0px 'Songti SC'; text-decoration: underline ; font-kerning: none; color: #0b0b0b; -webkit-text-stroke: 0px #000000}
    span.s114 {font: 10.0px Times; font-kerning: none}
    span.s115 {font: 12.0px Times; font-kerning: none; color: #000000; -webkit-text-stroke: 0px #000000}
    span.s116 {font: 12.0px 'Songti SC'; text-decoration: underline ; font-kerning: none; color: #0000e9; -webkit-text-stroke: 0px #00000b}
    span.s117 {font: 21.0px Arial; font-kerning: none}
    span.s118 {text-decoration: underline ; font-kerning: none; color: #00000b; background-color: #ffff15; -webkit-text-stroke: 0px #00000b}
    span.s119 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; color: #0b000b; -webkit-text-stroke: 0px #0b000b}
    span.s120 {font-kerning: none; color: #000000; background-color: #ffffff; -webkit-text-stroke: 0px #000000}
    span.s121 {text-decoration: underline ; font-kerning: none; color: #0b000b; -webkit-text-stroke: 0px #0b000b}
    span.s122 {text-decoration: underline ; font-kerning: none; color: #0b000b; background-color: #ffff15; -webkit-text-stroke: 0px #000000}
    span.s123 {text-decoration: underline ; font-kerning: none; color: #0b000b; -webkit-text-stroke: 0px #000000}
    span.s124 {font-kerning: none; color: #000000; background-color: #ffffff}
    span.s125 {text-decoration: underline ; font-kerning: none; color: #0b000b}
    span.s126 {text-decoration: underline ; font-kerning: none; background-color: #ffff15}
    span.s127 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; color: #0b000b; background-color: #ffff15; -webkit-text-stroke: 0px #000000}
    span.s128 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; color: #0b000b; -webkit-text-stroke: 0px #000000}
    span.s129 {font-kerning: none; background-color: #ffffff; -webkit-text-stroke: 0px #0b0b0b}
    span.s130 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; -webkit-text-stroke: 0px #0a000b}
    span.s131 {text-decoration: underline ; font-kerning: none; color: #0b000b; background-color: #ffff15}
    span.s132 {text-decoration: underline ; font-kerning: none; color: #0b000b; -webkit-text-stroke: 0px #0b0b0b}
    span.s133 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; color: #00000b; background-color: #ffffff; -webkit-text-stroke: 0px #00000b}
    span.s134 {font: 13.0px Helvetica; font-kerning: none; -webkit-text-stroke: 0px #0b0b0b}
    span.s135 {font-kerning: none; -webkit-text-stroke: 0px #0b0b0b}
    span.s136 {text-decoration: underline ; font-kerning: none; color: #0b0b0b; -webkit-text-stroke: 0px #000000}
    span.s137 {text-decoration: underline ; font-kerning: none; color: #0b0b0b; background-color: #ffff15; -webkit-text-stroke: 0px #000000}
    span.s138 {font-kerning: none; -webkit-text-stroke: 0px #000000}
    span.s139 {font: 12.0px 'Songti SC'; font-kerning: none; color: #0b0b0b; -webkit-text-stroke: 0px #0b0b0b}
    span.s140 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; color: rgba(11, 11, 11, 0.7); -webkit-text-stroke: 0px #000000}
    span.s141 {font: 15.0px 'Helvetica Neue'; text-decoration: underline ; font-kerning: none}
    span.s142 {text-decoration: line-through ; font-kerning: none; color: #0b0b0b; background-color: #ffffff; -webkit-text-stroke: 0px #0b0b0b}
    span.s143 {text-decoration: underline ; font-kerning: none; color: #0a000b; -webkit-text-stroke: 0px #000000}
    span.s144 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; color: #0a000b; -webkit-text-stroke: 0px #000000}
    span.s145 {text-decoration: underline ; font-kerning: none; color: #0a000b; -webkit-text-stroke: 0px #0a000b}
    span.s146 {text-decoration: underline ; font-kerning: none; color: #000011}
    span.s147 {text-decoration: underline ; font-kerning: none; color: #0d00e1; -webkit-text-stroke: 0px #000000}
    span.s148 {text-decoration: underline ; font-kerning: none; color: #134014; -webkit-text-stroke: 0px #000000}
    span.s149 {font: 18.0px Times; text-decoration: underline ; font-kerning: none; color: #0d00e1; -webkit-text-stroke: 0px #0d00e1}
    span.s150 {font: 13.0px Times; text-decoration: underline ; font-kerning: none; color: #134014; -webkit-text-stroke: 0px #134014}
    span.s151 {font: 13.0px 'Songti SC'; font-kerning: none; background-color: #ffffff}
    span.s152 {font: 18.0px Times; font-kerning: none; color: #0000d3; -webkit-text-stroke: 0px #0d00e1}
    span.s153 {font: 13.0px AppleMyungjo; font-kerning: none; background-color: #ffffff}
    span.s154 {text-decoration: underline ; font-kerning: none; color: #0d00e1; -webkit-text-stroke: 0px #0d00e1}
    span.s155 {text-decoration: underline ; font-kerning: none; color: #134014; -webkit-text-stroke: 0px #134014}
    span.s156 {text-decoration: underline ; font-kerning: none; color: #1b2dec; -webkit-text-stroke: 0px #0a003f}
    span.s157 {text-decoration: underline ; font-kerning: none; color: #176023; -webkit-text-stroke: 0px #0a003f}
    span.s158 {font: 12.0px Times; font-kerning: none; color: #0a003f}
    span.s159 {font: 18.0px Times; text-decoration: underline ; font-kerning: none; color: #0d00e1; -webkit-text-stroke: 0px #0a003f}
    span.s160 {font: 13.0px Times; text-decoration: underline ; font-kerning: none; color: #134014; -webkit-text-stroke: 0px #0a003f}
    span.s161 {text-decoration: underline ; font-kerning: none; background-color: #ffffff; -webkit-text-stroke: 0px #00000b}
    span.s162 {text-decoration: underline ; font-kerning: none; color: #000000; background-color: #0a000b; -webkit-text-stroke: 0px #000000}
    span.s163 {font: 12.0px Helvetica; text-decoration: underline ; font-kerning: none; color: #00000b; -webkit-text-stroke: 0px #000000}
    span.s164 {font: 12.0px 'PingFang SC'; font-kerning: none; color: #0b0b0b; background-color: #ffffff; -webkit-text-stroke: 0px #0b0b0b}
    span.s165 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; -webkit-text-stroke: 0px #000a0b}
    span.s166 {font: 12.0px Courier; text-decoration: underline ; font-kerning: none; color: #000000; -webkit-text-stroke: 0px #00000b}
    span.s167 {font: 12.0px Courier; text-decoration: underline ; font-kerning: none; color: #00000b}
    span.s168 {font-kerning: none; color: #00000b; -webkit-text-stroke: 0px #0a000b}
    span.s169 {text-decoration: underline ; font-kerning: none; color: #00000b; background-color: #ffffff; -webkit-text-stroke: 0px #000000}
    span.s170 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; color: #0b0b0b; background-color: #ffffff; -webkit-text-stroke: 0px #0b0b0b}
    span.s171 {font-kerning: none; background-color: #0b0b0b}
    span.s172 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; color: #0a000b; -webkit-text-stroke: 0px #0a000b}
    span.s173 {font: 15.0px 'PT Sans'; text-decoration: underline ; font-kerning: none; color: #00000b; -webkit-text-stroke: 0px #000000}
    span.s174 {text-decoration: underline ; font-kerning: none; color: #000015}
    span.s175 {font: 12.0px 'Songti SC'; font-kerning: none; color: #0b0b0b}
    span.s176 {font: 12.0px 'Songti SC'; text-decoration: underline ; font-kerning: none; color: #0b0b0b; -webkit-text-stroke: 0px #0b0b0b}
    span.s177 {font: 12.0px 'Songti SC'; text-decoration: underline ; font-kerning: none; color: #0b0b0b; background-color: #ffffff; -webkit-text-stroke: 0px #0b0b0b}
    span.s178 {text-decoration: underline ; font-kerning: none; color: #000a0b; background-color: #ffffff; -webkit-text-stroke: 0px #000a0b}
    span.s179 {text-decoration: underline ; font-kerning: none; color: #0a000b; background-color: #ffffff; -webkit-text-stroke: 0px #0a000b}
    span.s180 {text-decoration: underline ; font-kerning: none; color: #000000; background-color: #0c064c; -webkit-text-stroke: 0px #000000}
    span.s181 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; color: #0a000b; background-color: #ffffff; -webkit-text-stroke: 0px #0a000b}
    span.s182 {text-decoration: underline ; font-kerning: none; color: #000011; background-color: #0d105f}
    span.s183 {font-kerning: none; -webkit-text-stroke: 0px #0a000b}
    span.s184 {text-decoration: underline ; font-kerning: none; color: #000015; -webkit-text-stroke: 0px #000000}
    span.s185 {text-decoration: underline ; font-kerning: none; color: #0000e9; -webkit-text-stroke: 0px #000011}
    span.s186 {text-decoration: underline ; font-kerning: none; color: #00009f}
    span.s187 {font-kerning: none; color: #134014; background-color: #ffffff; -webkit-text-stroke: 0px #134014}
    span.s188 {text-decoration: underline ; font-kerning: none; color: #0000dc; -webkit-text-stroke: 0px #000000}
    span.s189 {font: 12.0px 'Songti SC'; font-kerning: none; color: #134014; background-color: #ffffff; -webkit-text-stroke: 0px #134014}
    span.s190 {font-kerning: none; color: #0d00e1; background-color: #ffffff; -webkit-text-stroke: 0px #0d00e1}
    span.s191 {font-kerning: none; color: #0a003f; -webkit-text-stroke: 0px #0a003f}
    span.s192 {text-decoration: underline ; font-kerning: none; color: #0000e9; background-color: #ffffff; -webkit-text-stroke: 0px #0000d3}
    span.s193 {text-decoration: underline ; font-kerning: none; color: #0000e9; background-color: #ffffff; -webkit-text-stroke: 0px #0000dc}
    span.s194 {text-decoration: underline ; font-kerning: none; color: #1300e7; -webkit-text-stroke: 0px #000000}
    span.s195 {font-kerning: none; color: #154f1a; background-color: #ffffff; -webkit-text-stroke: 0px #154f1a}
    span.s196 {text-decoration: underline ; font-kerning: none; color: #0000e3; -webkit-text-stroke: 0px #000000}
    span.s197 {font: 13.0px 'Songti SC'; font-kerning: none; color: #154f1a; background-color: #ffffff; -webkit-text-stroke: 0px #154f1a}
    span.s198 {font: 18.0px Times; text-decoration: underline ; font-kerning: none; color: #1300e7; -webkit-text-stroke: 0px #000000}
    span.s199 {font: 13.0px Times; text-decoration: underline ; font-kerning: none; color: #154f1a; -webkit-text-stroke: 0px #000000}
    span.s200 {text-decoration: underline ; font-kerning: none; color: #000011; -webkit-text-stroke: 0px #000011}
    span.s201 {font-kerning: none; color: #000011; -webkit-text-stroke: 0px #000011}
    span.s202 {font: 12.0px 'Songti SC'; text-decoration: underline ; font-kerning: none; color: #0000e9; background-color: #ffffff; -webkit-text-stroke: 0px #00001c}
    span.s203 {font-kerning: none; background-color: #ffffff; -webkit-text-stroke: 0px #000000}
    span.s204 {font-kerning: none; background-color: #4b4961}
    span.s205 {font: 12.0px Times; font-kerning: none; color: #0b0b0b}
    span.s206 {font: 17.5px 'Helvetica Neue'; font-kerning: none; color: #0b0b0b; background-color: #ffffff}
    span.s207 {font: 14.0px 'Helvetica Neue'; font-kerning: none; color: #0b0b0b}
    span.s208 {font: 16.8px 'Helvetica Neue'; text-decoration: underline ; font-kerning: none; color: #0000bd; background-color: #ffffff}
    span.s209 {font: 12.9px 'Helvetica Neue'; font-kerning: none; color: #0b0b0b; background-color: #ffffff}
    span.s210 {font: 12.9px 'Helvetica Neue'; font-kerning: none; color: #0b0b0b}
    span.s211 {font: 13.0px 'Helvetica Neue'; font-kerning: none; color: #0b0b0b; background-color: #ffffff}
    span.s212 {font: 12.0px 'Helvetica Neue'; text-decoration: underline ; font-kerning: none; color: #0a000b; -webkit-text-stroke: 0px #0a000b}
    span.s213 {font: 11.0px 'Helvetica Neue'; font-kerning: none; color: #ffffff; background-color: #0b0b0b; -webkit-text-stroke: 0px #ffffff}
    span.s214 {font: 14.0px 'Helvetica Neue'; font-kerning: none; color: #0b0b0b; -webkit-text-stroke: 0px #000000}
    span.s215 {font-kerning: none; color: #0000e9}
    span.s216 {text-decoration: underline ; font-kerning: none; color: #0a000b; background-color: #ffffff}
    span.s217 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; -webkit-text-stroke: 0px #00000e}
    span.s218 {text-decoration: underline ; font-kerning: none; color: #0000e9; background-color: #ffffff; -webkit-text-stroke: 0px #0a000b}
    span.s219 {font: 17.0px Times; font-kerning: none; -webkit-text-stroke: 0px #0b0b0b}
    span.s220 {font-kerning: none; background-color: #475c85; -webkit-text-stroke: 0px #0b0b0b}
    span.s221 {text-decoration: underline ; font-kerning: none; color: #0000d3; background-color: #ffffff; -webkit-text-stroke: 0px #000000}
    span.s222 {font-kerning: none; background-color: #475c85}
    span.s223 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; color: #0b0b0b; background-color: #ffffff}
    span.s224 {font-kerning: none; background-color: #878787; -webkit-text-stroke: 0px #0b0b0b}
    span.s225 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; color: #0b0b0b; -webkit-text-stroke: 0px #000000}
    span.s226 {font-kerning: none; background-color: #4e8f79}
    span.s227 {text-decoration: underline ; font-kerning: none; background-color: #4e8f79}
    span.s228 {font-kerning: none; color: #0a000e; background-color: #4e8f79; -webkit-text-stroke: 0px #0a000e}
    span.s229 {text-decoration: underline ; font-kerning: none; color: #000067; -webkit-text-stroke: 0px #000067}
    span.s230 {text-decoration: underline ; font-kerning: none; color: #0000e9; background-color: #ffffff; -webkit-text-stroke: 0px #000067}
    span.s231 {text-decoration: underline ; font-kerning: none; color: #0b0012; background-color: #ffff15; -webkit-text-stroke: 0px #000000}
    span.s232 {text-decoration: underline ; font-kerning: none; color: #0b0012; -webkit-text-stroke: 0px #000000}
    span.s233 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; color: #0a0015; -webkit-text-stroke: 0px #0a0015}
    span.s234 {font-kerning: none; color: #0a0015; -webkit-text-stroke: 0px #0a0015}
    span.s235 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; -webkit-text-stroke: 0px #00009f}
    span.s236 {font-kerning: none; background-color: #747474}
    span.s237 {font-kerning: none; color: #101010; background-color: #bbbbbb}
    span.s238 {text-decoration: underline ; font-kerning: none; background-color: #bbbbbb}
    span.s239 {font-kerning: none; background-color: #bbbbbb}
    span.s240 {font: 17.0px Helvetica; text-decoration: underline ; font-kerning: none; -webkit-text-stroke: 0px #000000}
    span.s241 {font: 17.0px Helvetica; text-decoration: underline ; font-kerning: none; color: #0b0b0b}
    span.s242 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; color: #0000c5; background-color: #ffffff; -webkit-text-stroke: 0px #0b0b0b}
    span.s243 {text-decoration: underline ; font-kerning: none; color: #0e1e0d}
    span.s244 {font: 12.0px Times; text-decoration: underline ; font-kerning: none; -webkit-text-stroke: 0px #0a0015}
    span.s245 {font-kerning: none; color: #0a0015}
    span.s246 {text-decoration: underline ; font-kerning: none; color: #0000e9; -webkit-text-stroke: 0px #00008d}
    span.s247 {text-decoration: underline ; font-kerning: none; color: #0e0045; background-color: #ffffff; -webkit-text-stroke: 0px #0e0045}
    span.s248 {text-decoration: underline ; font-kerning: none; color: #0e0045; background-color: #ffff19; -webkit-text-stroke: 0px #0e0045}
    span.s249 {text-decoration: underline ; font-kerning: none; color: #0e0045; -webkit-text-stroke: 0px #0e0045}
    span.s250 {text-decoration: underline ; font-kerning: none; color: #0e0045; background-color: #ffff19; -webkit-text-stroke: 0px #000000}
    span.s251 {text-decoration: underline ; font-kerning: none; color: #0e0045; -webkit-text-stroke: 0px #000000}
    span.s252 {font-kerning: none; color: #101010; background-color: #ffffff}
    span.s253 {text-decoration: underline ; font-kerning: none; color: #0e0045}
    span.s254 {text-decoration: underline ; font-kerning: none; color: #0900d9; -webkit-text-stroke: 0px #000000}
    span.s255 {font-kerning: none; color: #113210; background-color: #ffffff; -webkit-text-stroke: 0px #113210}
    span.s256 {text-decoration: underline ; font-kerning: none; color: #0000d3; -webkit-text-stroke: 0px #000000}
    span.s257 {font: 12.0px 'Songti SC'; font-kerning: none; color: #113210; background-color: #ffffff; -webkit-text-stroke: 0px #113210}
    span.s258 {text-decoration: underline ; font-kerning: none; -webkit-text-stroke: 0px #0000c9}
    span.s259 {text-decoration: underline ; font-kerning: none; color: #113210; -webkit-text-stroke: 0px #000000}
    span.s260 {text-decoration: underline ; font-kerning: none; color: #00000b; background-color: #ffff15; -webkit-text-stroke: 0px #000000}
    span.s261 {font: 7.0px Times; font-kerning: none; color: #000000; -webkit-text-stroke: 0px #000000}
    span.s262 {font: 14.0px Arial; text-decoration: underline ; font-kerning: none; color: #0b0b0b; -webkit-text-stroke: 0px #0b0b0b}
    span.s263 {font: 20.0px Arial; text-decoration: underline ; font-kerning: none; -webkit-text-stroke: 0px #0a000b}
    span.s264 {font: 14.0px Arial; font-kerning: none; color: #0b0b0b; -webkit-text-stroke: 0px #0b0b0b}
    span.s265 {font: 14.0px Times; text-decoration: underline ; font-kerning: none; color: #00000b; -webkit-text-stroke: 0px #00000b}
    span.s266 {font: 17.0px Times; text-decoration: underline ; font-kerning: none; color: #00000b}
    span.s267 {font: 13.0px 'Helvetica Neue'; text-decoration: underline ; font-kerning: none; background-color: #ffffff}
    span.s268 {font: 13.0px 'Helvetica Neue'; font-kerning: none}
    span.s269 {font: 13.0px 'PingFang SC'; font-kerning: none; color: #154f1a; background-color: #ffffff; -webkit-text-stroke: 0px #000000}
    span.s270 {text-decoration: underline ; font-kerning: none; -webkit-text-stroke: 0px #00000c}
    span.Apple-tab-span {white-space:pre}
    table.t1 {width: 784.0px}
    table.t2 {border-style: solid; border-width: 1.0px 1.0px 1.0px 1.0px; border-color: #0b0b0b #0b0b0b #0b0b0b #0b0b0b}
    td.td1 {width: 774.0px; padding: 5.0px 5.0px 5.0px 5.0px}
    td.td2 {width: 87.0px; border-style: solid; border-width: 1.0px 1.0px 1.0px 1.0px; border-color: #0b0b0b #0b0b0b #0b0b0b #0b0b0b; padding: 3.0px 3.0px 3.0px 3.0px}
    td.td3 {width: 63.0px; border-style: solid; border-width: 1.0px 1.0px 1.0px 1.0px; border-color: #0b0b0b #0b0b0b #0b0b0b #0b0b0b; padding: 3.0px 3.0px 3.0px 3.0px}
    td.td4 {width: 67.0px; border-style: solid; border-width: 1.0px 1.0px 1.0px 1.0px; border-color: #0b0b0b #0b0b0b #0b0b0b #0b0b0b; padding: 3.0px 3.0px 3.0px 3.0px}
    td.td5 {width: 39.0px; border-style: solid; border-width: 1.0px 1.0px 1.0px 1.0px; border-color: #0b0b0b #0b0b0b #0b0b0b #0b0b0b; padding: 3.0px 3.0px 3.0px 3.0px}
    td.td6 {width: 56.0px; border-style: solid; border-width: 1.0px 1.0px 1.0px 1.0px; border-color: #0b0b0b #0b0b0b #0b0b0b #0b0b0b; padding: 3.0px 3.0px 3.0px 3.0px}
    td.td7 {width: 48.0px; border-style: solid; border-width: 1.0px 1.0px 1.0px 1.0px; border-color: #0b0b0b #0b0b0b #0b0b0b #0b0b0b; padding: 3.0px 3.0px 3.0px 3.0px}
    td.td8 {width: 92.0px; border-style: solid; border-width: 1.0px 1.0px 1.0px 1.0px; border-color: #0b0b0b #0b0b0b #0b0b0b #0b0b0b; padding: 3.0px 3.0px 3.0px 3.0px}
    td.td9 {width: 62.7px; border-style: solid; border-width: 1.0px 1.0px 1.0px 1.0px; border-color: #0b0b0b #0b0b0b #0b0b0b #0b0b0b; padding: 3.0px 3.0px 3.0px 3.0px}
    ul.ul1 {list-style-type: none}
  </style>
</head>
<body>
<p class="p1"><span class="s1"><a href="https://patents.google.com/"><b>google<span class="Apple-converted-space">  </span>patents</b></a></span></p>
<p class="p2"><span class="s2"><b>google advanced patents</b></span></p>
<p class="p2"><span class="s2">updated June 30, 2023<br>
</span></p>
<p class="p3"><span class="s2"><span class="Apple-converted-space"> </span>456<span class="Apple-converted-space">  </span>patents with my name in title</span></p>
<p class="p4"><span class="s2"><span class="Apple-converted-space">  </span></span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2008-2013 1</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/US20160364469A1/en">US20160364469A1 - System and method for ... - Google Patents<span class="s3"></span></a></span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/US20160364469A1/en">patents.google.com › patent<span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">which claims benefit of priority from U.S. Provisional Patent Application Ser. No. ... [17] S. E. Fienberg, M. M. Meyer, and S. Wasserman. ... US8379967B1 2008-12-04 2013-02-19 Lockheed Martin Corporation Swarm control systems and methods ... Accelerated discrete distribution clustering under wasserstein distance.</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p7"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2008-2013 2</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/US9984147B2/en">US9984147B2 - System and method for ... - Google Patents<span class="s3"></span></a></span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/US9984147B2/en">patents.google.com › patent<span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">which claims benefit of priority from U.S. Provisional Patent Application Ser. No. ... [17] S. E. Fienberg, M. M. Meyer, and S. Wasserman. ... US8379967B1 2008-12-04 2013-02-19 Lockheed Martin Corporation Swarm control systems and methods ... Accelerated discrete distribution clustering under <i>wasserstein</i> distance.</span></p>
<p class="p5"><span class="s2">2017? see 2 above</span></p>
<p class="p8"><span class="s1"><a href="https://encrypted.google.com/patents/US20170083608">Patent US20170083608 - Accelerated discrete distribution<span class="Apple-converted-space">  </span></a></span><span class="s4">clustering under wasserstein distance <a href="https://encrypted.google.com/patents/US20170083608"><span class="s5">- Google</span></a></span><span class="s6"> patents</span></p>
<p class="p5"><span class="s2">Accelerated discrete distribution clustering under wasserstein distance. US 20170083608 A1. Abstract. Computationally efficient accelerated D2-clustering algorithms are disclosed for clustering discrete distributions under the Wasserstein distance with improved scalability. Three first-order methods include subgradient ...</span></p>
<p class="p9"><span class="s4">Inventor <a href="https://patents.google.com/?inventor=Jianbo+Ye"><span class="s5">Jianbo Ye</span></a><span class="Apple-converted-space">  </span><a href="https://patents.google.com/?inventor=Jia+Li"><span class="s5">Jia Li</span></a><span class="Apple-converted-space">  </span><a href="https://patents.google.com/?inventor=James+Z.+Wang"><span class="s5">James Z. Wang</span></a></span></p>
<p class="p5"><span class="s2">2018-07-03<span class="Apple-converted-space">  </span>Application granted</span></p>
<p class="p5"><span class="s2"><b>Abstract<span class="Apple-converted-space">  </span></b>Computationally efficient accelerated D2-clustering algorithms are disclosed for clustering discrete distributions under the Wasserstein distance with improved scalability. Three first-order methods include subgradient descent method with re-parametrization, alternating direction method of multipliers (ADMM), and a modified version of Bregman ADMM. The effects of the hyper-parameters on robustness, convergence, and speed of optimization are thoroughly examined. A parallel algorithm for the modified Bregman ADMM method is tested in a multi-core environment with adequate scaling efficiency subject to hundreds of CPUs, demonstrating the effectiveness of AD2-clustering.</span></p>
<p class="p9"><span class="s4"><span class="Apple-converted-space">   </span><a href="https://patents.google.com/patent/US10013477B2/en"><span class="s5"><b>Accelerated discrete distribution clustering under wasserstein distance</b></span></a></span></p>
<p class="p5"><span class="s7"><a href="https://scholar.google.com/citations?user=2iStecQAAAAJ&amp;hl=en&amp;oi=sra">J Ye</a></span><span class="s2">, <a href="https://scholar.google.com/citations?user=4Nmf18IAAAAJ&amp;hl=en&amp;oi=sra"><span class="s8">J Li</span></a>, <a href="https://scholar.google.com/citations?user=inVzWAcAAAAJ&amp;hl=en&amp;oi=sra"><span class="s8">JZ Wang</span></a> - US Patent 10,013,477, 2018 - Google Patents</span></p>
<p class="p5"><span class="s2">Computationally efficient accelerated D2-clustering algorithms are disclosed for clustering discrete distributions under the Wasserstein distance with improved scalability. Three first-order methods include subgradient descent method with re-parametrization, alternating direction method of multipliers (ADMM), and a modified version of Bregman ADMM. The effects of the hyper-parameters on robustness, convergence, and speed of optimization are thoroughly examined. A parallel algorithm for the modified Bregman ADMM method is tested …</span></p>
<p class="p9"><span class="s7"><a href="https://scholar.google.com/scholar?cites=220912351068891375&amp;as_sdt=5,39&amp;sciodt=0,39&amp;hl=en">Cited by 4</a></span><span class="s4"> <a href="https://scholar.google.com/scholar?q=related:7yj145zWEAMJ:scholar.google.com/&amp;scioq=Accelerated+Discrete+Distribution+Clustering+under+Wasserstein+Distance&amp;hl=en&amp;as_sdt=0,39"><span class="s5">Related articles</span></a><span class="Apple-converted-space"> </span></span></p>
<p class="p10"><span class="s2"><br>
&lt;—2 patents in 2008 <span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space"> </span>end 2008</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p11"><span class="s9">s</span><span class="s2">tart 2016</span></p>
<p class="p11"><span class="s2">2 patents</span><span class="s9"><br>
</span></p>
<p class="p5"><span class="s2">2016-18 1</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/US10013477B2/en?q=wasserstein"><b>Accelerated discrete distribution clustering under wasserstein distance<span class="Apple-converted-space"> </span></b><span class="s3"><b></b></span></a></span></p>
<p class="p5"><span class="s2"><b>US </b><a href="https://patentimages.storage.googleapis.com/fd/db/86/c273ed82c9148b/US10013477.pdf"><span class="s10"><b>US10013477B2</b></span></a><b> Jianbo Ye The Penn State Research Fondation<span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2"><b>Priority 2012-11-19 • Filed 2016-09-30 • Granted 2018-07-03 • Published 2018-07-03</b></span></p>
<p class="p5"><span class="s2">Computationally efficient accelerated D2-clustering algorithms are disclosed for clustering discrete distributions under the <b>Wasserstein</b> distance with improved scalability. Three first-order methods include subgradient descent method with re-parametrization, alternating direction method of … \<br>
<b>US-2017083608-A1</b></span></p>
<p class="p12"><span class="s1"><a href="https://patents.google.com/xhr/query?url=q%3Dwasserstein&amp;exp=&amp;download=true"><span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">2016-2019 2</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/CN110097512A/en?q=wasserstein"><b>… denoising model of confrontation network are generated based on Wasserstein<span class="Apple-converted-space"> </span></b><span class="s3"><b></b></span></a></span></p>
<p class="p5"><span class="s2"><b>CN </b><a href="https://patentimages.storage.googleapis.com/1e/83/8d/114112ea3396b9/CN110097512A.pdf"><span class="s10"><b>CN110097512A</b></span></a><b> </b></span><span class="s11"><b>张意</b></span><span class="s2"><b> </b></span><span class="s11"><b>四川大学</b></span><span class="s2"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2"><b>Priority 2019-04-16 • Filed 2019-04-16 • Published 2019-08-06</b></span></p>
<p class="p5"><span class="s2">4. the building of the three-dimensional MRI image denoising model of confrontation network is generated based on <b>Wasserstein</b> according to claim 3 Method, it is characterised in that the noise data of input coding device is successively handled by Three dimensional convolution, at normalization in …<span class="Apple-converted-space"> </span></span></p>
<p class="p10"><span class="s2"><br>
</span></p>
<p class="p10"><span class="s2">&lt;— 2 in 2016</span></p>
<p class="p10"><span class="s2">+ 4 till 2016</span></p>
<p class="p10"><span class="s2">= 6</span></p>
<p class="p10"><span class="s2">end 2016</span></p>
<p class="p13"><span class="s2">start 2017 <span class="Apple-converted-space"> </span></span></p>
<p class="p13"><span class="s2">12<span class="Apple-converted-space">  </span>patents</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2017 2018 1<br>
Deformable convolution kernel method based on WGAN (Wasserstein-Generative Adversarial Network) model</span></p>
<p class="p5"><span class="s2">by XU JING; LI LIPING; LI LIJUN; More... 04/2018</span></p>
<p class="p5"><span class="s2">The invention discloses a deformable convolution kernel method based on a WGAN (Wasserstein-Generative Adversarial Network) model, and belongs to the field of...</span></p>
<p class="p5"><span class="s2">Patent: <span class="Apple-converted-space"> </span></span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/CN107886162A/en?q=Deformable&amp;q=convolution+kernel&amp;q=method&amp;q=based&amp;q=WGAN&amp;q=(Wasserstein-Generative+Adversarial+Network)&amp;q=model&amp;oq=Deformable+convolution+kernel+method+based+on+WGAN+(Wasserstein-Generative+Adversarial+Network)+model">Defrmable convolution kernel method based on WGAN (Wasserstein-Generative<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p10"><span class="s12">CN <a href="https://patentimages.storage.googleapis.com/61/62/4a/9f7d37745b5a5d/CN107886162A.pdf"><span class="s13">Application CN107886162A</span></a> </span><span class="s14">周智恒</span><span class="s12"> </span><span class="s14">华南理工大学</span></p>
<p class="p5"><span class="s2">Priority 2017-11-14 • Filing 2017-11-14 • Publication 2018-04-06</span></p>
<p class="p5"><span class="s2">The invention discloses a deformable convolution kernel method based on a WGAN (Wasserstein-Generative Adversarial Network) model, and belongs to the field of the deep learning neural network. The method comprises the following steps that: S1: constructing an original genera</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/CN107886162A/en?q=Deformable+convolution+kernel+method+based&amp;oq=Deformable+convolution+kernel+method+based"><b>A kind of deformable convolution kernel method based on WGAN models<span class="Apple-converted-space"> </span></b><span class="s3"><b></b></span></a></span></p>
<p class="p5"><span class="s2"><b>CN </b><a href="https://patentimages.storage.googleapis.com/61/62/4a/9f7d37745b5a5d/CN107886162A.pdf"><span class="s10"><b>CN107886162A</b></span></a><b> </b></span><span class="s11"><b>周智恒</b></span><span class="s2"><b> </b></span><span class="s11"><b>华南理工大学</b></span><span class="s2"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2"><b>Priority 2017-11-14 • Filed 2017-11-14 • Published 2018-04-06</b></span></p>
<p class="p5"><span class="s2">3. a kind of <b>deformable convolution kernel method based</b> on WGAN models according to claim 1, it is characterised in that described Step S5 detailed processes are as follows</span><span class="s11">：</span><span class="s2"> S51, the characteristics of image figure that will be obtained after deformable convolution, input in arbiter and are …<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">2017 2</span></p>
<p class="p6"><span class="s1"><a href="https://www.research.psu.edu/otm/foundation">The Penn State Research Foundation Submits United States Patent Application for Accelerated Discrete Distribution Clustering Under Wasserstein Distance<span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Global IP News. Software Patent News, Mar 23, 2017</span></p>
<p class="p5"><span class="s2">Newspaper Article: Citation Online</span></p>
<p class="p6"><span class="s1"><a href="http://jianbo.ws/ad2-slides.pdf">Accelerated Discrete Distribution Clustering under Wasserstein Distance</a></span><span class="s6"><span class="Apple-converted-space">  </span></span><span class="s12">slides</span></p>
<p class="p5"><span class="s2">O We have developed and compared three rst-order methods for optimizing the Wasserstein centroids in. D -clustering. We refer to the modi ed Bregman ADMM as the main algorithm. O The new methods, collectively called AD -clustering, improve scalability signi cantly. We have also developed a parallel algorithm for the ...</span></p>
<p class="p6"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwfV1LT8JAEJ4oPm-KGsVH1kujB4TS0pYENLIFvViIIXIky3aJChbSYkz89c5OixgTvc4mm-x0Xrv9Zj4Aq3JVLv6KCaYbOpgZhG3LkfJcN7SrlqpJaQt9A0mx5D_gUK-L1hgaG_pBsxLRwSS6_5zC92z5puUT1DIpDV9QNL1p9xq-kV2WTQ9N1DH8ZqPV7fgdbnDe4IERPGqqVc9zTKdyuwprWNJ72jlaT03dpDLTGcbNAmd7B9a7uFs034WVz-c8bPEFEVseNh-y_9952CDApkxQmDllsgexr6jyHE4U0yDyzJjYWMWRmrCUI5rpdBUyFPfvbgN2UX8T8fi6L6jbUjNe1kskKaZzqHUQZETWnAhtoixI4eKXjKhz9uG83erx-yIeY_CtswEPlie2DiAXTSN1CKwiLCGkxBLDkbaJX0O6KqxVw7I7FFj5jI6g8Pc-hf8Wj2Fb658wLs4J5ObxuzqlwYxnpOgvpHmfyQ">Deformable convolution kernel method based on WGAN (Wasserstein-Generative Adversarial...<span class="s3"></span></a></span></p>
<p class="p14"><span class="s2">by </span><span class="s1">XU JING</span><span class="s2">; </span><span class="s1">LI LIPING</span><span class="s2">; </span><span class="s1">LI LIJUN</span><span class="s2"> ; </span><span class="s1">More...</span></p>
<p class="p14"><span class="s2">04/2018</span></p>
<p class="p14"><span class="s2">The invention discloses a deformable convolution kernel method based on a WGAN (Wasserstein-Generative Adversarial Network) model, and belongs to the field of...</span></p>
<p class="p9"><span class="s15">Patent<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwfV1LT8JAEJ4oPm-KGsVH1kujB4TS0pYENLIFvViIIXIky3aJChbSYkz89c5OixgTvc4mm-x0Xrv9Zj4Aq3JVLv6KCaYbOpgZhG3LkfJcN7SrlqpJaQt9A0mx5D_gUK-L1hgaG_pBsxLRwSS6_5zC92z5puUT1DIpDV9QNL1p9xq-kV2WTQ9N1DH8ZqPV7fgdbnDe4IERPGqqVc9zTKdyuwprWNJ72jlaT03dpDLTGcbNAmd7B9a7uFs034WVz-c8bPEFEVseNh-y_9952CDApkxQmDllsgexr6jyHE4U0yDyzJjYWMWRmrCUI5rpdBUyFPfvbgN2UX8T8fi6L6jbUjNe1kskKaZzqHUQZETWnAhtoixI4eKXjKhz9uG83erx-yIeY_CtswEPlie2DiAXTSN1CKwiLCGkxBLDkbaJX0O6KqxVw7I7FFj5jI6g8Pc-hf8Wj2Fb658wLs4J5ObxuzqlwYxnpOgvpHmfyQ"><span class="s16">Available Online</span></a></span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2017 3</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN107886162A/en?q=wgan&amp;oq=wgan">A kind of deformable convolution kernel method based on <span class="s1"><b>WGAN</b> models</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/61/62/4a/9f7d37745b5a5d/CN107886162A.pdf"><span class="s5">CN107886162A</span></a> </span><span class="s19">周智恒</span><span class="s18"> </span><span class="s19">华南理工大学</span></p>
<p class="p14"><span class="s18">Priority 2017-11-14 • Filed 2017-11-14 • Published 2018-04-06</span></p>
<p class="p14"><span class="s18">A kind of 1. deformable convolution kernel method based on <b>WGAN</b> models, it is characterised in that described deformable convolution kernel method bag Include the following steps</span><span class="s19">：</span><span class="s18"> S1, construction are originally generated confrontation network model, and generating image by maker inputs to arbiter …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2017 4</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/?q=wgan&amp;oq=wgan#">A kind of empty convolution method based on <span class="s1"><b>WGAN</b> models</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/c7/99/30/94f9af01e3c9ce/CN108021978A.pdf"><span class="s5">CN108021978A</span></a> </span><span class="s19">周智恒</span><span class="s18"> </span><span class="s19">华南理工大学</span></p>
<p class="p14"><span class="s18">Priority 2017-11-14 • Filed 2017-11-14 • Published 2018-05-11</span></p>
<p class="p14"><span class="s18">1. a kind of empty convolution method based on <b>WGAN</b> models, it is characterised in that the empty convolution method includes following step Suddenly</span><span class="s19">：</span><span class="s18"> S1, construction are originally generated confrontation network model, and generating image by maker inputs to arbiter progress network training</span><span class="s19">；</span><span class="s18"> S2 …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2017-2018 5</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/?q=wgan&amp;oq=wgan#">A kind of pedestrian detection method based on <span class="s1"><b>WGAN</b> models</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/b9/f5/85/ad813aeed0a261/CN108009568A.pdf"><span class="s5">CN108009568A</span></a> </span><span class="s19">周智恒</span><span class="s18"> </span><span class="s19">华南理工大学</span></p>
<p class="p14"><span class="s18">Priority 2017-11-14 • Filed 2017-11-14 • Published 2018-05-08</span></p>
<p class="p14"><span class="s18">1. a kind of pedestrian detection method based on <b>WGAN</b> models, it is characterised in that the pedestrian detection method includes following step Suddenly</span><span class="s19">：</span><span class="s18"> S1, construction are originally generated confrontation network model, and generating image by maker inputs to arbiter progress network …</span></p>
<p class="p10"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2017-2018 6</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN107590531A/en?q=wgan&amp;oq=wgan">A kind of <span class="s1"><b>WGAN</b> methods based on text generation</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/4b/52/ad/703a56bed82d2e/CN107590531A.pdf"><span class="s5">CN107590531A</span></a> </span><span class="s19">周智恒</span><span class="s18"> </span><span class="s19">华南理工大学</span></p>
<p class="p14"><span class="s18">Priority 2017-08-14 • Filed 2017-08-14 • Published 2018-01-16</span></p>
<p class="p15"><span class="s2">A kind of 3. <b>WGAN</b> methods based on text generation according to claim 1, it is characterised in that described text data Collection is to belong to same type of content. A kind of 4. <b>WGAN</b> methods based on text generation according to claim 1, it is characterised in that described step S4 tools Body …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p16"><span class="s20"><span class="Apple-converted-space"> </span>2017 7<br>
<a href="https://patents.google.com/patent/CN107563510A/en?q=wgan&amp;before=priority:20171231&amp;after=priority:20170101&amp;oq=2017+wgan"><span class="s21">A kind of <b>WGAN</b> model methods based on depth convolutional neural networks</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/c2/2a/43/a1443c9b2b3214/CN107563510A.pdf"><span class="s5">CN107563510A </span></a></span><span class="s19">周智恒</span><span class="s18"> </span><span class="s19">华南理工大学</span></p>
<p class="p14"><span class="s18">Priority 2017-08-14 • Filed 2017-08-14 • Published 2018-01-09</span></p>
<p class="p14"><span class="s18">A kind of 3. <b>WGAN</b> model methods based on depth convolutional neural networks according to claim 1, it is characterised in that institute The transposition depth convolutional network number of plies of maker and the depth convolutional neural networks number of plies of arbiter are identical in the …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2017 8</span></p>
<p class="p17"><span class="s17"><a href="https://patents.google.com/patent/CN107590532A/en?q=wgan&amp;before=priority:20171231&amp;after=priority:20170101&amp;oq=2017+wgan">A kind of hyper parameter dynamic adjusting method based on <span class="s22"><b>WGAN</b></span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/e1/0b/92/e9056dd44fa311/CN107590532A.pdf"><span class="s5">CN107590532A </span></a></span><span class="s19">周智恒</span><span class="s18"> </span><span class="s19">华南理工大学</span></p>
<p class="p14"><span class="s18">Priority 2017-08-14 • Filed 2017-08-14 • Published 2018-01-16</span></p>
<p class="p14"><span class="s18">A kind of 3. hyper parameter dynamic adjusting method based on <b>WGAN</b> according to claim 1, it is characterised in that described step Rapid S2 is specific as follows</span><span class="s19">：</span><span class="s18"> Get out image data set, random initializtion maker, arbiter convolutional neural networks in all parameter and weight, Hyper …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2017 9</span></p>
<p class="p16"><span class="s23"><a href="https://patents.google.com/patent/CN107590531A/en?q=wgan&amp;before=priority:20171231&amp;after=priority:20170101&amp;oq=2017+wgan">A kind of <span class="s5"><b>WGAN</b> methods based on text generation</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/4b/52/ad/703a56bed82d2e/CN107590531A.pdf"><span class="s5">CN107590531A </span></a></span><span class="s19">周智恒</span><span class="s18"> </span><span class="s19">华南理工大学</span></p>
<p class="p14"><span class="s18">Priority 2017-08-14 • Filed 2017-08-14 • Published 2018-01-16</span></p>
<p class="p14"><span class="s18">A kind of 3. <b>WGAN</b> methods based on text generation according to claim 1, it is characterised in that described text data Collection is to belong to same type of content. A kind of 4. <b>WGAN</b> methods based on text generation according to claim 1, it is characterised in that described step S4 tools Body …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2017 10</span></p>
<p class="p17"><span class="s17"><a href="https://patents.google.com/patent/CN107943750A/en?q=wgan&amp;before=priority:20171231&amp;after=priority:20170101&amp;oq=2017+wgan">A kind of decomposition convolution method based on <span class="s22"><b>WGAN</b> models</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/8d/cb/17/ed1b4736f009fb/CN107943750A.pdf"><span class="s5">CN107943750A </span></a></span><span class="s19">周智恒</span><span class="s18"> </span><span class="s19">华南理工大学</span></p>
<p class="p14"><span class="s18">Priority 2017-11-14 • Filed 2017-11-14 • Published 2018-04-20</span></p>
<p class="p14"><span class="s18">1. a kind of decomposition convolution method based on <b>WGAN</b> models, it is characterised in that the decomposition convolution method includes following step Suddenly</span><span class="s19">：</span><span class="s18"> S1, construction are originally generated confrontation network model, and generating image by maker inputs to arbiter progress …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2017 11</span></p>
<p class="p17"><span class="s17"><a href="https://patents.google.com/patent/CN108021978A/en?q=wgan&amp;before=priority:20171231&amp;after=priority:20170101&amp;oq=2017+wgan">A kind of empty convolution method based on <span class="s22"><b>WGAN</b> models</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/c7/99/30/94f9af01e3c9ce/CN108021978A.pdf"><span class="s5">CN108021978A </span></a></span><span class="s19">周智恒</span><span class="s18"> </span><span class="s19">华南理工大学</span></p>
<p class="p14"><span class="s18">Priority 2017-11-14 • Filed 2017-11-14 • Published 2018-05-11</span></p>
<p class="p14"><span class="s18">1. a kind of empty convolution method based on <b>WGAN</b> models, it is characterised in that the empty convolution method includes following step Suddenly</span><span class="s19">：</span><span class="s18"> S1, construction are originally generated confrontation network model, and generating image by maker inputs to arbiter progress network training</span><span class="s19">；</span><span class="s18"> …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2017 12</span></p>
<p class="p17"><span class="s17"><a href="https://patents.google.com/patent/CN108009568A/en?q=wgan&amp;before=priority:20171231&amp;after=priority:20170101&amp;oq=2017+wgan">A kind of pedestrian detection method based on <span class="s22"><b>WGAN</b> model</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/b9/f5/85/ad813aeed0a261/CN108009568A.pdf"><span class="s5">CN108009568A </span></a></span><span class="s19">周智恒</span><span class="s18"> </span><span class="s19">华南理工大学</span></p>
<p class="p14"><span class="s18">Priority 2017-11-14 • Filed 2017-11-14 • Published 2018-05-08</span></p>
<p class="p14"><span class="s18">1. a kind of pedestrian detection method based on <b>WGAN</b> models, it is characterised in that the pedestrian detection method includes following step Suddenly</span><span class="s19">：</span><span class="s18"> S1, construction are originally generated confrontation network model, and generating image by maker inputs to arbiter progress network …</span></p>
<p class="p18"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p10"><span class="s2">&lt;— 4 till 2016</span></p>
<p class="p10"><span class="s2">+ 12 in 2017</span></p>
<p class="p10"><span class="s2">= 16 till 2017<span class="Apple-converted-space"> </span></span></p>
<p class="p10"><span class="s2">end 2017 e17</span></p>
<p class="p10"><span class="s2"><br>
</span></p>
<p class="p19"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p13"><span class="s2">start 2018</span></p>
<p class="p13"><span class="s2">28 <span class="Apple-converted-space">  </span>patents</span></p>
<p class="p10"><span class="s2"><br>
</span></p>
<p class="p10"><span class="s2"><br>
2018 1</span></p>
<p class="p8"><span class="s1"><a href="https://patents.google.com/patent/CN109660206B/en?oq=Wasserstein+GAN-based+photovoltaic+array+fault+diagnosis+method++CN-109660206-B">Wasserstein GAN-based photovoltaic array fault diagnosis method</a></span><span class="s4"><span class="Apple-converted-space">  </span>CN-109660206-B</span></p>
<p class="p5"><span class="s2"><br>
2018</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/CN109086437A/en?q=wasserstein"><b>A kind of image search method merging Faster-RCNN and Wasserstein self-encoding</b></a></span><span class="s5"><b> </b></span><span class="s24">encoder</span></p>
<p class="p5"><span class="s2"><b>CN </b><a href="https://patentimages.storage.googleapis.com/ff/77/63/09c490792156ea/CN109086437A.pdf"><span class="s10"><b>CN109086437A</b></span></a><b> </b></span><span class="s11"><b>冯永</b></span><span class="s2"><b> </b></span><span class="s11"><b>重庆大学</b></span><span class="s2"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2"><b>Priority 2018-08-15 • Filed 2018-08-15 • Published 2018-12-25</b></span></p>
<p class="p5"><span class="s2">2. the image search method of fusion Faster-RCNN and <b>Wasserstein</b> self-encoding encoder as described in claim 1, It is characterized in that, in the S1, builds Caffe deep learning frame. 3. the image search method of fusion Faster-RCNN and <b>Wasserstein</b> self-encoding encoder as described in claim 1, …<span class="Apple-converted-space"> </span></span></p>
<p class="p10"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2018-2019 2</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/CN109660206A/en?q=wasserstein"><b>A kind of diagnosing failure of photovoltaic array method based on Wasserstein …<span class="Apple-converted-space"> </span></b><span class="s3"><b></b></span></a></span></p>
<p class="p5"><span class="s2"><b>CN </b><a href="https://patentimages.storage.googleapis.com/2c/1d/cb/d1c719bd71da4d/CN109660206A.pdf"><span class="s10"><b>CN109660206A</b></span></a><b> </b></span><span class="s11"><b>林培杰</b></span><span class="s2"><b> </b></span><span class="s11"><b>福州大学</b></span><span class="s2"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2"><b>Priority 2018-12-20 • Filed 2018-12-20 • Published 2019-04-19</b></span></p>
<p class="p5"><span class="s2">Step S2: the electric current of the step S1 photovoltaic power generation array obtained is plotted on same picture and is saved with voltage data For sample</span><span class="s11">；</span><span class="s2"> Step S3: a discriminator network D and a generator network G are designed by <b>Wasserstein</b> GAN</span><span class="s11">；</span><span class="s2"> Step S4: being divided into training set for …<span class="Apple-converted-space"> </span></span></p>
<p class="p10"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space"> </span>2018-2020 3</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/CN111046708A/en?q=wasserstein&amp;oq=wasserstein&amp;page=1"><b>Human face gender discrimination algorithm based on Wasserstein distance<span class="Apple-converted-space"> </span></b><span class="s3"><b></b></span></a></span></p>
<p class="p5"><span class="s2"><b>CN </b><a href="https://patentimages.storage.googleapis.com/3b/19/98/18fb69b56bf773/CN111046708A.pdf"><span class="s10"><b>CN111046708A</b></span></a><b> </b></span><span class="s11"><b>徐江涛</b></span><span class="s2"><b> </b></span><span class="s11"><b>天津大学青岛海洋技术研究院</b></span><span class="s2"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2"><b>Priority 2018-10-15 • Filed 2018-10-15 • Published 2020-04-21</b></span></p>
<p class="p5"><span class="s2">1. The human face gender discrimination algorithm based on the <b>Wasserstein</b> distance is characterized in that: the method comprises three steps, wherein the first step is to construct a comparison library, and select different genders to construct comparison libraries with different distributions;<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2"><br>
2018-2020 4</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/US20200125982A1/en?q=wasserstein&amp;oq=wasserstein&amp;page=1"><b>System a</b><span class="s3">nd method for unsupervised domain adaptation via sliced-wasserstein …<span class="Apple-converted-space"> </span></span></a></span></p>
<p class="p14"><span class="s18">patent number 11,176,477 [Application Number 16/719,668] was granted by the patent office on 2021-11-16 for system and method for unsupervised domain adaptation via sliced-wasserstein distance. This pate</span></p>
<p class="p5"><span class="s2">US <a href="https://patentimages.storage.googleapis.com/f7/09/ea/46536d7e571bdc/US20200125982A1.pdf"><span class="s10">US20200125982A1</span></a> Alexander J. Gabourie Hrl Laboratories, Llc<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Priority 2018-02-06 • Filed 2019-12-18 • Published 2020-04-23</span></p>
<p class="p5"><span class="s2">The computer program product as set forth in claim 11 , wherein the one or more processors further perform an operation of using sliced-<b>Wasserstein</b> (SW) distance as a dissimilarity measure for determining dissimilarity between the first input data distribution and the second input data distribution.<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2018-2019 5</span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/2c/ce/e0/ccbbca3f8a7e25/CN109389080A.pdf"><span class="s5">CN109389080A</span></a> </span><span class="s19">白静</span><span class="s18"> </span><span class="s19">西安电子科技大学</span></p>
<p class="p14"><span class="s18">Priority 2018-09-30 • Filed 2018-09-30 • Published 2019-02-26</span></p>
<p class="p20"><span class="s2">本发明公开了一种<b>基于半监督</b></span><span class="s9"><b>WGAN‑GP</b></span><span class="s2"><b>的高光谱图像分类方法</b>，克服了现有技术在训练数据受限条件下难以提取到丰富的特征信息，无法充利用无标签样本对分类器进行训练，分类精度低的问题。本发明的具体步骤包括：</span><span class="s9">(1)</span><span class="s2">输入待分类的高光谱图像；</span><span class="s9">(2)</span><span class="s2">生成样本集；</span><span class="s9">(3)</span><span class="s2">构建半监督</span><span class="s9">WGAN‑GP</span><span class="s2">网络；</span><span class="s9">(4)</span><span class="s2">训练半监督</span><span class="s9">WGAN‑GP</span><span class="s2">网络；</span><span class="s9">(5)</span><span class="s2">对测试数据进行分类。本发明能通过半监督</span><span class="s9">WGAN‑GP</span><span class="s2">中的生成器接收噪声产生伪高光谱数据辅助判别器分类，可以充分利用有限样本提高分类精度，可用于在精细农业、低质调研等领域中对高光谱图像进行地物目标的分类。</span></p>
<p class="p21"><span class="s2"><br>
</span></p>
<p class="p10"><span class="s1"><b>2018-2019 6</b></span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN109389080A/en?q=wgan&amp;oq=wgan">Hyperspectral image classification method based on semi-supervised <span class="s1"><b>WGAN</b>-GP</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/2c/ce/e0/ccbbca3f8a7e25/CN109389080A.pdf"><span class="s5">CN109389080A</span></a> </span><span class="s19">白静</span><span class="s18"> </span><span class="s19">西安电子科技大学</span></p>
<p class="p14"><span class="s18">Priority 2018-09-30 • Filed 2018-09-30 • Published 2019-02-26</span></p>
<p class="p14"><span class="s18">Selected is had supervision batch and the semi-supervised <b>WGAN</b>-GP of noise inputs by (4d), marks training data to optimize the net using having Supervision loss function in network optimizes arbiter network weight</span><span class="s19">；</span><span class="s18"> (4e) optimizes the net by selected unsupervised batch and the semi-supervised <b>WGAN</b>- …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2018 7</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN108399422A/en?q=wgan&amp;oq=wgan">A kind of image channel fusion method based on <span class="s1"><b>WGAN</b> models</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/6e/b6/07/5d7fae7de19c98/CN108399422A.pdf"><span class="s5">CN108399422A</span></a> </span><span class="s19">周智恒</span><span class="s18"> </span><span class="s19">华南理工大学</span></p>
<p class="p14"><span class="s18">Priority 2018-02-01 • Filed 2018-02-01 • Published 2018-08-14</span></p>
<p class="p15"><span class="s2">1. a kind of image channel fusion method based on <b>WGAN</b> models, which is characterized in that the image channel fusion method packet Include following steps</span><span class="s11">：</span><span class="s2"> S1, construction are originally generated confrontation network model, generate image by generator and are input to arbiter progress network …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/?q=Wasserstein+generative+adversarial+network+based+ultra-parameter+dynamic+regulating+method%2c+involves+calculating+dynamic&amp;scholar&amp;oq=Wasserstein+generative+adversarial+network+based+ultra-parameter+dynamic+regulating+method%2c+involves+calculating+dynamic+">2018</a></span><span class="s5"> 8</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=29">Wasserstein generative adversarial network based ultra-parameter dynamic regulating method, involves calculating dynamic adjusting ultra-parameter value, and increasing adjusting ultra-parameter value when difference value is negative<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN107590532-A CN107590532-B<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV SOUTH CHINA TECHNOLOGY<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): ZHOU Z; LI L.</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2018 22020 9</span></p>
<p class="p17"><span class="s17"><a href="https://patents.google.com/patent/CN109086437B/en?q=Image+retrieval+method+fusing+fast-RCNN+Wasserstein+self-encode&amp;oq=Image+retrieval+method+fusing+fast-RCNN+and+Wasserstein+self-encode"><b>Image retrieval method fusing fast-RCNN and Wasserstein self-encoder</b><span class="s25"><b></b></span></a></span></p>
<p class="p15"><span class="s2">CN <a href="https://patentimages.storage.googleapis.com/a4/85/51/2e3265f633b8f9/CN109086437B.pdf"><span class="s26">CN109086437B</span></a></span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p22"><span class="s2">2018 10</span></p>
<p class="p23"><span class="s27"><a href="https://patents.google.com/patent/CN109711452A/en?q=wgan&amp;before=priority:20181231&amp;after=priority:20180101&amp;oq=2018+wgan">It is a kind of based on <span class="s16"><b>WGAN</b>-GP model to the uneven classification method of …</span></a></span></p>
<p class="p22"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/8e/f2/61/a0367cf1a9c871/CN109711452A.pdf"><span class="s28">CN109711452A </span></a></span><span class="s29">赵艺</span><span class="s18"> </span><span class="s29">四川新网银行股份有限公司</span></p>
<p class="p22"><span class="s18">Priority 2018-12-20 • Filed 2018-12-20 • Published 2019-05-03</span></p>
<p class="p22"><span class="s18">3. a kind of method for constructing <b>WGAN</b>-GP model according to claim 1 or 2, which is characterized in that the step S2 packet Include following steps: The dimensional characteristics of the few class data of S2.1, basis, construct <b>WGAN</b>-GP structure and hyper parameter simultaneously are arranged</span><span class="s29">；</span></p>
<p class="p22"><span class="s2"><br>
</span></p>
<p class="p22"><span class="s2">2018 11</span></p>
<p class="p24"><span class="s17"><a href="https://patents.google.com/patent/CN109947086B/en?q=wasserstein&amp;before=priority:20191231&amp;after=priority:20190101&amp;oq=2019+wasserstein&amp;page=1">A kind of fuzzy detection seed set generation method and generator based on <span class="s28"><b>WGAN</b> …</span></a></span></p>
<p class="p23"><span class="s30">CN <a href="https://patentimages.storage.googleapis.com/c9/b1/39/1f3dcbf287cdb1/CN108549597A.pdf"><span class="s16">CN108549597A </span></a></span><span class="s31">纪守领</span><span class="s30"> </span><span class="s31">浙江大学</span></p>
<p class="p22"><span class="s18">Priority 2018-03-05 • Filed 2018-03-05 • Published 2018-09-18</span></p>
<p class="p22"><span class="s18">1. a kind of fuzzy detection seed set generator based on <b>WGAN</b> models, which is characterized in that including</span><span class="s29">：</span><span class="s18"> Training set acquisition module, has the fuzzy detection tool based on mutation algorithm, the fuzzy detection tool is to common Input carries out random modification and obtains …</span></p>
<p class="p22"><span class="s2"><br>
</span></p>
<p class="p22"><span class="s2">2018 12</span></p>
<p class="p24"><span class="s17"><a href="https://patents.google.com/patent/KR102202842B1/en?q=wasserstein&amp;before=priority:20191231&amp;after=priority:20190101&amp;oq=2019+wasserstein&amp;page=1">It is predicted based on difference <span class="s28"><b>WGAN</b> network safety situation</span></a></span></p>
<p class="p23"><span class="s30">CN <a href="https://patentimages.storage.googleapis.com/d0/4f/58/6fc98991d493c0/CN109120652A.pdf"><span class="s16">CN109120652A </span></a></span><span class="s31">王永</span><span class="s30"> </span><span class="s31">重庆邮电大学</span></p>
<p class="p22"><span class="s18">Priority 2018-11-09 • Filed 2018-11-09 • Published 2019-01-01</span></p>
<p class="p22"><span class="s18">The invention proposes a kind of network security situation prediction methods based on difference <b>WGAN</b>.The invention simulates the development process of situation using confrontation network (Generative adversarial network, GAN) is generated, and realizes Tendency Prediction from time dimension.</span></p>
<p class="p22"><span class="s2"><br>
</span></p>
<p class="p22"><span class="s2">2018 13</span></p>
<p class="p24"><span class="s17"><a href="https://patents.google.com/patent/CN110493242B/en?q=wgan&amp;before=priority:20191231&amp;after=priority:20190101&amp;oq=2019+wgan">Hyperspectral image classification method based on semi-supervised <span class="s28"><b>WGAN</b>-GP</span></a></span></p>
<p class="p22"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/2c/ce/e0/ccbbca3f8a7e25/CN109389080A.pdf"><span class="s28">CN109389080A </span></a></span><span class="s29">白静</span><span class="s18"> </span><span class="s29">西安电子科技大学</span></p>
<p class="p22"><span class="s18">Priority 2018-09-30 • Filed 2018-09-30 • Published 2019-02-26</span></p>
<p class="p22"><span class="s18">Selected is had supervision batch and the semi-supervised <b>WGAN</b>-GP of noise inputs by (4d), marks training data to optimize the net using having Supervision loss function in network optimizes arbiter network weight</span><span class="s29">；</span><span class="s18"> (4e) optimizes the net by selected unsupervised batch and the semi-supervised <b>WGAN</b>- …</span></p>
<p class="p22"><span class="s2"><br>
</span></p>
<p class="p22"><span class="s2">2018 14</span></p>
<p class="p25"><span class="s18">A kind of image channel fusion method based on <b>WGAN</b> models</span></p>
<p class="p23"><span class="s30">CN <a href="https://patentimages.storage.googleapis.com/6e/b6/07/5d7fae7de19c98/CN108399422A.pdf"><span class="s16">CN108399422A </span></a></span><span class="s31">周智恒</span><span class="s30"> </span><span class="s31">华南理工大学</span></p>
<p class="p22"><span class="s18">Priority 2018-02-01 • Filed 2018-02-01 • Published 2018-08-14</span></p>
<p class="p26"><span class="s2">1. a kind of image channel fusion method based on <b>WGAN</b> models, which is characterized in that the image channel fusion method packet Include following steps</span><span class="s32">：</span><span class="s2"> S1, construction are originally generated confrontation network model, generate image by generator and are input to arbiter progress network …</span></p>
<p class="p22"><span class="s2"><br>
</span></p>
<p class="p22"><span class="s2">2018 15</span></p>
<p class="p25"><span class="s18">Object Shape Regression Using <b>Wasserstein</b> Distance</span></p>
<p class="p22"><span class="s18">EP US JP <a href="https://patentimages.storage.googleapis.com/e8/65/8a/f45cfd3950c1bc/JP2020098587A.pdf"><span class="s28">JP2020098587A </span></a></span><span class="s29">ジン</span><span class="s33">・サン</span><span class="s18"> </span><span class="s29">パロ</span><span class="s18"> </span><span class="s29">アルト</span><span class="s18"> </span><span class="s29">リサーチ</span><span class="s18"> </span><span class="s29">センター</span><span class="s18"> </span><span class="s29">インコーポレイテッド</span></p>
<p class="p14"><span class="s34">Prio</span><span class="s18">rity 2018-12-17 • Filed 2019-11-25 • Published 2020-06-25</span></p>
<p class="p14"><span class="s18">Optimizing the parameters of the shape regression model based on the <b>Wasserstein</b> distances calculated by the classifier module. The method of claim 2, wherein optimizing the shape regression model comprises updating parameters of the shape regression model such that the calculated <b>Wasserstein</b> …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2018 16</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN108197581A/en?q=wgans&amp;oq=wgans">… plane signal identification detection algorithm based on improvement AC-<span class="s16"><b>WGANs</b></span></a></span></p>
<p class="p9"><span class="s30">CN <a href="https://patentimages.storage.googleapis.com/01/ba/51/fa2d97f0176b66/CN108197581A.pdf"><span class="s35">CN108197581A </span></a></span><span class="s36">赵彩丹</span><span class="s30"> </span><span class="s36">厦门大学</span></p>
<p class="p14"><span class="s18">Priority 2018-01-10 • Filed 2018-01-10 • Published 2018-06-22</span></p>
<p class="p15"><span class="s2">4. as described in claim 1 a kind of based on the unmanned plane signal identification detection algorithm for improving AC-<b>WGANs</b>, feature exists In</span><span class="s11">：</span><span class="s2">In step S4, it is described improve AC-<b>WGANs</b> algorithms the specific steps are</span><span class="s11">：</span><span class="s2"> S41, according to the characteristics of the loss function of AC-<b>WGANs</b> …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p25"><span class="s37">2018 17<br>
</span><span class="s18">A kind of feature recalibration convolution method based on <b>WGAN</b> model</span></p>
<p class="p23"><span class="s30">CN <a href="https://patentimages.storage.googleapis.com/79/5e/9c/9b8adaafae1e4b/CN109359667A.pdf"><span class="s16">CN109359667A </span></a></span><span class="s31">周智恒</span><span class="s30"> </span><span class="s31">华南理工大学</span></p>
<p class="p22"><span class="s18">Priority 2018-09-07 • Filed 2018-09-07 • Published 2019-02-19</span></p>
<p class="p22"><span class="s18">5. a kind of feature recalibration convolution method based on <b>WGAN</b> model according to claim 1, which is characterized in that described Loss function expression formula are as follows: Wherein, D (x) indicates differentiation of the arbiter to image, and pr indicates the distribution of data …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p27"><span class="s2">2018 18. patent. 2018-2020</span></p>
<p class="p28"><span class="s17"><a href="https://patents.google.com/patent/CN113962612A/en?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new">Object shape regression using <span class="s38"><b>wasserstein</b> distance</span></a></span></p>
<p class="p29"><span class="s18">EP US JP <a href="https://patentimages.storage.googleapis.com/55/0e/1f/32387dbd1ea59f/EP3671555A1.pdf"><span class="s39">EP3671555A1 </span></a>Jin Sun Palo Alto Research Center Incorporated</span></p>
<p class="p30"><span class="s18">Priority 2018-12-17 • Filed 2019-12-13 • Published 2020-06-24</span></p>
<p class="p27"><span class="s18">optimizing parameters of the shape-regression model based on the <b>Wasserstein</b> distance computed by the discriminator module. The method of claim 2, wherein optimizing the shape-regression model comprises updating parameters of the shape-regression model in such a way that the computed <b>Wasserstein</b> …</span><span class="s2"><br>
</span></p>
<p class="p27"><span class="s2">2018 19. patent</span></p>
<p class="p31"><span class="s40"><a href="https://patents.google.com/patent/ID26464A/en?q=TI%3d(bwgan)&amp;num=25&amp;oq=TI%3d(bwgan)&amp;sort=new">A kind of <span class="s38"><b>eGaN</b> HEMT bridge arm clutter reduction driving circuits and its …</span></a></span></p>
<p class="p29"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/db/5a/16/cf8555a93ef65a/CN108649777A.pdf"><span class="s39">CN108649777A </span></a></span><span class="s19">张英</span><span class="s18"> </span><span class="s19">南京航空航天大学</span></p>
<p class="p30"><span class="s18">Priority 2018-04-12 • Filed 2018-04-12 • Published 2018-10-12</span></p>
<p class="p27"><span class="s18">4. a kind of <b>eGaN</b> HEMT bridge arms clutter reduction driving circuit according to claim 1, it is characterised in that</span><span class="s19">：</span><span class="s18">Described One Low ESR bridge arm clutter reduction circuit and the second Low ESR bridge arm clutter reduction circuit structure are identical, include that third switchs The drain …</span></p>
<p class="p32"><span class="s2"></span><br></p>
<p class="p27"><span class="s2">2018 20<span class="Apple-converted-space">  </span>patent</span></p>
<p class="p28"><span class="s17"><a href="https://patents.google.com/?q=TI%3d(wgan)&amp;num=25&amp;oq=TI%3d(wgan)&amp;sort=new&amp;page=2#">A kind of fuzzy detection seed set generation method and generator based on <span class="s38"><b>WGAN</b> …</span></a></span></p>
<p class="p33"><span class="s41">CN <a href="https://patentimages.storage.googleapis.com/c9/b1/39/1f3dcbf287cdb1/CN108549597A.pdf"><span class="s42">CN108549597A </span></a></span><span class="s43">纪守领</span><span class="s41"> </span><span class="s43">浙江大学</span></p>
<p class="p30"><span class="s18">Priority 2018-03-05 • Filed 2018-03-05 • Published 2018-09-18</span></p>
<p class="p27"><span class="s18">1. a kind of fuzzy detection seed set generator based on <b>WGAN</b> models, which is characterized in that including</span><span class="s19">：</span><span class="s18"> Training set acquisition module, has the fuzzy detection tool based on mutation algorithm, the fuzzy detection tool is to common Input carries out random modification and obtains …</span></p>
<p class="p32"><span class="s2"></span><br></p>
<p class="p27"><span class="s2">2018 21. patent</span></p>
<p class="p28"><span class="s17"><a href="https://patents.google.com/?q=TI%3d(wgan)&amp;num=25&amp;oq=TI%3d(wgan)&amp;sort=new&amp;page=2#">A kind of image channel fusion method based on <span class="s38"><b>WGAN</b> models</span></a></span></p>
<p class="p29"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/6e/b6/07/5d7fae7de19c98/CN108399422A.pdf"><span class="s39">CN108399422A </span></a></span><span class="s19">周智恒</span><span class="s18"> </span><span class="s19">华南理工大学</span></p>
<p class="p30"><span class="s18">Priority 2018-02-01 • Filed 2018-02-01 • Published 2018-08-14</span></p>
<p class="p27"><span class="s18">1. a kind of image channel fusion method based on <b>WGAN</b> models, which is characterized in that the image channel fusion method packet Include following steps</span><span class="s19">：</span><span class="s18"> S1, construction are originally generated confrontation network model, generate image by generator and are input to arbiter progress network …</span></p>
<p class="p34"><span class="s44"><br>
</span><span class="s45"><span class="Apple-converted-space"> </span></span><span class="s20"><br>
</span><span class="s2">2018 22. patent</span></p>
<p class="p31"><span class="s40"><a href="https://patents.google.com/?q=TI%3d(wgan)&amp;num=25&amp;oq=TI%3d(wgan)&amp;sort=new&amp;page=2#">It is a kind of based on <span class="s38"><b>WGAN</b>-GP model to the uneven classification method of<span class="Apple-converted-space"> </span></span></a></span></p>
<p class="p29"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/8e/f2/61/a0367cf1a9c871/CN109711452A.pdf"><span class="s39">CN109711452A </span></a></span><span class="s19">赵艺</span><span class="s18"> </span><span class="s19">四川新网银行股份有限公司</span></p>
<p class="p30"><span class="s18">Priority 2018-12-20 • Filed 2018-12-20 • Published 2019-05-03</span></p>
<p class="p27"><span class="s18">3. a kind of method for constructing <b>WGAN</b>-GP model according to claim 1 or 2, which is characterized in that the step S2 packet Include following steps: The dimensional characteristics of the few class data of S2.1, basis, construct <b>WGAN</b>-GP structure and hyper parameter simultaneously are arranged</span><span class="s19">；</span></p>
<p class="p27"><span class="s2"><br>
2018 23. patent</span></p>
<p class="p28"><span class="s17"><a href="https://patents.google.com/?q=TI%3d(wgan)&amp;num=25&amp;oq=TI%3d(wgan)&amp;sort=new&amp;page=2#">It is predicted based on difference <span class="s38"><b>WGAN</b> network safety situation</span></a></span></p>
<p class="p33"><span class="s41">CN <a href="https://patentimages.storage.googleapis.com/d0/4f/58/6fc98991d493c0/CN109120652A.pdf"><span class="s42">CN109120652A </span></a></span><span class="s43">王永</span><span class="s41"> </span><span class="s43">重庆邮电大学</span></p>
<p class="p30"><span class="s18">Priority 2018-11-09 • Filed 2018-11-09 • Published 2019-01-01</span></p>
<p class="p27"><span class="s18">The invention proposes a kind of network security situation prediction methods based on difference <b>WGAN</b>.The invention simulates the development process of situation using confrontation network (Generative adversarial network, GAN) is generated, and realizes Tendency Prediction from time dimension.</span></p>
<p class="p27"><span class="s2"><br>
</span></p>
<p class="p27"><span class="s2">2018 24. patent</span></p>
<p class="p28"><span class="s17"><a href="https://patents.google.com/patent/ID28505A/en?q=TI%3d(bwgan)&amp;num=25&amp;oq=TI%3d(bwgan)&amp;sort=new">Hyperspectral image classification method based on semi-supervised <span class="s38"><b>WGAN</b>-GP</span></a></span></p>
<p class="p29"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/2c/ce/e0/ccbbca3f8a7e25/CN109389080A.pdf"><span class="s39">CN109389080A </span></a></span><span class="s19">白静</span><span class="s18"> </span><span class="s19">西安电子科技大学</span></p>
<p class="p30"><span class="s18">Priority 2018-09-30 • Filed 2018-09-30 • Published 2019-02-26</span></p>
<p class="p27"><span class="s18">Selected is had supervision batch and the semi-supervised <b>WGAN</b>-GP of noise inputs by (4d), marks training data to optimize the net using having Supervision loss function in network optimizes arbiter network weight</span><span class="s19">；</span><span class="s18"> (4e) optimizes the net by selected unsupervised batch and the semi-supervised <b>WGAN</b>- …</span></p>
<p class="p27"><span class="s2"><br>
2018 25. patent</span></p>
<p class="p28"><span class="s17"><a href="https://patents.google.com/patent/ID26463A/en?q=TI%3d(bwgan)&amp;num=25&amp;oq=TI%3d(bwgan)&amp;sort=new">A kind of feature recalibration convolution method based on <span class="s38"><b>WGAN</b> model</span></a></span></p>
<p class="p29"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/79/5e/9c/9b8adaafae1e4b/CN109359667A.pdf"><span class="s39">CN109359667A </span></a></span><span class="s19">周智恒</span><span class="s18"> </span><span class="s19">华南理工大学</span></p>
<p class="p30"><span class="s18">Priority 2018-09-07 • Filed 2018-09-07 • Published 2019-02-19</span></p>
<p class="p27"><span class="s18">5. a kind of feature recalibration convolution method based on <b>WGAN</b> model according to claim 1, which is characterized in that described Loss function expression formula are as follows: Wherein, D (x) indicates differentiation of the arbiter to image, and pr indicates the distribution of data …</span></p>
<p class="p35"><span class="s1"><a href="https://scholar.google.com/scholar?q=Wasserstein+Distributional+Learning+%7C+DeepAI&amp;hl=en&amp;as_sdt=0&amp;as_vis=1&amp;oi=scholart"><span class="Apple-converted-space"> </span><span class="s46"></span></a></span></p>
<p class="p27"><span class="s2">2018 26. patent</span></p>
<p class="p36"><span class="s17"><a href="https://patents.google.com/?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new&amp;page=1#">A kind of diagnosing failure of photovoltaic array method based on <span class="s47"><b>Wasserstein</b> …</span></a></span></p>
<p class="p37"><span class="s41">CN <a href="https://patentimages.storage.googleapis.com/2c/1d/cb/d1c719bd71da4d/CN109660206A.pdf"><span class="s48">CN109660206A </span></a></span><span class="s49">林培杰</span><span class="s41"> </span><span class="s49">福州大学</span></p>
<p class="p38"><span class="s18">Priority 2018-12-20 • Filed 2018-12-20 • Published 2019-04-19</span></p>
<p class="p39"><span class="s18">Step S2: the electric current of the step S1 photovoltaic power generation array obtained is plotted on same picture and is saved with voltage data For sample</span><span class="s50">；</span><span class="s18"> Step S3: a discriminator network D and a generator network G are designed by <b>Wasserstein</b> GAN</span><span class="s50">；</span><span class="s18"> Step S4: being divided into training set for …</span></p>
<p class="p27"><span class="s2"><br>
2018 27<span class="Apple-converted-space">  </span>patent</span></p>
<p class="p36"><span class="s17"><a href="https://patents.google.com/?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new&amp;page=1#">Human face gender discrimination algorithm based on <span class="s47"><b>Wasserstein</b> distance</span></a></span></p>
<p class="p40"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/3b/19/98/18fb69b56bf773/CN111046708A.pdf"><span class="s51">CN111046708A </span></a></span><span class="s50">徐江涛</span><span class="s18"> </span><span class="s50">天津大学青岛海洋技术研究院</span></p>
<p class="p38"><span class="s18">Priority 2018-10-15 • Filed 2018-10-15 • Published 2020-04-21</span></p>
<p class="p39"><span class="s18">1. The human face gender discrimination algorithm based on the <b>Wasserstein</b> distance is characterized in that: the method comprises three steps, wherein the first step is to construct a comparison library, and select different genders to construct comparison libraries with different distributions;</span></p>
<p class="p27"><span class="s52"><br>
</span><span class="s2">2018 28. patent</span></p>
<p class="p36"><span class="s17"><a href="https://patents.google.com/patent/CN112765426A/en?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new">Image retrieval method fusing fast-RCNN and <span class="s47"><b>Wasserstein</b> self-encoder</span></a></span></p>
<p class="p37"><span class="s41">CN <a href="https://patentimages.storage.googleapis.com/a4/85/51/2e3265f633b8f9/CN109086437B.pdf"><span class="s48">CN10908643</span></a></span></p>
<p class="p41"><span class="s17"><a href="https://www.worldcat.org/title/7355712920"><b><span class="Apple-converted-space"> </span></b><span class="s53"><b></b></span></a></span></p>
<p class="p42"><span class="s2"></span><br></p>
<p class="p42"><span class="s2"></span><br></p>
<p class="p10"><span class="s2">&lt;— 16 till 2017<span class="Apple-converted-space"> </span></span></p>
<p class="p10"><span class="s2">+ 28 in 2018 <span class="Apple-converted-space">   </span></span></p>
<p class="p10"><span class="s2">= 44<span class="Apple-converted-space">  </span>till 2018</span></p>
<p class="p10"><span class="s2">end 2018. e18</span></p>
<p class="p14"><span class="s2"><span class="Apple-converted-space"> </span><br>
</span></p>
<p class="p42"><span class="s18"><span class="Apple-converted-space"> </span></span></p>
<p class="p13"><span class="s2">start 2019</span></p>
<p class="p13"><span class="s2">58 <span class="Apple-converted-space">  </span>patents</span></p>
<p class="p5"><span class="s2"><br>
2019 1</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/CN110414383A/en?q=wasserstein"><b>Convolutional neural networks based on Wasserstein distance fight transfer …<span class="Apple-converted-space"> </span></b><span class="s3"><b></b></span></a></span></p>
<p class="p5"><span class="s2"><b>CN </b><a href="https://patentimages.storage.googleapis.com/62/e0/ec/08ab9f68e1b69f/CN110414383A.pdf"><span class="s10"><b>CN110414383A</b></span></a><b> </b></span><span class="s11"><b>袁烨</b></span><span class="s2"><b> </b></span><span class="s11"><b>华中科技大学</b></span><span class="s2"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2"><b>Priority 2019-07-11 • Filed 2019-07-11 • Published 2019-11-05</b></span></p>
<p class="p5"><span class="s2">To maximize described in the distance of the <b>Wasserstein</b> between the source domain feature set and the target signature collection and minimum The judgement loss of <b>Wasserstein</b> distance, the judgement penalty values of the source domain breakdown judge collection and target faults judgement …<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2"><b><span class="Apple-converted-space"> </span></b><br>
</span></p>
<p class="p5"><span class="s2">2019 2</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/CN110110670A/en?q=wasserstein"><b>Data correlation method in pedestrian tracking based on Wasserstein measurement<span class="Apple-converted-space"> </span></b><span class="s3"><b></b></span></a></span></p>
<p class="p5"><span class="s2"><b>CN </b><a href="https://patentimages.storage.googleapis.com/d3/3f/51/267dfa486198f4/CN110110670A.pdf"><span class="s10"><b>CN110110670A</b></span></a><b> </b></span><span class="s11"><b>郭春生</b></span><span class="s2"><b> </b></span><span class="s11"><b>杭州电子科技大学</b></span><span class="s2"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2"><b>Priority 2019-05-09 • Filed 2019-05-09 • Published 2019-08-09</b></span></p>
<p class="p5"><span class="s2">It is a kind of based on <b>Wasserstein</b> measurement pedestrian tracking in data correlation method, it include: the external appearance characteristic for obtaining pedestrian, the external appearance characteristic extracted is input to a feature extraction network, the external appearance …<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><br>
2019-2020 3</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/CN110797919A/en?q=wasserstein"><b>Clean energy power supply planning method based on Wasserstein distance and …<span class="Apple-converted-space"> </span></b><span class="s3"><b></b></span></a></span></p>
<p class="p43"><span class="s9"><b>CN </b><a href="https://patentimages.storage.googleapis.com/c3/44/ed/aa51c8631c9dec/CN110797919A.pdf"><span class="s13"><b>CN110797919A</b></span></a><b> </b></span><span class="s2"><b>汪荣华</b></span><span class="s9"><b> </b></span><span class="s2"><b>国网四川省电力公司经济技术研究院</b></span><span class="s9"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2"><b>Priority 2019-12-05 • Filed 2019-12-05 • Published 2020-02-14</b></span></p>
<p class="p5"><span class="s2">5. The method for clean energy power planning based on <b>Wasserstein</b> distance and distribution robust optimization according to claim 2, characterized in that the method uses <b>Wasserstein</b> distance to describe the difference between the empirical distribution and the true distribution obtained from a …<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2"><br>
2019 4</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/CN110555382A/en?q=wasserstein"><b>Finger vein identification method based on deep learning and Wasserstein …<span class="Apple-converted-space"> </span></b><span class="s3"><b></b></span></a></span></p>
<p class="p5"><span class="s2"><b>CN </b><a href="https://patentimages.storage.googleapis.com/9c/5e/85/29c204e0d55353/CN110555382A.pdf"><span class="s10"><b>CN110555382A</b></span></a><b> </b></span><span class="s11"><b>张娜</b></span><span class="s2"><b> </b></span><span class="s11"><b>浙江理工大学</b></span><span class="s2"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2"><b>Priority 2019-07-31 • Filed 2019-07-31 • Published 2019-12-10</b></span></p>
<p class="p5"><span class="s2">S52, in the identification stage, extracting feature codes G w (x) 'of the finger vein image through steps S1, S2, S3 and S4, matching the feature codes G w (x) } registered in a database one by one, calculating the <b>Wasserstein</b> distance between G w (x)' and G w (x), and solving the <b>Wasserstein</b> …<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2"><br>
2019-2020 5</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/JP2020098587A/en?q=wasserstein&amp;oq=wasserstein"><b>Object Shape Regression Using Wasserstein Distance<span class="Apple-converted-space"> </span></b><span class="s3"><b></b></span></a></span></p>
<p class="p43"><span class="s54"><a href="https://patentimages.storage.googleapis.com/e8/65/8a/f45cfd3950c1bc/JP2020098587A.pdf"><b>JP2020098587A</b></a></span><span class="s9"><b> </b></span><span class="s2"><b>ジン</b></span><span class="s55"><b>・サン</b></span><span class="s9"><b> </b></span><span class="s2"><b>パロ</b></span><span class="s9"><b> </b></span><span class="s2"><b>アルト</b></span><span class="s9"><b> </b></span><span class="s2"><b>リサーチ</b></span><span class="s9"><b> </b></span><span class="s2"><b>センター</b></span><span class="s9"><b> </b></span><span class="s2"><b>インコーポレイテッド</b></span><span class="s9"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2"><b>Priority 2018-12-17 • Filed 2019-11-25 • Published 2020-06-25</b></span></p>
<p class="p5"><span class="s2">Optimizing parameters of the shape regression model based on the <b>Wasserstein</b> distances calculated by the discriminator module. The apparatus of claim 9, wherein optimizing the shape regression model comprises updating parameters of the shape regression model such that the calculated <b>Wasserstein</b> …<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2"><br>
2019-2020 6</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/EP3671555A1/en?q=wasserstein&amp;oq=wasserstein"><b>Object shape regression using wasserstein distance<span class="Apple-converted-space"> </span></b><span class="s3"><b></b></span></a></span></p>
<p class="p5"><span class="s2"><b>EP US </b><a href="https://patentimages.storage.googleapis.com/55/0e/1f/32387dbd1ea59f/EP3671555A1.pdf"><span class="s10"><b>EP3671555A1</b></span></a><b> Jin Sun Palo Alto Research Center Incorporated<span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2"><b>Priority 2018-12-17 • Filed 2019-12-13 • Published 2020-06-24</b></span></p>
<p class="p5"><span class="s2">optimizing parameters of the shape-regression model based on the <b>Wasserstein</b> distance computed by the discriminator module. The method of claim 2, wherein optimizing the shape-regression model comprises updating parameters of the shape-regression model in such a way that the computed <b>Wasserstein</b> …<span class="Apple-converted-space"> </span></span></p>
<p class="p44"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2"><br>
2019-2020 7</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/CN111178427A/en?q=wasserstein&amp;oq=wasserstein&amp;page=1"><b>Depth self-coding embedded clustering method based on Sliced-Wasserstein …<span class="Apple-converted-space"> </span></b><span class="s3"><b></b></span></a></span></p>
<p class="p5"><span class="s2"><b>CN </b><a href="https://patentimages.storage.googleapis.com/91/b5/5d/c32cab847bcf9b/CN111178427A.pdf"><span class="s10"><b>CN111178427A</b></span></a><b> </b></span><span class="s11"><b>郭春生</b></span><span class="s2"><b> </b></span><span class="s11"><b>杭州电子科技大学</b></span><span class="s2"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2"><b>Priority 2019-12-27 • Filed 2019-12-27 • Published 2020-05-19</b></span></p>
<p class="p5"><span class="s2">The invention discloses a depth self-coding embedded clustering method based on Sliced-<b>Wasserstein</b> distance, which comprises the following steps: s11, constructing a self-coding network module based on a Sliced-Walserstein distance; s12, constructing a clustering module; s13, combining the built …<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2019 8</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN110555382A/en?q=wasserstein">Finger vein identification method based on deep learning and <span class="s1"><b>Wasserstein</b> …</span></a></span></p>
<h4 style="margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0b0b0b; -webkit-text-stroke: #0b0b0b"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/9c/5e/85/29c204e0d55353/CN110555382A.pdf"><span class="s5">CN110555382A</span></a> </span><span class="s19">张娜</span><span class="s18"> </span><span class="s19">浙江理工大学</span></h4>
<h4 style="margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times; color: #0b0b0b; -webkit-text-stroke: #0b0b0b"><span class="s18">Priority 2019-07-31 • Filed 2019-07-31 • Published 2019-12-10</span></h4>
<p class="p14"><span class="s18">S52, in the identification stage, extracting feature codes G w (x) 'of the finger vein image through steps S1, S2, S3 and S4, matching the feature codes G w (x) } registered in a database one by one, calculating the <b>Wasserstein</b> distance between G w (x)' and G w (x), and solving the <b>Wasserstein</b> …</span></p>
<p class="p5"><span class="s2"><br>
2019 9</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/CN110907176A/en?q=wasserstein&amp;oq=wasserstein&amp;page=1"><b>Wasserstein distance-based fault diagnosis method for deep countermeasure …<span class="Apple-converted-space"> </span></b><span class="s3"><b></b></span></a></span></p>
<p class="p5"><span class="s2"><b>CN </b><a href="https://patentimages.storage.googleapis.com/a8/e1/de/b044ab8a470aac/CN110907176A.pdf"><span class="s10"><b>CN110907176A</b></span></a><b> </b></span><span class="s11"><b>徐娟</b></span><span class="s2"><b> </b></span><span class="s11"><b>合肥工业大学</b></span><span class="s2"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2"><b>Priority 2019-09-30 • Filed 2019-09-30 • Published 2020-03-24</b></span></p>
<p class="p5"><span class="s2">1. A fault diagnosis method of a deep countermeasure migration network based on <b>Wasserstein</b> distance is characterized by comprising the following steps: s1, respectively obtaining source domains D s And a target domain D t The data set of (a); wherein D represents a domain; superscript s denotes …<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2"><br>
2019 10</span></p>
<p class="p6"><span class="s1"><a href="https://apps-webofknowledge-com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=1&amp;SID=7EI6YyDJo6Djz3hflt9&amp;page=2&amp;doc=29">Wasserstein distance based convolution neural network anti-transfer learning method, involves completing countermeasure migration learning of convolution neural network according to convergence criterion<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN110414383-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV HUAZHONG SCI &amp; TECHNOLOGY<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): YUAN Y; ZHOU B; CHENG C; et al.</span></p>
<table width="784.0" cellspacing="0" cellpadding="0" class="t1">
  <tbody>
    <tr>
      <td valign="middle" class="td1">
        <table cellspacing="0" cellpadding="0" class="t2">
          <tbody>
            <tr>
              <td valign="middle" class="td2">
                <p class="p5"><span class="s2">Patent Number</span></p>
              </td>
              <td valign="middle" class="td3">
                <p class="p5"><span class="s2">Publ. Date</span></p>
              </td>
              <td valign="middle" class="td4">
                <p class="p5"><span class="s2">Main IPC</span></p>
              </td>
              <td valign="middle" class="td5">
                <p class="p5"><span class="s2">Week</span></p>
              </td>
              <td valign="middle" class="td6">
                <p class="p5"><span class="s2">Page Count</span></p>
              </td>
              <td valign="middle" class="td7">
                <p class="p5"><span class="s2">Language</span></p>
              </td>
            </tr>
            <tr>
              <td valign="middle" class="td2">
                <p class="p5"><span class="s2">CN110414383-A </span></p>
              </td>
              <td valign="middle" class="td3">
                <p class="p5"><span class="s2">05 Nov 2019</span></p>
              </td>
              <td valign="middle" class="td4">
                <p class="p5"><span class="s2">G06K-009/00</span></p>
              </td>
              <td valign="middle" class="td5">
                <p class="p5"><span class="s2">201989 </span></p>
              </td>
              <td valign="middle" class="td6">
                <p class="p5"><span class="s2">Pages: 17 </span></p>
              </td>
              <td valign="middle" class="td7">
                <p class="p5"><span class="s2">Chinese </span></p>
              </td>
            </tr>
          </tbody>
        </table>
      </td>
    </tr>
  </tbody>
</table>
<p class="p10"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2019-2020 11</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/CN110929399A/en?q=wasserstein&amp;oq=wasserstein&amp;page=1"><b>… typical scene generation method based on BIRCH clustering and Wasserstein …<span class="Apple-converted-space"> </span></b><span class="s3"><b></b></span></a></span></p>
<p class="p43"><span class="s9"><b>CN </b><a href="https://patentimages.storage.googleapis.com/43/9a/ba/e1eb5d3157ffde/CN110929399A.pdf"><span class="s13"><b>CN110929399A</b></span></a><b> </b></span><span class="s2"><b>汤向华</b></span><span class="s9"><b> </b></span><span class="s2"><b>国网江苏省电力有限公司南通供电分公司</b></span><span class="s9"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2"><b>Priority 2019-11-21 • Filed 2019-11-21 • Published 2020-03-27</b></span></p>
<p class="p5"><span class="s2">2. The method for generating a typical wind power output scene based on BIRCH clustering and <b>Wasserstein</b> distance as claimed in claim 1, wherein: the specific steps of the BIRCH clustering are as follows: a) setting threshold parameters B, L and T, and inputting wind power scene number S; b) number … <br>
</span></p>
<p class="p5"><span class="s2">2019 12</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=AdvancedSearch&amp;qid=3&amp;SID=5DtnKIc854mkvi4l9SB&amp;page=2&amp;doc=11">Deep learning and Wasserstein distance metric based finger vein identification method, involves performing encoding operation on images, and utilizing similarity of Wasserstein distance metric as result of search identification </a></span><span class="s5"><span class="Apple-converted-space">   </span></span></p>
<p class="p5"><span class="s56"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=AdvancedSearch&amp;qid=3&amp;SID=5DtnKIc854mkvi4l9SB&amp;page=2&amp;doc=11"><span class="Apple-converted-space"> </span></a></span><span class="s2">Patent Number: CN110555382-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV ZHEJIANG SCI-TECH<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): ZHANG N; TU X; BAO X; et al.</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2019 13</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=AdvancedSearch&amp;qid=3&amp;SID=5DtnKIc854mkvi4l9SB&amp;page=3&amp;doc=30">Generated confrontation network based mushroom phenotype image generation method, involves obtaining Wasserstein distance similarity measurement index for establishing high-quality mushroom surface type image generating model<span class="Apple-converted-space"> </span></a></span><span class="s5"> 2019</span></p>
<p class="p5"><span class="s2">Patent Number: CN110197514-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV NANJING AGRIC<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): YUAN P; WU M; XU H; et al.</span></p>
<p class="p5"><span class="s2"><br>
2019 14</span></p>
<p class="p5"><span class="s2">Open Access<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s7"><a href="https://worldwide.espacenet.com/publicationDetails/biblio?FT=D&amp;date=20191105&amp;DB=EPODOC&amp;CC=CN&amp;NR=110414383A#"><b>Convolutional neural network adversarial transfer learning</b></a></span><span class="s2"><b> method based on Waserstein distance and application thereof<span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2">by LI XINGYI; MA GUIJUN; CHENG CHENG; More...<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">11/2019</span></p>
<p class="p5"><span class="s2">The invention relates to a convolutional neural network adversarial transfer learning method based on Waserstein distance and application thereof and the...</span></p>
<p class="p5"><span class="s2">Patent: Citation Online<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2"><br>
2019 15</span></p>
<p class="p5"><span class="s2">Open Access<span class="Apple-converted-space"> </span></span></p>
<p class="p8"><span class="s57"><a href="https://worldwide.espacenet.com/publicationDetails/biblio?FT=D&amp;date=20190419&amp;DB=EPODOC&amp;CC=CN&amp;NR=109660206A#"><b>种基于</b><span class="s58"><b>Wasserstein</b></span><span class="s3"><b> GAN</b></span><span class="s1"><b>的光伏阵列故障诊断方法</b></span><span class="s3"><b><span class="Apple-converted-space"> </span></b></span></a></span></p>
<p class="p5"><span class="s2">04/2019</span></p>
<p class="p43"><span class="s2">本发明涉及种基于</span><span class="s9">Wasserstein GAN</span><span class="s2">的光伏阵列故障诊断方法，首先对光伏阵列电流、电压时序数据进行采集；接着将获取的光伏阵列时序电流与时序电压数据绘制为曲线图形并保存为样本；然后设计</span><span class="s9">Wasserstein GAN</span><span class="s2">网络中的鉴别器</span><span class="s9">D</span><span class="s2">与生成器</span><span class="s9">G</span><span class="s2">；然后训练</span><span class="s9">Wasserstein...</span></p>
<p class="p5"><span class="s2">Patent:<span class="Apple-converted-space">  </span>Citation Online<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2"><b>Photovoltaic array fault diagnosis method based on Wasserstein GAN</b></span></p>
<p class="p5"><span class="s2">[Chinese<span class="Apple-converted-space">  </span>Fault Diagnosis Method for Photovoltaic Array Based on Wasserstein GAN]</span></p>
<p class="p44"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">2019 16</span></p>
<p class="p5"><span class="s2">Open Access<span class="Apple-converted-space"> </span></span></p>
<p class="p45"><span class="s1"><a href="https://worldwide.espacenet.com/publicationDetails/biblio?FT=D&amp;date=20190806&amp;DB=EPODOC&amp;CC=CN&amp;NR=110097512A#"><b>基于</b><span class="s59"><b>Wasserstein</b></span><span class="s60"><b>生成对抗网络的三维</b></span><span class="s61"><b>MRI</b></span><span class="s60"><b>图像去噪模型的构建方法及应用</b></span><span class="s61"><b><span class="Apple-converted-space"> </span></b></span></a></span></p>
<p class="p5"><span class="s2">08/2019</span></p>
<p class="p5"><span class="s2">Patent:<span class="Apple-converted-space">  </span>Citation Online <span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2"><b>Construction method and application of three-dimensional MRI image denoising model based on Wasserstein generative adversarial network  <span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2">[Chinese<span class="Apple-converted-space">  </span>Construction method and application of 3D MRI image denoising model based on Wasserstein generative adversarial network]</span></p>
<p class="p9"><span class="s2"><br>
2019 17</span></p>
<p class="p8"><span class="s1"><a href="https://worldwide.espacenet.com/publicationDetails/biblio?FT=D&amp;date=20191122&amp;DB=EPODOC&amp;CC=CN&amp;NR=110493242A#"><b>Improved image enhancement method and device based on WGA-GP and U-net, and storage medium<span class="Apple-converted-space"> </span></b><span class="s61"><b></b></span></a></span></p>
<p class="p5"><span class="s2">by WANG HONGLING; TANG JIE; LI QINGYU<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">11/2019</span></p>
<p class="p5"><span class="s2">The invention discloses an improved image enhancement method and an improved image enhancement device based on WGAN-GP and U-net, and a storage medium. The...</span></p>
<p class="p5"><span class="s2">Patent: <span class="Apple-converted-space">  </span>Citation Online<span class="Apple-converted-space"> </span></span></p>
<p class="p8"><span class="s1"><a href="https://patents.google.com/patent/CN105825484A/zh">details<span class="s61"></span></a></span></p>
<p class="p5"><span class="s2"><br>
2019 18</span></p>
<p class="p46"><span class="s1"><a href="http://faculty.csu.edu.cn/dengxiaoheng/en/zlcg/10456/content/3827.htm"><b>一种基于</b><span class="s3"><b>WGAN-GP</b></span><span class="s57"><b>和过采样的不平衡学习方法</b></span><span class="s3"><b> - </b></span><span class="s57"><b>中南大学教师</b></span><span class="s3"><b> ...</b></span></a></span></p>
<p class="p6"><span class="s1"><a href="http://faculty.csu.edu.cn/dengxiaoheng/en/zlcg/10456/content/3827.htm"><i>faculty.csu.edu.cn › dengxiaoheng › zlcg › content</i><span class="s3"><i></i></span></a></span></p>
<p class="p6"><span class="s1"><a href="https://translate.google.com/translate?hl=en&amp;sl=zh-CN&amp;u=http://faculty.csu.edu.cn/dengxiaoheng/en/zlcg/10456/content/3827.htm&amp;prev=search">Translate this page<span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">An imbalanced learning method based on <i>WGAN</i>-<i>GP</i> and oversampling. Click</span><span class="s11">：</span><span class="s2">. Application no</span><span class="s11">：</span><span class="s2"> ... <i>Patent</i> Inventor</span><span class="s11">：邓晓衡、黄戎、沈海澜</span><span class="s2">. Open date</span><span class="s11">：</span><span class="s2">2019-05-28.</span></p>
<p class="p43"><span class="s2"><b>一种基于</b></span><span class="s62"><b>WGAN</b></span><span class="s9"><b>-GP</b></span><span class="s2"><b>和过采样的不平衡学习方法</b></span><span class="s9"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2">05/2019</span></p>
<p class="p43"><span class="s2">本发明公开了一种基于</span><span class="s9">WGAN-GP</span><span class="s2">和过采样的不平衡学习方法，包括：生成器网络，由三层全连接网络组成并且每一层的输出都应用了</span><span class="s9">Batch...</span></p>
<p class="p5"><span class="s2">Patent: Citation Online<span class="Apple-converted-space"> </span></span></p>
<p class="p10"><span class="s2"><br>
</span></p>
<p class="p10"><span class="s1"><b>2019 19</b></span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=AdvancedSearch&amp;qid=3&amp;SID=5DtnKIc854mkvi4l9SB&amp;page=3&amp;doc=30">Generated confrontation network based mushroom phenotype image generation method, involves obtaining Wasserstein distance similarity measurement index for establishing high-quality mushroom surface type image generating model<span class="Apple-converted-space"> </span></a></span><span class="s5"> 2019</span></p>
<p class="p47"><span class="s2">Patent Number: CN110197514-A<span class="Apple-converted-space"> </span></span></p>
<p class="p47"><span class="s2">Patent Assignee: UNIV NANJING AGRIC<span class="Apple-converted-space"> </span></span></p>
<p class="p47"><span class="s2">Inventor(s): YUAN P; WU M; XU H; et al.</span></p>
<p class="p6"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtZ1Na8JAEIYXtRdvLW3pN3MopUVszUf9AFtQUezFirW1N1ljlFCNkOjBv9hf1ZnZbAz2Yg8FCbIsa_RZdmfjO-8IYZn3hfzWmlCyK6NJBY8XtsTX6NFwcZspyPKkbDiONRnp7DElh0q9_JJI_St4bEP0lEj7B_jxoNiA73EK4BUnAV53mgakX-wqDdZcmW-TiXTL42SWMNem4kN1EmqpSBzDT044-fCCqUcJW93FbK18Xp2EsID1nhSmJoUdbFxK__jERbTkbLbOBYvRKlxyhrHD0viQy1K4Y60NixLsBpIzP6n6Jg9C3fVzCl1yKvaYDTc2w9EjC4PrLUTiVVZ04PLd-4yrIquFt2LbeQw1VC832RY5hqsF1lIFXrY8smtFjHSohohxQ47p87HnLJ9cP__-lhZpDIkzYq_e7HR7eo8ukg0c6w2iT402ZOUTxjtmf19k6UZnnFV1IFKufyi-sQUS0IChgYYGBA0IGmhoQNBAQ4MENIihAUIDhgYbaHD76sM2MlDIQCGDBDLQyICQQXUug6_nBLjqA7eA5nd3JHKtZr_RztP3HpITiE9So6lcheGw1h80OsPNr2odi4y_8N0TAdK0pEEuhrbj2GMMdx2TzwElE4_q5rh0Kq53GfFst27nIruZQBciswxW7iX7e15FSH8AXyNxlg"><b>New Programming Study Findings Have Been Reported from Virginia Polytechnic Institute and State University (On distributionally robust chance constrained programs with </b><span class="s63"><b>Wasserstein</b></span><span class="s3"><b>...</b></span></a></span><span class="s4"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p47"><span class="s2">Mathematics Week, 12/2019</span></p>
<p class="p10"><span class="s4">Newsletter<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtZ1Na8JAEIYXtRdvLW3pN3MopUVszUf9AFtQUezFirW1N1ljlFCNkOjBv9hf1ZnZbAz2Yg8FCbIsa_RZdmfjO-8IYZn3hfzWmlCyK6NJBY8XtsTX6NFwcZspyPKkbDiONRnp7DElh0q9_JJI_St4bEP0lEj7B_jxoNiA73EK4BUnAV53mgakX-wqDdZcmW-TiXTL42SWMNem4kN1EmqpSBzDT044-fCCqUcJW93FbK18Xp2EsID1nhSmJoUdbFxK__jERbTkbLbOBYvRKlxyhrHD0viQy1K4Y60NixLsBpIzP6n6Jg9C3fVzCl1yKvaYDTc2w9EjC4PrLUTiVVZ04PLd-4yrIquFt2LbeQw1VC832RY5hqsF1lIFXrY8smtFjHSohohxQ47p87HnLJ9cP__-lhZpDIkzYq_e7HR7eo8ukg0c6w2iT402ZOUTxjtmf19k6UZnnFV1IFKufyi-sQUS0IChgYYGBA0IGmhoQNBAQ4MENIihAUIDhgYbaHD76sM2MlDIQCGDBDLQyICQQXUug6_nBLjqA7eA5nd3JHKtZr_RztP3HpITiE9So6lcheGw1h80OsPNr2odi4y_8N0TAdK0pEEuhrbj2GMMdx2TzwElE4_q5rh0Kq53GfFst27nIruZQBciswxW7iX7e15FSH8AXyNxlg"><span class="s13">Full Text Online</span></a><span class="Apple-converted-space"> </span></span></p>
<p class="p47"><span class="s2"><br>
</span></p>
<p class="p10"><span class="s1"><b>2019 20</b></span></p>
<p class="p6"><span class="s1"><a href="https://apps-webofknowledge-com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=1&amp;SID=7EI6YyDJo6Djz3hflt9&amp;page=2&amp;doc=29">Wasserstein distance based convolution neural network anti-transfer learning method, involves completing countermeasure migration learning of convolution neural network according to convergence criterion<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p47"><span class="s2">Patent Number: CN110414383-A<span class="Apple-converted-space"> </span></span></p>
<p class="p47"><span class="s2">Patent Assignee: UNIV HUAZHONG SCI &amp; TECHNOLOGY<span class="Apple-converted-space"> </span></span></p>
<p class="p47"><span class="s2">Inventor(s): YUAN Y; ZHOU B; CHENG C; et al.</span></p>
<table width="784.0" cellspacing="0" cellpadding="0" class="t1">
  <tbody>
    <tr>
      <td valign="middle" class="td1">
        <table cellspacing="0" cellpadding="0" class="t2">
          <tbody>
            <tr>
              <td valign="middle" class="td8">
                <p class="p47"><span class="s2">Patent Number</span></p>
              </td>
              <td valign="middle" class="td9">
                <p class="p47"><span class="s2">Publ. Date</span></p>
              </td>
              <td valign="middle" class="td4">
                <p class="p47"><span class="s2">Main IPC</span></p>
              </td>
              <td valign="middle" class="td5">
                <p class="p47"><span class="s2">Week</span></p>
              </td>
              <td valign="middle" class="td6">
                <p class="p47"><span class="s2">Page Count</span></p>
              </td>
              <td valign="middle" class="td7">
                <p class="p47"><span class="s2">Language</span></p>
              </td>
            </tr>
            <tr>
              <td valign="middle" class="td8">
                <p class="p47"><span class="s2">CN110414383-A </span></p>
              </td>
              <td valign="middle" class="td9">
                <p class="p47"><span class="s2">05 Nov 2019</span></p>
              </td>
              <td valign="middle" class="td4">
                <p class="p47"><span class="s2">G06K-009/00</span></p>
              </td>
              <td valign="middle" class="td5">
                <p class="p47"><span class="s2">201989 </span></p>
              </td>
              <td valign="middle" class="td6">
                <p class="p47"><span class="s2">Pages: 17 </span></p>
              </td>
              <td valign="middle" class="td7">
                <p class="p47"><span class="s2">Chinese </span></p>
              </td>
            </tr>
          </tbody>
        </table>
      </td>
    </tr>
  </tbody>
</table>
<p class="p10"><span class="s4"><br>
</span><span class="s1"><b>2019 21</b></span></p>
<p class="p47"><span class="s2">Open Access<span class="Apple-converted-space"> </span></span></p>
<p class="p48"><span class="s7"><a href="https://worldwide.espacenet.com/publicationDetails/biblio?FT=D&amp;date=20191105&amp;DB=EPODOC&amp;CC=CN&amp;NR=110414383A#"><b>Convolutional neural network adversarial transfer learning</b></a></span><span class="s2"><b> method based on Waserstein distance and application thereof<span class="Apple-converted-space"> </span></b></span></p>
<p class="p47"><span class="s2">by LI XINGYI; MA GUIJUN; CHENG CHENG; More...<span class="Apple-converted-space"> </span></span></p>
<p class="p47"><span class="s2">11/2019</span></p>
<p class="p47"><span class="s2">The invention relates to a convolutional neural network adversarial transfer learning method based on Waserstein distance and application thereof and the...</span></p>
<p class="p47"><span class="s2">Patent: Citation Online<span class="Apple-converted-space"> </span></span></p>
<p class="p47"><span class="s2"><br>
</span></p>
<p class="p47"><span class="s2">2019 22</span></p>
<p class="p47"><span class="s2">Open Access<span class="Apple-converted-space"> </span></span></p>
<p class="p49"><span class="s1"><a href="https://worldwide.espacenet.com/publicationDetails/biblio?FT=D&amp;date=20190806&amp;DB=EPODOC&amp;CC=CN&amp;NR=110097512A#"><b>基于</b><span class="s64"><b>Wasserstein</b></span><span class="s65"><b>生成对抗网络的三维</b></span><span class="s66"><b>MRI</b></span><span class="s65"><b>图像去噪模型的构建方法及应用</b></span><span class="s66"><b><span class="Apple-converted-space"> </span></b></span></a></span></p>
<p class="p47"><span class="s2">08/2019</span></p>
<p class="p47"><span class="s2">Patent:<span class="Apple-converted-space">  </span>Citation Online <span class="Apple-converted-space"> </span></span></p>
<p class="p48"><span class="s2"><b>Construction method and application of three-dimensional MRI image denoising model based on Wasserstein generative adversarial network  <span class="Apple-converted-space"> </span></b></span></p>
<p class="p47"><span class="s2">[Chinese<span class="Apple-converted-space">  </span>Construction method and application of 3D MRI image denoising model based on Wasserstein generative adversarial network]</span></p>
<p class="p47"><span class="s2"><br>
</span></p>
<p class="p47"><span class="s2">2019 23</span></p>
<p class="p46"><span class="s1"><a href="http://faculty.csu.edu.cn/dengxiaoheng/en/zlcg/10456/content/3827.htm"><b>一种基于</b><span class="s3"><b>WGAN-GP</b></span><span class="s57"><b>和过采样的不平衡学习方法</b></span><span class="s3"><b> - </b></span><span class="s57"><b>中南大学教师</b></span><span class="s3"><b> ...</b></span></a></span></p>
<p class="p6"><span class="s1"><a href="http://faculty.csu.edu.cn/dengxiaoheng/en/zlcg/10456/content/3827.htm"><i>faculty.csu.edu.cn › dengxiaoheng › zlcg › content</i><span class="s3"><i></i></span></a></span></p>
<p class="p6"><span class="s1"><a href="https://translate.google.com/translate?hl=en&amp;sl=zh-CN&amp;u=http://faculty.csu.edu.cn/dengxiaoheng/en/zlcg/10456/content/3827.htm&amp;prev=search">Translate this page<span class="s3"></span></a></span></p>
<p class="p47"><span class="s2">An imbalanced learning method based on <i>WGAN</i>-<i>GP</i> and oversampling. Click</span><span class="s11">：</span><span class="s2">. Application no</span><span class="s11">：</span><span class="s2"> ... <i>Patent</i> Inventor</span><span class="s11">：邓晓衡、黄戎、沈海澜</span><span class="s2">. Open date</span><span class="s11">：</span><span class="s2">2019-05-28.</span></p>
<p class="p50"><span class="s2"><b>一种基于</b></span><span class="s62"><b>WGAN</b></span><span class="s9"><b>-GP</b></span><span class="s2"><b>和过采样的不平衡学习方法</b></span><span class="s9"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p47"><span class="s2">05/2019</span></p>
<p class="p50"><span class="s2">本发明公开了一种基于</span><span class="s9">WGAN-GP</span><span class="s2">和过采样的不平衡学习方法，包括：生成器网络，由三层全连接网络组成并且每</span></p>
<p class="p50"><span class="s2"><br>
</span></p>
<p class="p47"><span class="s2">2019 24</span></p>
<p class="p46"><span class="s1"><a href="http://faculty.csu.edu.cn/dengxiaoheng/en/zlcg/10456/content/3827.htm"><b>一种基于</b><span class="s3"><b>WGAN-GP</b></span><span class="s57"><b>和过采样的不平衡学习方法</b></span><span class="s3"><b> - </b></span><span class="s57"><b>中南大学教师</b></span><span class="s3"><b> ...</b></span></a></span></p>
<p class="p6"><span class="s1"><a href="http://faculty.csu.edu.cn/dengxiaoheng/en/zlcg/10456/content/3827.htm"><i>faculty.csu.edu.cn › dengxiaoheng › zlcg › content</i><span class="s3"><i></i></span></a></span></p>
<p class="p6"><span class="s1"><a href="https://translate.google.com/translate?hl=en&amp;sl=zh-CN&amp;u=http://faculty.csu.edu.cn/dengxiaoheng/en/zlcg/10456/content/3827.htm&amp;prev=search">Translate this page<span class="s3"></span></a></span></p>
<p class="p47"><span class="s2">An imbalanced learning method based on <i>WGAN</i>-<i>GP</i> and oversampling. Click</span><span class="s11">：</span><span class="s2">. Application no</span><span class="s11">：</span><span class="s2"> ... <i>Patent</i> Inventor</span><span class="s11">：邓晓衡、黄戎、沈海澜</span><span class="s2">. Open date</span><span class="s11">：</span><span class="s2">2019-05-28.</span></p>
<p class="p50"><span class="s2"><b>一种基于</b></span><span class="s62"><b>WGAN</b></span><span class="s9"><b>-GP</b></span><span class="s2"><b>和过采样的不平衡学习方法</b></span><span class="s9"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p47"><span class="s2">05/2019</span></p>
<p class="p50"><span class="s2">本发明公开了一种基于</span><span class="s9">WGAN-GP</span><span class="s2">和过采样的不平衡学习方法，包括：生成器网络，由三层全连接网络组成并且每一层的输出都应用了</span><span class="s9">Batch...</span></p>
<p class="p47"><span class="s2">Patent: Citation Online<span class="Apple-converted-space"> </span></span></p>
<p class="p47"><span class="s2"><br>
</span></p>
<p class="p47"><span class="s2">2019 25</span></p>
<p class="p47"><span class="s2">Open Access<span class="Apple-converted-space"> </span></span></p>
<p class="p51"><span class="s7"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwY2AwNtIz0EUrE9JSLdIMTBMNjdISEw1M05INzBITzQxTE4EpwtzSEnydCvJyqCzY1hjwsaHl4LMSgRksGZj9S8DFdwFiTMsFvNSyWD8pEyiUb-8WYuuiBu0sAys7YOtCzcXJ1jXA38XfWc3Z2dbZT80vyBZ0iJKFJbC15MjMwArsRIBneF3DnECbVArykQtjN0EGtgCgcXklQgxMVRnCDJzOsJvYhBk4fKET4MIM7OAVm8nFQEForiwWYXB8On_Xk119T3u7ns-e-HzuYpvcxKJsu3B3Rz8bfTBT1z3g-ayWl6tnPG3tfLFh49PZ-5429z_taHu-cfezaTufbZ4qyqDo5hri7KELdFY8PAzinf0QPjASY2DJy89LlWBQsDQyMkhOTE0yMEo1MDFJsbRISUsE5slUYxPTJGNjszRJBinc5kjhk5Rm4AKFJ3gzt5kMA2saMHOkyoJPWpQDhxwAIgmcWA"><b>基于半监督</b><span class="s67"><b>WGAN</b></span><span class="s68"><b>-GP的高光谱图像分类方法</b></span></a></span><span class="s69"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p47"><span class="s2">02/2019</span></p>
<p class="p10"><span class="s4">Patent<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwY2AwNtIz0EUrE9JSLdIMTBMNjdISEw1M05INzBITzQxTE4EpwtzSEnydCvJyqCzY1hjwsaHl4LMSgRksGZj9S8DFdwFiTMsFvNSyWD8pEyiUb-8WYuuiBu0sAys7YOtCzcXJ1jXA38XfWc3Z2dbZT80vyBZ0iJKFJbC15MjMwArsRIBneF3DnECbVArykQtjN0EGtgCgcXklQgxMVRnCDJzOsJvYhBk4fKET4MIM7OAVm8nFQEForiwWYXB8On_Xk119T3u7ns-e-HzuYpvcxKJsu3B3Rz8bfTBT1z3g-ayWl6tnPG3tfLFh49PZ-5429z_taHu-cfezaTufbZ4qyqDo5hri7KELdFY8PAzinf0QPjASY2DJy89LlWBQsDQyMkhOTE0yMEo1MDFJsbRISUsE5slUYxPTJGNjszRJBinc5kjhk5Rm4AKFJ3gzt5kMA2saMHOkyoJPWpQDhxwAIgmcWA"><span class="s13">Citation Online</span></a><span class="Apple-converted-space"> </span></span></p>
<p class="p47"><span class="s2">[Chinese<span class="Apple-converted-space">  </span>Hyperspectral image classification method based on semi-supervised WGAN-GP]</span></p>
<p class="p52"><span class="s7"><a href="https://patents.google.com/patent/CN109389080A/zh?q=%E5%9F%BA%E4%BA%8E%E5%8D%8A%E7%9B%91%E7%9D%A3+WGAN-GP+%E7%9A%84%E9%AB%98%E5%85%89%E8%B0%B1%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%96%B9%E6%B3%95&amp;oq=%E5%9F%BA%E4%BA%8E%E5%8D%8A%E7%9B%91%E7%9D%A3WGAN-GP%E7%9A%84%E9%AB%98%E5%85%89%E8%B0%B1%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%96%B9%E6%B3%95+"><b>基于半监督</b><span class="s68"><b>wgan-gp的高光谱图像分类方法</b></span></a></span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2019 26</span></p>
<p class="p5"><span class="s2">Open Access<span class="Apple-converted-space"> </span></span></p>
<p class="p53"><span class="s70"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwY2AwNtIz0EUrE9JSLdIMTBMNjdISEw1M05INzBITzQxTE4EpwtzSEnydCvJyqCzY1hjwsaHl4LMSgRksGZj9S8DFdwFiTMsFvNSyWD8pEyiUb-8WYuuiBu0sAys7YOtCzcXJ1jXA38XfWc3Z2dbZT80vyBZ0iJKFJbC15MjMwArsRIBneF3DnECbVArykQtjN0EGtgCgcXklQgxMVRnCDJzOsJvYhBk4fKET4MIM7OAVm8nFQEForiwWYXB8On_Xk119T3u7ns-e-HzuYpvcxKJsu3B3Rz8bfTBT1z3g-ayWl6tnPG3tfLFh49PZ-5429z_taHu-cfezaTufbZ4qyqDo5hri7KELdFY8PAzinf0QPjASY2DJy89LlWBQsDQyMkhOTE0yMEo1MDFJsbRISUsE5slUYxPTJGNjszRJBinc5kjhk5Rm4AKFJ3gzt5kMA2saMHOkyoJPWpQDhxwAIgmcWA"><b>基于半监督</b><span class="s71"><b>WGAN</b></span><span class="s72"><b>-GP</b></span><span class="s42"><b>的高光谱图像分类方法</b></span></a></span><span class="s73"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2">02/2019</span></p>
<p class="p10"><span class="s12">Patent<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwY2AwNtIz0EUrE9JSLdIMTBMNjdISEw1M05INzBITzQxTE4EpwtzSEnydCvJyqCzY1hjwsaHl4LMSgRksGZj9S8DFdwFiTMsFvNSyWD8pEyiUb-8WYuuiBu0sAys7YOtCzcXJ1jXA38XfWc3Z2dbZT80vyBZ0iJKFJbC15MjMwArsRIBneF3DnECbVArykQtjN0EGtgCgcXklQgxMVRnCDJzOsJvYhBk4fKET4MIM7OAVm8nFQEForiwWYXB8On_Xk119T3u7ns-e-HzuYpvcxKJsu3B3Rz8bfTBT1z3g-ayWl6tnPG3tfLFh49PZ-5429z_taHu-cfezaTufbZ4qyqDo5hri7KELdFY8PAzinf0QPjASY2DJy89LlWBQsDQyMkhOTE0yMEo1MDFJsbRISUsE5slUYxPTJGNjszRJBinc5kjhk5Rm4AKFJ3gzt5kMA2saMHOkyoJPWpQDhxwAIgmcWA"><span class="s13">Citation Online</span></a><span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">[Chinese<span class="Apple-converted-space">  </span>Hyperspectral image classification method based on semi-supervised WGAN-GP]</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2019 27</span></p>
<p class="p5"><span class="s2">Open Access<span class="Apple-converted-space"> </span></span></p>
<p class="p8"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwfV1ZS8NAEB7Uer1pVLQerC95q81hmgQaJd0kCmJapOhj2RyLB6bFFgR_vbNjakXQt2QDy2bYb2Zn99tvAGzrzGj98gmy9KThCNOSQhiOzI2OEB2zFDgjXN-ncio_6VDP86sxJBv6TlqJCLAc4T8j9z1Z7GlFRLWctrMnbBpfJsMg0utkGYOdAmTUC-JBP-pznfOAp3p6FygRJQdX-m64DA1MIuiEN77vqUsqExVh_NrBJluwOsDeqtk2LH08arDB54XYNFi_rc-_NVgjwmY-xcYalNMduAmZLEmfk6H7EpQAqyEzxSivZxb7qhTNVNAqGL53X8Xby8XDVZh22_TIqCbOLpwm8ZBft3B8o29jjHi6-BVrD1aqcVXuAzOs3DOFpzY4s_PMLjJctjm-V3iltG3HNQ6g-Xc_zf8-HsKmMqwiLpv-ETQkoqQ8JsnFEzLhJ8qYkR4"><b>A feature recalibration convolution method based on </b><span class="s74"><b>WGAN</b></span><span class="s61"><b> model</b></span></a></span><span class="s4"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2">by LI LIJUN; ZHOU ZHIHENG<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">02/2019</span></p>
<p class="p5"><span class="s2">The invention discloses a feature recalibration convolution method based on a WGAN model, and belongsto the field of depth learning neural network. The method...</span></p>
<p class="p9"><span class="s4">Patent<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwfV1ZS8NAEB7Uer1pVLQerC95q81hmgQaJd0kCmJapOhj2RyLB6bFFgR_vbNjakXQt2QDy2bYb2Zn99tvAGzrzGj98gmy9KThCNOSQhiOzI2OEB2zFDgjXN-ncio_6VDP86sxJBv6TlqJCLAc4T8j9z1Z7GlFRLWctrMnbBpfJsMg0utkGYOdAmTUC-JBP-pznfOAp3p6FygRJQdX-m64DA1MIuiEN77vqUsqExVh_NrBJluwOsDeqtk2LH08arDB54XYNFi_rc-_NVgjwmY-xcYalNMduAmZLEmfk6H7EpQAqyEzxSivZxb7qhTNVNAqGL53X8Xby8XDVZh22_TIqCbOLpwm8ZBft3B8o29jjHi6-BVrD1aqcVXuAzOs3DOFpzY4s_PMLjJctjm-V3iltG3HNQ6g-Xc_zf8-HsKmMqwiLpv-ETQkoqQ8JsnFEzLhJ8qYkR4"><span class="s5">Citation Online</span></a><span class="Apple-converted-space"> </span></span></p>
<p class="p8"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV1LT8JAEN74uBgvGDU-k7nopYLLAoUmaILEBwcNiRi9kaXdGiMUQpGzP92Z2dIWT3jwsmm3TbP9djoznZ2dT4iKKsniL50QmkYoa7qsQq1lLfSlq7VbNholou55TKeSS4dKCfayvn-deOzDqaeNtH-Y_PSh2IHHKALYohBgu5IYUOKFwzx5liqbY-mkLka0YtBFTzOaWVfUz9IOtUOeIS0toFep-Y-ar7XH0TwZrfPI1NPODVrBgFYcXu9bT8ysNsz7u5ZSwOl0WZtS-AH_-3UwSErEcvLt0CpbTkdfjCi_-4ICEkouIqyJCDHFiMO1tfD2NLjndOezUpqqtFT3-q1TX-609XhdNLC0UVedUxX0UfDhz65MVHx5XhfrymskNnSbjObCcvYKokADnOiJmULLgr4j1ky0K74JcGDAgQEHAhwSwMG-HuQABwQcNCSAwxLgkAMcLODAgAOeN0d6-nlNsDcv-RAY_T1xcXfbaz8Uadj9hGMUm5iiMPG7_orjfvbScl9sROPIHAjwlJK-NgOpjKxWA68RhBo1ralUa4NKxQ0PxdlKjzxa8b5jsZXN64nYDPFbMKdcVfMHlGtDpA"><b>Univ South China Tech Submits Patent Application for a Feature Recalibration Convolution Method Based on </b><span class="s74"><b>WGAN</b></span><span class="s61"><b> Model</b></span></a></span><span class="s4"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2">Global IP News: Broadband and Wireless Network Patent News, Aug 31, 2020</span></p>
<p class="p5"><span class="s2">Newspaper Article<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV1LT8JAEN74uBgvGDU-k7nopYLLAoUmaILEBwcNiRi9kaXdGiMUQpGzP92Z2dIWT3jwsmm3TbP9djoznZ2dT4iKKsniL50QmkYoa7qsQq1lLfSlq7VbNholou55TKeSS4dKCfayvn-deOzDqaeNtH-Y_PSh2IHHKALYohBgu5IYUOKFwzx5liqbY-mkLka0YtBFTzOaWVfUz9IOtUOeIS0toFep-Y-ar7XH0TwZrfPI1NPODVrBgFYcXu9bT8ysNsz7u5ZSwOl0WZtS-AH_-3UwSErEcvLt0CpbTkdfjCi_-4ICEkouIqyJCDHFiMO1tfD2NLjndOezUpqqtFT3-q1TX-609XhdNLC0UVedUxX0UfDhz65MVHx5XhfrymskNnSbjObCcvYKokADnOiJmULLgr4j1ky0K74JcGDAgQEHAhwSwMG-HuQABwQcNCSAwxLgkAMcLODAgAOeN0d6-nlNsDcv-RAY_T1xcXfbaz8Uadj9hGMUm5iiMPG7_orjfvbScl9sROPIHAjwlJK-NgOpjKxWA68RhBo1ralUa4NKxQ0PxdlKjzxa8b5jsZXN64nYDPFbMKdcVfMHlGtDpA"><span class="s8">Citation Online</span></a><span class="Apple-converted-space"> </span></span></p>
<p class="p8"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrZ1LS8NAEMcHrRdPVlR8VebgtXbz2DygKrVYvSgVBMFLmSS7INqkTVsPnvzo7qwNVSl68ZawEDLs5D-zs5v5AXjuiWj-0AStIi0kOa4mElKnIiAKHEXGI8I4tjiVr8eh7qpfY-bTXamkle6sSLlq3nIZ3C09PwrOR-Mmc6R4v7WCatActpCdOp4jo1VY415n_On25eMS4eVw0tuA6viUeiMLLFyyav3ervFf37IOdda2EY1UiZ1P19mEFZVvwTsf1EDL1UOL1kauvaORl-HTdIJ9k5nmU-wsdr3RJL1IyJnkrFRoslCyttixbpG_zl0bbyyqGi9M1MzQ3LeHVD6fPVx1btste4mMZXvZhuPe5X33ulmZOeBmytrE2MlgYaS3A7W8yNUuYOb7gpwk1CkJPxFxov1QxSS9NAmjIJV70Pj1Uft_jB_AusuLX1vgPYTatJyphu39eGQn-QPCO8og"><b>Univ South China Tech Submits Patent Application for a Feature Recalibration Convolution Method Based on </b><span class="s74"><b>WGAN</b></span><span class="s61"><b> Model</b></span></a></span><span class="s4"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p54"><span class="s2"><br>
</span></p>
<p class="p54"><span class="s2"><b>2019 28</b></span></p>
<p class="p5"><span class="s2">Open Access<span class="Apple-converted-space"> </span></span></p>
<p class="p55"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwfV1ZS8NAEB7Uer1pVLQerC95q81hmgQaJd0kCmJapOhj2RyLB6bFFgR_vbNjakXQt2QDy2bYb2Zn99tvAGzrzGj98gmy9KThCNOSQhiOzI2OEB2zFDgjXN-ncio_6VDP86sxJBv6TlqJCLAc4T8j9z1Z7GlFRLWctrMnbBpfJsMg0utkGYOdAmTUC-JBP-pznfOAp3p6FygRJQdX-m64DA1MIuiEN77vqUsqExVh_NrBJluwOsDeqtk2LH08arDB54XYNFi_rc-_NVgjwmY-xcYalNMduAmZLEmfk6H7EpQAqyEzxSivZxb7qhTNVNAqGL53X8Xby8XDVZh22_TIqCbOLpwm8ZBft3B8o29jjHi6-BVrD1aqcVXuAzOs3DOFpzY4s_PMLjJctjm-V3iltG3HNQ6g-Xc_zf8-HsKmMqwiLpv-ETQkoqQ8JsnFEzLhJ8qYkR4"><b>A feature recalibration convolution method based on </b><span class="s71"><b>WGAN</b></span><span class="s72"><b> model</b></span></a></span><span class="s4"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2">by LI LIJUN; ZHOU ZHIHENG<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">02/2019</span></p>
<p class="p5"><span class="s2">The invention discloses a feature recalibration convolution method based on a WGAN model, and belongsto the field of depth learning neural network. The method...</span></p>
<p class="p9"><span class="s4">Patent<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwfV1ZS8NAEB7Uer1pVLQerC95q81hmgQaJd0kCmJapOhj2RyLB6bFFgR_vbNjakXQt2QDy2bYb2Zn99tvAGzrzGj98gmy9KThCNOSQhiOzI2OEB2zFDgjXN-ncio_6VDP86sxJBv6TlqJCLAc4T8j9z1Z7GlFRLWctrMnbBpfJsMg0utkGYOdAmTUC-JBP-pznfOAp3p6FygRJQdX-m64DA1MIuiEN77vqUsqExVh_NrBJluwOsDeqtk2LH08arDB54XYNFi_rc-_NVgjwmY-xcYalNMduAmZLEmfk6H7EpQAqyEzxSivZxb7qhTNVNAqGL53X8Xby8XDVZh22_TIqCbOLpwm8ZBft3B8o29jjHi6-BVrD1aqcVXuAzOs3DOFpzY4s_PMLjJctjm-V3iltG3HNQ6g-Xc_zf8-HsKmMqwiLpv-ETQkoqQ8JsnFEzLhJ8qYkR4"><span class="s5">Citation Online</span></a><span class="Apple-converted-space"> </span></span></p>
<p class="p56"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV1LT8JAEN74uBgvGDU-k7nopYLLAoUmaILEBwcNiRi9kaXdGiMUQpGzP92Z2dIWT3jwsmm3TbP9djoznZ2dT4iKKsniL50QmkYoa7qsQq1lLfSlq7VbNholou55TKeSS4dKCfayvn-deOzDqaeNtH-Y_PSh2IHHKALYohBgu5IYUOKFwzx5liqbY-mkLka0YtBFTzOaWVfUz9IOtUOeIS0toFep-Y-ar7XH0TwZrfPI1NPODVrBgFYcXu9bT8ysNsz7u5ZSwOl0WZtS-AH_-3UwSErEcvLt0CpbTkdfjCi_-4ICEkouIqyJCDHFiMO1tfD2NLjndOezUpqqtFT3-q1TX-609XhdNLC0UVedUxX0UfDhz65MVHx5XhfrymskNnSbjObCcvYKokADnOiJmULLgr4j1ky0K74JcGDAgQEHAhwSwMG-HuQABwQcNCSAwxLgkAMcLODAgAOeN0d6-nlNsDcv-RAY_T1xcXfbaz8Uadj9hGMUm5iiMPG7_orjfvbScl9sROPIHAjwlJK-NgOpjKxWA68RhBo1ralUa4NKxQ0PxdlKjzxa8b5jsZXN64nYDPFbMKdcVfMHlGtDpA"><b>Univ South China Tech Submits Patent Application for a Feature Recalibration Convolution Method Based on </b><span class="s75"><b>WGAN</b></span><span class="s76"><b> Model</b></span></a></span><span class="s4"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2">Global IP News: Broadband and Wireless Network Patent News, Aug 31, 2020</span></p>
<p class="p5"><span class="s2">Newspaper Article<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV1LT8JAEN74uBgvGDU-k7nopYLLAoUmaILEBwcNiRi9kaXdGiMUQpGzP92Z2dIWT3jwsmm3TbP9djoznZ2dT4iKKsniL50QmkYoa7qsQq1lLfSlq7VbNholou55TKeSS4dKCfayvn-deOzDqaeNtH-Y_PSh2IHHKALYohBgu5IYUOKFwzx5liqbY-mkLka0YtBFTzOaWVfUz9IOtUOeIS0toFep-Y-ar7XH0TwZrfPI1NPODVrBgFYcXu9bT8ysNsz7u5ZSwOl0WZtS-AH_-3UwSErEcvLt0CpbTkdfjCi_-4ICEkouIqyJCDHFiMO1tfD2NLjndOezUpqqtFT3-q1TX-609XhdNLC0UVedUxX0UfDhz65MVHx5XhfrymskNnSbjObCcvYKokADnOiJmULLgr4j1ky0K74JcGDAgQEHAhwSwMG-HuQABwQcNCSAwxLgkAMcLODAgAOeN0d6-nlNsDcv-RAY_T1xcXfbaz8Uadj9hGMUm5iiMPG7_orjfvbScl9sROPIHAjwlJK-NgOpjKxWA68RhBo1ralUa4NKxQ0PxdlKjzxa8b5jsZXN64nYDPFbMKdcVfMHlGtDpA"><span class="s8">Citation Online</span></a><span class="Apple-converted-space"> </span></span></p>
<p class="p56"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrZ1LS8NAEMcHrRdPVlR8VebgtXbz2DygKrVYvSgVBMFLmSS7INqkTVsPnvzo7qwNVSl68ZawEDLs5D-zs5v5AXjuiWj-0AStIi0kOa4mElKnIiAKHEXGI8I4tjiVr8eh7qpfY-bTXamkle6sSLlq3nIZ3C09PwrOR-Mmc6R4v7WCatActpCdOp4jo1VY415n_On25eMS4eVw0tuA6viUeiMLLFyyav3ervFf37IOdda2EY1UiZ1P19mEFZVvwTsf1EDL1UOL1kauvaORl-HTdIJ9k5nmU-wsdr3RJL1IyJnkrFRoslCyttixbpG_zl0bbyyqGi9M1MzQ3LeHVD6fPVx1btste4mMZXvZhuPe5X33ulmZOeBmytrE2MlgYaS3A7W8yNUuYOb7gpwk1CkJPxFxov1QxSS9NAmjIJV70Pj1Uft_jB_AusuLX1vgPYTatJyphu39eGQn-QPCO8og"><b>Univ South China Tech Submits Patent Application for a Feature Recalibration Convolution Method Based on </b><span class="s75"><b>WGAN</b></span><span class="s76"><b> Model</b></span></a></span><span class="s73"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2">Global IP News. Broadband and Wireless Network News, Aug 31, 2020</span></p>
<p class="p5"><span class="s2">Newspaper Article<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrZ1LS8NAEMcHrRdPVlR8VebgtXbz2DygKrVYvSgVBMFLmSS7INqkTVsPnvzo7qwNVSl68ZawEDLs5D-zs5v5AXjuiWj-0AStIi0kOa4mElKnIiAKHEXGI8I4tjiVr8eh7qpfY-bTXamkle6sSLlq3nIZ3C09PwrOR-Mmc6R4v7WCatActpCdOp4jo1VY415n_On25eMS4eVw0tuA6viUeiMLLFyyav3ervFf37IOdda2EY1UiZ1P19mEFZVvwTsf1EDL1UOL1kauvaORl-HTdIJ9k5nmU-wsdr3RJL1IyJnkrFRoslCyttixbpG_zl0bbyyqGi9M1MzQ3LeHVD6fPVx1btste4mMZXvZhuPe5X33ulmZOeBmytrE2MlgYaS3A7W8yNUuYOb7gpwk1CkJPxFxov1QxSS9NAmjIJV70Pj1Uft_jB_AusuLX1vgPYTatJyphu39eGQn-QPCO8og"><span class="s8">Full Text Online</span></a> <br>
</span></p>
<p class="p5"><span class="s2">2019 29</span></p>
<p class="p5"><span class="s2">Open Access<span class="Apple-converted-space"> </span></span></p>
<p class="p55"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwfV1ZS8NAEB7Uer1pVLQerC95q81hmgQaJd0kCmJapOhj2RyLB6bFFgR_vbNjakXQt2QDy2bYb2Zn99tvAGzrzGj98gmy9KThCNOSQhiOzI2OEB2zFDgjXN-ncio_6VDP86sxJBv6TlqJCLAc4T8j9z1Z7GlFRLWctrMnbBpfJsMg0utkGYOdAmTUC-JBP-pznfOAp3p6FygRJQdX-m64DA1MIuiEN77vqUsqExVh_NrBJluwOsDeqtk2LH08arDB54XYNFi_rc-_NVgjwmY-xcYalNMduAmZLEmfk6H7EpQAqyEzxSivZxb7qhTNVNAqGL53X8Xby8XDVZh22_TIqCbOLpwm8ZBft3B8o29jjHi6-BVrD1aqcVXuAzOs3DOFpzY4s_PMLjJctjm-V3iltG3HNQ6g-Xc_zf8-HsKmMqwiLpv-ETQkoqQ8JsnFEzLhJ8qYkR4"><b>A feature recalibration convolution method based on </b><span class="s71"><b>WGAN</b></span><span class="s72"><b> model</b></span></a></span><span class="s4"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2">by LI LIJUN; ZHOU ZHIHENG<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">02/2019</span></p>
<p class="p5"><span class="s2">The invention discloses a feature recalibration convolution method based on a WGAN model, and belongsto the field of depth learning neural network. The method...</span></p>
<p class="p9"><span class="s4">Patent<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwfV1ZS8NAEB7Uer1pVLQerC95q81hmgQaJd0kCmJapOhj2RyLB6bFFgR_vbNjakXQt2QDy2bYb2Zn99tvAGzrzGj98gmy9KThCNOSQhiOzI2OEB2zFDgjXN-ncio_6VDP86sxJBv6TlqJCLAc4T8j9z1Z7GlFRLWctrMnbBpfJsMg0utkGYOdAmTUC-JBP-pznfOAp3p6FygRJQdX-m64DA1MIuiEN77vqUsqExVh_NrBJluwOsDeqtk2LH08arDB54XYNFi_rc-_NVgjwmY-xcYalNMduAmZLEmfk6H7EpQAqyEzxSivZxb7qhTNVNAqGL53X8Xby8XDVZh22_TIqCbOLpwm8ZBft3B8o29jjHi6-BVrD1aqcVXuAzOs3DOFpzY4s_PMLjJctjm-V3iltG3HNQ6g-Xc_zf8-HsKmMqwiLpv-ETQkoqQ8JsnFEzLhJ8qYkR4"><span class="s5">Citation Online</span></a><span class="Apple-converted-space"> </span></span></p>
<p class="p56"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV1LT8JAEN74uBgvGDU-k7nopYLLAoUmaILEBwcNiRi9kaXdGiMUQpGzP92Z2dIWT3jwsmm3TbP9djoznZ2dT4iKKsniL50QmkYoa7qsQq1lLfSlq7VbNholou55TKeSS4dKCfayvn-deOzDqaeNtH-Y_PSh2IHHKALYohBgu5IYUOKFwzx5liqbY-mkLka0YtBFTzOaWVfUz9IOtUOeIS0toFep-Y-ar7XH0TwZrfPI1NPODVrBgFYcXu9bT8ysNsz7u5ZSwOl0WZtS-AH_-3UwSErEcvLt0CpbTkdfjCi_-4ICEkouIqyJCDHFiMO1tfD2NLjndOezUpqqtFT3-q1TX-609XhdNLC0UVedUxX0UfDhz65MVHx5XhfrymskNnSbjObCcvYKokADnOiJmULLgr4j1ky0K74JcGDAgQEHAhwSwMG-HuQABwQcNCSAwxLgkAMcLODAgAOeN0d6-nlNsDcv-RAY_T1xcXfbaz8Uadj9hGMUm5iiMPG7_orjfvbScl9sROPIHAjwlJK-NgOpjKxWA68RhBo1ralUa4NKxQ0PxdlKjzxa8b5jsZXN64nYDPFbMKdcVfMHlGtDpA"><b>Univ South China Tech Submits Patent Application for a Feature Recalibration Convolution Method Based on </b><span class="s75"><b>WGAN</b></span><span class="s76"><b> Model</b></span></a></span><span class="s4"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2">Global IP News: Broadband and Wireless Network Patent News, Aug 31, 2020</span></p>
<p class="p5"><span class="s2">Newspaper Article<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV1LT8JAEN74uBgvGDU-k7nopYLLAoUmaILEBwcNiRi9kaXdGiMUQpGzP92Z2dIWT3jwsmm3TbP9djoznZ2dT4iKKsniL50QmkYoa7qsQq1lLfSlq7VbNholou55TKeSS4dKCfayvn-deOzDqaeNtH-Y_PSh2IHHKALYohBgu5IYUOKFwzx5liqbY-mkLka0YtBFTzOaWVfUz9IOtUOeIS0toFep-Y-ar7XH0TwZrfPI1NPODVrBgFYcXu9bT8ysNsz7u5ZSwOl0WZtS-AH_-3UwSErEcvLt0CpbTkdfjCi_-4ICEkouIqyJCDHFiMO1tfD2NLjndOezUpqqtFT3-q1TX-609XhdNLC0UVedUxX0UfDhz65MVHx5XhfrymskNnSbjObCcvYKokADnOiJmULLgr4j1ky0K74JcGDAgQEHAhwSwMG-HuQABwQcNCSAwxLgkAMcLODAgAOeN0d6-nlNsDcv-RAY_T1xcXfbaz8Uadj9hGMUm5iiMPG7_orjfvbScl9sROPIHAjwlJK-NgOpjKxWA68RhBo1ralUa4NKxQ0PxdlKjzxa8b5jsZXN64nYDPFbMKdcVfMHlGtDpA"><span class="s8">Citation Online</span></a><span class="Apple-converted-space"> </span></span></p>
<p class="p56"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrZ1LS8NAEMcHrRdPVlR8VebgtXbz2DygKrVYvSgVBMFLmSS7INqkTVsPnvzo7qwNVSl68ZawEDLs5D-zs5v5AXjuiWj-0AStIi0kOa4mElKnIiAKHEXGI8I4tjiVr8eh7qpfY-bTXamkle6sSLlq3nIZ3C09PwrOR-Mmc6R4v7WCatActpCdOp4jo1VY415n_On25eMS4eVw0tuA6viUeiMLLFyyav3ervFf37IOdda2EY1UiZ1P19mEFZVvwTsf1EDL1UOL1kauvaORl-HTdIJ9k5nmU-wsdr3RJL1IyJnkrFRoslCyttixbpG_zl0bbyyqGi9M1MzQ3LeHVD6fPVx1btste4mMZXvZhuPe5X33ulmZOeBmytrE2MlgYaS3A7W8yNUuYOb7gpwk1CkJPxFxov1QxSS9NAmjIJV70Pj1Uft_jB_AusuLX1vgPYTatJyphu39eGQn-QPCO8og"><b>Univ South China Tech Submits Patent Application for a Feature Recalibration Convolution Method Based on </b><span class="s75"><b>WGAN</b></span><span class="s76"><b> Model</b></span></a></span><span class="s73"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2">Global IP News. Broadband and Wireless Network News, Aug 31, 2020</span></p>
<p class="p5"><span class="s2">Newspaper Article<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrZ1LS8NAEMcHrRdPVlR8VebgtXbz2DygKrVYvSgVBMFLmSS7INqkTVsPnvzo7qwNVSl68ZawEDLs5D-zs5v5AXjuiWj-0AStIi0kOa4mElKnIiAKHEXGI8I4tjiVr8eh7qpfY-bTXamkle6sSLlq3nIZ3C09PwrOR-Mmc6R4v7WCatActpCdOp4jo1VY415n_On25eMS4eVw0tuA6viUeiMLLFyyav3ervFf37IOdda2EY1UiZ1P19mEFZVvwTsf1EDL1UOL1kauvaORl-HTdIJ9k5nmU-wsdr3RJL1IyJnkrFRoslCyttixbpG_zl0bbyyqGi9M1MzQ3LeHVD6fPVx1btste4mMZXvZhuPe5X33ulmZOeBmytrE2MlgYaS3A7W8yNUuYOb7gpwk1CkJPxFxov1QxSS9NAmjIJV70Pj1Uft_jB_AusuLX1vgPYTatJyphu39eGQn-QPCO8og"><span class="s8">Full Text Online</span></a> <br>
</span></p>
<p class="p5"><span class="s2">2019 30</span></p>
<p class="p5"><span class="s2">Open Access<span class="Apple-converted-space"> </span></span></p>
<p class="p9"><span class="s7"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwY2AwNtIz0EUrE9JSLdIMTBMNjdISEw1M05INzBITzQxTE4EpwtzSEnydCvJyqCzY1hjwsaHl4LMSgRksGZj9S8DFdwFiTMsFvNSyWD8pEyiUb-8WYuuiBu0sgyo7YFfZxcnWNcDfxd9ZzdnZ1tlPzS_IFnQcphGw9jVyZGZgBXYiwDO8rmFOoE0qBcAaBlgQQ0tYN0EGtgCgcXklQgxMVRnCDJzOsJvYhBk4fKET4EAmNC8WizAEukDvNgHm0RwFm9zEomy7cHdHPxt9MFMBVD-lKORBlnkrFEPvqVMoziyBnO6tUFAEMhbMhNwjLcqg6OYa4uyhC3RcPDwk4p39EP4wEmNgycvPS5VgUDAwSrYwTLQAjW4mmSQZpyQB22ymlhYpFqlpxsam5gaSDFK4zZHCJynNwAUKVcgQhAwDaxowi6TKgs9blAOHHwCR3ZDy"><b>Differential </b><span class="s77"><b>WGAN</b></span><span class="s5"><b> based network security situation prediction method</b></span></a></span><span class="s4"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2">by ZHU JIANG; WANG TINGTING; WANG YONG<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">01/2019</span></p>
<p class="p5"><span class="s2">The invention provides a differential WGAN based network security situation prediction method. The GAN (Generative adversarial network) is used to simulate the...</span></p>
<p class="p9"><span class="s4">Patent<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwY2AwNtIz0EUrE9JSLdIMTBMNjdISEw1M05INzBITzQxTE4EpwtzSEnydCvJyqCzY1hjwsaHl4LMSgRksGZj9S8DFdwFiTMsFvNSyWD8pEyiUb-8WYuuiBu0sgyo7YFfZxcnWNcDfxd9ZzdnZ1tlPzS_IFnQcphGw9jVyZGZgBXYiwDO8rmFOoE0qBcAaBlgQQ0tYN0EGtgCgcXklQgxMVRnCDJzOsJvYhBk4fKET4EAmNC8WizAEukDvNgHm0RwFm9zEomy7cHdHPxt9MFMBVD-lKORBlnkrFEPvqVMoziyBnO6tUFAEMhbMhNwjLcqg6OYa4uyhC3RcPDwk4p39EP4wEmNgycvPS5VgUDAwSrYwTLQAjW4mmSQZpyQB22ymlhYpFqlpxsam5gaSDFK4zZHCJynNwAUKVcgQhAwDaxowi6TKgs9blAOHHwCR3ZDy"><span class="s5">Citation Online</span></a><span class="Apple-converted-space"> </span></span></p>
<p class="p8"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrZ3PS8MwFMeDzosnJyr-mryDeKtL1mZtYSpzOrwolQ0EL-O1Tabo2q6dF_8P_1-TrGVORC_eAoXSkPT7Xvtevh9C7NYptb5pghSepBxZSyJSLiPaRmwzgWpHuL5vcCpf26Huq6Mx5XJXKmmkO04j_de8qZJn7qkEh3kX2dTSHCldb62gGljCFuIzZjPurZI17XWmX92APy4Lr1Md0elvkKp9SryjARb-8NW6bNf4r09ZJ3WtbRlmIofufOtskhWRbJEP3agBvac0GU9VUAPN8i3gBIYal5NOoK9EpAAN3RaFgEAlqskMuosiOKgcGK5K6IoSj1foTDB_OX8YY9JpmiFcqsAZw928_xwGJUAPBs-zue04BLmuHpnhrQFcb5Pj_vWwd2NVcx9ph2WpAm8xWszc3iG1JE3ELoHYcSiy0JURUiekfigdV_jI7Sh0vXbE90jj11vt_3H9gKyrlMbX0YU5h6Q2y99EwxhCHpmV_wRhTtKU"><b>Univ Chongqing Posts &amp; Telecom Files Chinese Patent Application for Differential </b><span class="s74"><b>Wgan</b></span><span class="s61"><b> Based Network Security Situation Prediction Method</b></span></a></span><span class="s4"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2">Global IP News. Security &amp; Protection Patent News, Oct 14, 2019</span></p>
<p class="p5"><span class="s2">Newspaper Article<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrZ3PS8MwFMeDzosnJyr-mryDeKtL1mZtYSpzOrwolQ0EL-O1Tabo2q6dF_8P_1-TrGVORC_eAoXSkPT7Xvtevh9C7NYptb5pghSepBxZSyJSLiPaRmwzgWpHuL5vcCpf26Huq6Mx5XJXKmmkO04j_de8qZJn7qkEh3kX2dTSHCldb62gGljCFuIzZjPurZI17XWmX92APy4Lr1Md0elvkKp9SryjARb-8NW6bNf4r09ZJ3WtbRlmIofufOtskhWRbJEP3agBvac0GU9VUAPN8i3gBIYal5NOoK9EpAAN3RaFgEAlqskMuosiOKgcGK5K6IoSj1foTDB_OX8YY9JpmiFcqsAZw928_xwGJUAPBs-zue04BLmuHpnhrQFcb5Pj_vWwd2NVcx9ph2WpAm8xWszc3iG1JE3ELoHYcSiy0JURUiekfigdV_jI7Sh0vXbE90jj11vt_3H9gKyrlMbX0YU5h6Q2y99EwxhCHpmV_wRhTtKU"><span class="s8">Full Text Online</span></a><span class="Apple-converted-space"> </span></span></p>
<p class="p8"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV1NT8JAEN2AXowXjBo_k7nIpRZb6AdN0ARRIgcTEjDxRrZli8RQkKL_xP_rzO7aFr3gwcum2TSb3fe2s5Pp7DzGGvWaZf6wCbFoxpbL7XrMueXGkeVx7tmC447wg0DKqRTSoUrmrxSpfyUe-5B6ukj7B_KzQbEDn3ELYIubANuNtgElXhidl3kyeaOgAGnzppLuIQngzGdGF81CKmW0RSqoYj8lB7Tz39oyD_FOy6isZHx9gjbhFk-_MV0XpsQuHbVHf34wXana4ZTbMZ4qHfJHqVJddIOV0oDR60sjS1GJbASaW18Vj5DDqAkVb2PIiGtAlt3OA5RScsSQtbbw9SzYZ_Q_VrUsdWmtDvZzz1_vVPV5PXSFHBc9kCpVRZ_RGq5FYj4NyqxcD5r6TN3V5ye5B8MKq9D8FnwhltBWHOyxkkj22SfhDxn-IPGHKmj0QaIPGn1Qi4UC-oDoQxF9aM348vWGOGhdyUeQVICmAr6BhIwKyKkARcUBu-zeDzsPJi1lpHVIsUkpUpNO-HuajnIgrEO2lcwTccRg7DgWt0M_jrjlhFYQxo4vAu42otBvepF7zC42GvJkw_dO2U7O9RnbjvF7Eeey8uYXFLxSVg"><b>Univ Chongqing Posts &amp; Telecom Files Chinese Patent Application for Differential </b><span class="s74"><b>Wgan</b></span><span class="s61"><b> Based Network Security Situation Prediction Method</b></span></a></span><span class="s4"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p5"><span class="s2">Global IP News: Security &amp; Protection Patent News, Oct 14, 2019</span></p>
<p class="p5"><span class="s2">Newspaper Article<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV1NT8JAEN2AXowXjBo_k7nIpRZb6AdN0ARRIgcTEjDxRrZli8RQkKL_xP_rzO7aFr3gwcum2TSb3fe2s5Pp7DzGGvWaZf6wCbFoxpbL7XrMueXGkeVx7tmC447wg0DKqRTSoUrmrxSpfyUe-5B6ukj7B_KzQbEDn3ELYIubANuNtgElXhidl3kyeaOgAGnzppLuIQngzGdGF81CKmW0RSqoYj8lB7Tz39oyD_FOy6isZHx9gjbhFk-_MV0XpsQuHbVHf34wXana4ZTbMZ4qHfJHqVJddIOV0oDR60sjS1GJbASaW18Vj5DDqAkVb2PIiGtAlt3OA5RScsSQtbbw9SzYZ_Q_VrUsdWmtDvZzz1_vVPV5PXSFHBc9kCpVRZ_RGq5FYj4NyqxcD5r6TN3V5ye5B8MKq9D8FnwhltBWHOyxkkj22SfhDxn-IPGHKmj0QaIPGn1Qi4UC-oDoQxF9aM348vWGOGhdyUeQVICmAr6BhIwKyKkARcUBu-zeDzsPJi1lpHVIsUkpUpNO-HuajnIgrEO2lcwTccRg7DgWt0M_jrjlhFYQxo4vAu42otBvepF7zC42GvJkw_dO2U7O9RnbjvF7Eeey8uYXFLxSVg"><span class="s8">Citation Online</span></a><span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2019-2020 31</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/?q=wgan&amp;oq=wgan#">… consumption prediction method and monitoring prediction system based on <span class="s42"><b>WGAN</b> …</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/23/93/d3/2e8fc2798eb038/CN111178626A.pdf"><span class="s16">CN111178626A</span></a> </span><span class="s19">傅启明</span><span class="s18"> </span><span class="s19">苏州科技大学</span></p>
<p class="p14"><span class="s18">Priority 2019-12-30 • Filed 2019-12-30 • Published 2020-05-19</span></p>
<p class="p14"><span class="s18">8. the <b>WGAN</b> algorithm-based building energy consumption prediction method according to claim 1, wherein after completing one GAN prediction model training in step S400, the reinforcement learning algorithm is used to optimize the hyperparameters in GAN, LSTM, and CNN, find and update the optimal …</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2"><span class="Apple-converted-space"> </span>2019 32</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN108549597A/en?q=allintitle:+wasserstein+OR+wgan&amp;oq=allintitle:+wasserstein+OR+wgan">A kind of fuzzy detection seed set generation method and generator based on <span class="s16"><b>WGAN</b> …</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/c9/b1/39/1f3dcbf287cdb1/CN108549597A.pdf"><span class="s16">CN108549597A</span></a> </span><span class="s19">纪守领</span><span class="s18"> </span><span class="s19">浙江大学</span></p>
<p class="p14"><span class="s18">Priority 2018-03-05 • Filed 2018-03-05 • Published 2018-09-18</span></p>
<p class="p14"><span class="s18">The invention discloses a kind of fuzzy detection seed set generator based on <b>WGAN</b> models, including</span><span class="s19">：</span><span class="s18">Training set acquisition module, has the fuzzy detection tool based on mutation algorithm, using common input as the identical program of Seed inspection multiple input format, it may be found that …</span><span class="s12"><br>
</span></p>
<p class="p8"><span class="s1"><a href="https://patents.google.com/?q=Fuzzy+detection+seed+set+generator+based+on+wasserstein+gallium+nitride+(WGAN)+model%2c+has+WGAN+module+converts+training+set&amp;scholar&amp;oq=Fuzzy+detection+seed+set+generator+based+on+wasserstein+gallium+nitride+(WGAN)+model%2c+has+WGAN+module+converts+training+set+">2019</a></span><span class="s5"> 33</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=28">Fuzzy detection seed set generator based on wasserstein gallium nitride (WGAN) model, has WGAN module converts training set into real data set, trains WGAN model to convergence, and generates fuzzy detection seed set in form of matrix<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN108549597-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV ZHEJIANG<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): JI S; LV C; CHEN J; et al.</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2019<span class="Apple-converted-space">  </span>34</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN110110670B/en?q=wasserstein&amp;before=priority:20191231&amp;after=priority:20190101&amp;oq=2019+wasserstein">Data association method in pedestrian tracking based on <span class="s16"><b>Wasserstein</b> measurement</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/61/7d/5e/1a022e4c151b86/CN110110670B.pdf"><span class="s16">CN110110670B </span></a></span><span class="s19">郭春生</span><span class="s18"> </span><span class="s19">杭州电子科技大学</span></p>
<p class="p14"><span class="s18">Priority 2019-05-09 • Filed 2019-05-09 • Granted 2022-03-25 • Published 2022-03-25</span></p>
<p class="p14"><span class="s18">5. The data association method in pedestrian tracking based on <b>Wasserstein</b> measurement as claimed in claim 1, wherein said second step is specifically: the method comprises the steps that seven video clips on a train sequence of an MOT16 data set are used for making data sets, and the made training …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p10"><span class="s18">2019 35</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN111476721B/en?q=wasserstein&amp;before=priority:20201231&amp;after=priority:20200101&amp;oq=2020+wasserstein">Methods and devices performing adaptive quadratic <span class="s16"><b>Wasserstein</b> full-waveform …</span></a></span></p>
<p class="p14"><span class="s18">US <i>BR</i> GB <a href="https://patentimages.storage.googleapis.com/a3/b3/17/c76a37b0acd7ba/GB2584196A.pdf"><span class="s16">GB2584196A </span></a>Wang Diancheng Cgg Services Sas</span></p>
<p class="p14"><span class="s18">Priority 2019-03-26 • Filed 2020-03-13 • Published 2020-11-25</span></p>
<p class="p15"><span class="s2">8. A seismic data processing apparatus (800) configured to perform seismic exploration of an underground structure using a <b>Wasserstein</b> metric-based full-wave inversion, FWI, the apparatus comprising: an interface (810) configured to obtain seismic data acquired over the explored underground …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">20192020 36<span class="Apple-converted-space"> </span></span></p>
<p class="p9"><span class="s27"><a href="https://patents.google.com/patent/US20200342361A1/en?q=wasserstein&amp;before=priority:20191231&amp;after=priority:20190101&amp;oq=2019+wasserstein"><b>Wasserstein</b><span class="s35"> barycenter model ensembling</span></a></span></p>
<p class="p14"><span class="s18">US <a href="https://patentimages.storage.googleapis.com/c3/a3/e7/a2964f59d36632/US20200342361A1.pdf"><span class="s16">US20200342361A1 </span></a>Youssef Mroueh International Business Machines Corporation</span></p>
<p class="p14"><span class="s18">Priority 2019-04-29 • Filed 2019-04-29 • Published 2020-10-29</span></p>
<p class="p15"><span class="s2">10 . The system according to claim 9 , further comprising inputting side information into the barycenter, wherein the barycenter comprises a <b>Wasserstein</b> barycenter with a <b>Wasserstein</b> distance metric. 11 . The system according to claim 9 , further comprising a plurality of the barycenters to determine …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2019 37</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN111178427B/en?q=wasserstein&amp;before=priority:20191231&amp;after=priority:20190101&amp;oq=2019+wasserstein&amp;page=1">… and embedded clustering based on depth self-coding of Sliced-<span class="s16"><b>Wasserstein</b> …</span></a></span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/31/a4/a0/52f9a2bced7f60/CN111178427B.pdf"><span class="s16">CN111178427B </span></a></span><span class="s19">郭春生</span><span class="s18"> </span><span class="s19">杭州电子科技大学</span></p>
<p class="p14"><span class="s18">Priority 2019-12-27 • Filed 2019-12-27 • Granted 2022-07-26 • Published 2022-07-26</span></p>
<p class="p15"><span class="s2">2. The method for image dimensionality reduction and embedded clustering based on depth self-coding of Sliced-<b>Wasserstein</b> distance according to claim 1, wherein in step S4, the cluster center of the self-coding embedded clustering network after initialization construction is initialized by an …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p10"><span class="s23"><a href="https://patents.google.com/patent/CN109947086B/en?q=wasserstein&amp;before=priority:20191231&amp;after=priority:20190101&amp;oq=2019+wasserstein&amp;page=1"><span class="Apple-converted-space"> </span></a></span><span class="s18">2019 38</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN110097512A/en?q=wasserstein&amp;before=priority:20191231&amp;after=priority:20190101&amp;oq=2019+wasserstein">… for high-dimension unsupervised anomaly detection using kernalized <span class="s16"><b>wasserstein</b><span class="Apple-converted-space"> </span></span></a></span></p>
<p class="p14"><span class="s18">KR <a href="https://patentimages.storage.googleapis.com/ea/58/4a/cacf67e4c6cedc/KR102202842B1.pdf"><span class="s16">KR102202842B1 </span></a></span><span class="s78">백명희조</span><span class="s18"> </span><span class="s78">서울대학교산학협력단</span></p>
<p class="p14"><span class="s18">Priority 2019-08-13 • Filed 2019-08-13 • Granted 2021-01-14 • Published 2021-01-14</span></p>
<p class="p14"><span class="s18">The present invention relates to a learning method and a learning apparatus for high-dimension unsupervised abnormality detection using a kernalized <b>Wasserstein</b> autoencoder to decrease excessive computations of a Christoffel function, and a test method and a test apparatus using the same.</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p42"><span class="s2"><span class="Apple-converted-space">  </span></span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2019 39</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN109816044A/en?q=wgan&amp;before=priority:20191231&amp;after=priority:20190101&amp;oq=2019+wgan">A kind of uneven learning method based on <span class="s16"><b>WGAN</b>-GP and over-sampling</span></a></span></p>
<p class="p9"><span class="s30">CN <a href="https://patentimages.storage.googleapis.com/a6/1e/b8/0c16671d33d2ec/CN109816044A.pdf"><span class="s35">CN109816044A </span></a></span><span class="s36">邓晓衡</span><span class="s30"> </span><span class="s36">中南大学</span></p>
<p class="p14"><span class="s18">Priority 2019-02-11 • Filed 2019-02-11 • Published 2019-05-28</span></p>
<p class="p14"><span class="s18">3. a kind of uneven learning method based on <b>WGAN</b>-GP and over-sampling as claimed in claim 2, which is characterized in that sentence The loss function of other device, as follows: Wherein, D (), G () respectively indicate the function expression of arbiter and Maker model, P r Indicate the number of …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2019 40</span></p>
<p class="p9"><span class="s27"><a href="https://patents.google.com/patent/CN109947086B/en?q=wasserstein&amp;before=priority:20191231&amp;after=priority:20190101&amp;oq=2019+wasserstein&amp;page=1">Sketch based on <span class="s35"><b>WGAN</b>-GP and U-NET-photo method for transformation</span></a></span></p>
<p class="p9"><span class="s30">CN <a href="https://patentimages.storage.googleapis.com/26/f4/3d/68f84ee9187273/CN110175567A.pdf"><span class="s35">CN110175567A </span></a></span><span class="s36">王世刚</span><span class="s30"> </span><span class="s36">吉林大学</span></p>
<p class="p14"><span class="s18">Priority 2019-05-28 • Filed 2019-05-28 • Published 2019-08-27</span></p>
<p class="p14"><span class="s18">1. a kind of sketch based on <b>WGAN</b>-GP and U-NET -- photo method for transformation, it is characterised in that include the following steps: 1.1 obtain human face sketch -- picture data library: FERET, CUHK, IIIT-D</span><span class="s19">；</span><span class="s18"> 1.2 by sketch -- photo keeps the distribution proportion of its face of …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2019 41</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/KR102202842B1/en?q=wasserstein&amp;before=priority:20191231&amp;after=priority:20190101&amp;oq=2019+wasserstein&amp;page=1">New energy capacity configuration method based on <span class="s16"><b>WGAN</b> scene simulation and …</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/c0/d5/8f/b0670661fc4d5d/CN112994115A.pdf"><span class="s16">CN112994115A </span></a></span><span class="s19">马燕峰</span><span class="s18"> </span><span class="s19">华北电力大学（保定）</span></p>
<p class="p14"><span class="s18">Priority 2019-12-18 • Filed 2019-12-18 • Published 2021-06-18</span></p>
<p class="p14"><span class="s18">1. A new energy capacity configuration method based on Wasserstein generation countermeasure network (<b>WGAN</b>) scene simulation and time sequence production simulation is characterized by mainly comprising the following specific steps: step 1, simulating a large number of wind and light resource …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2019 41</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN110493242B/en?q=wgan&amp;before=priority:20191231&amp;after=priority:20190101&amp;oq=2019+wgan">Method, device and storage medium for improving image enhancement based on <span class="s16"><b>WGAN</b> …</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/3c/46/1a/2db88ab263b120/CN110493242B.pdf"><span class="s16">CN110493242B </span></a></span><span class="s19">王红玲</span><span class="s18"> </span><span class="s19">上海网达软件股份有限公司</span></p>
<p class="p14"><span class="s18">Priority 2019-08-27 • Filed 2019-08-27 • Granted 2022-02-11 • Published 2022-02-11</span></p>
<p class="p14"><span class="s18">1. A method for improved image enhancement based on <b>WGAN</b>-GP and U-net, comprising the steps of: the first step is as follows: de-encapsulating the input video stream or file to obtain a first video code stream and a first audio code stream; the second step is as follows: decoding the first video …</span><span class="s2"><br>
</span></p>
<p class="p27"><span class="s2"><br>
</span></p>
<p class="p27"><span class="s2">2019 42. patent</span></p>
<p class="p28"><span class="s17"><a href="https://patents.google.com/patent/CN111178427A/en?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new&amp;page=1">Depth self-coding embedded clustering method based on Sliced-<span class="s38"><b>Wasserstein</b> …</span></a></span></p>
<p class="p29"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/91/b5/5d/c32cab847bcf9b/CN111178427A.pdf"><span class="s39">CN111178427A </span></a></span><span class="s19">郭春生</span><span class="s18"> </span><span class="s19">杭州电子科技大学</span></p>
<p class="p30"><span class="s18">Priority 2019-12-27 • Filed 2019-12-27 • Published 2020-05-19</span></p>
<p class="p27"><span class="s18">The invention discloses a depth self-coding embedded clustering method based on Sliced-<b>Wasserstein</b> distance, which comprises the following steps: s11, constructing a self-coding network module based on a Sliced-Walserstein distance; s12, constructing a clustering module; s13, combining the built …</span></p>
<p class="p27"><span class="s2"><br>
</span></p>
<p class="p27"><span class="s2">2019 43. patent</span></p>
<p class="p28"><span class="s17"><a href="https://patents.google.com/patent/US20200125982A1/en?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new&amp;page=1">System and method for unsupervised domain adaptation via sliced-<span class="s38"><b>wasserstein</b> …</span></a></span></p>
<p class="p29"><span class="s18">US <a href="https://patentimages.storage.googleapis.com/f7/09/ea/46536d7e571bdc/US20200125982A1.pdf"><span class="s39">US20200125982A1 </span></a>Alexander J. Gabourie Hrl Laboratories, Llc</span></p>
<p class="p30"><span class="s18">Priority 2018-02-06 • Filed 2019-12-18 • Published 2020-04-23</span></p>
<p class="p27"><span class="s18">The computer program product as set forth in claim 11 , wherein the one or more processors further perform an operation of using sliced-<b>Wasserstein</b> (SW) distance as a dissimilarity measure for determining dissimilarity between the first input data distribution and the second input data distribution.</span></p>
<p class="p27"><span class="s2"><br>
</span></p>
<p class="p27"><span class="s2">2019 44 patent</span></p>
<p class="p28"><span class="s17"><a href="https://patents.google.com/patent/WO2020159638A1/en?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new&amp;page=1">System and method for unsupervised domain adaptation via sliced-<span class="s38"><b>wasserstein</b> …</span></a></span></p>
<p class="p29"><span class="s18">WO EP CN <a href="https://patentimages.storage.googleapis.com/dd/7f/79/e74e530f5b35ea/WO2020159638A1.pdf"><span class="s39">WO2020159638A1 </span></a>Alexander J. GABOURIE Hrl Laboratories, Llc</span></p>
<p class="p30"><span class="s18">Priority 2019-01-30 • Filed 2019-12-18 • Published 2020-08-06</span></p>
<p class="p27"><span class="s18">12. The computer program product as set forth in Claim 11, wherein the one or more processors further perform an operation of using sliced-<b>Wasserstein</b> (SW) distance as a dissimilarity measure for determining dissimilarity between the first input data distribution and the second input data …</span></p>
<p class="p27"><span class="s2"><br>
</span></p>
<p class="p27"><span class="s2">2019 45<span class="Apple-converted-space">  </span>patent</span></p>
<p class="p28"><span class="s17"><a href="https://patents.google.com/patent/CN108399422A/en?q=TI%3d(wgan)&amp;num=25&amp;oq=TI%3d(wgan)&amp;sort=new&amp;page=2">Clean energy power supply planning method based on <span class="s38"><b>Wasserstein</b> distance and …</span></a></span></p>
<p class="p57"><span class="s79">CN <a href="https://patentimages.storage.googleapis.com/48/5e/db/f23e6503ae46ad/CN110797919B.pdf"><span class="s80">CN110797919B </span></a></span><span class="s18">汪荣华</span><span class="s79"> </span><span class="s18">国网四川省电力公司经济技术研究院</span></p>
<p class="p30"><span class="s18">Priority 2019-12-05 • Filed 2019-12-05 • Granted 2020-09-01 • Published 2020-09-01</span></p>
<p class="p27"><span class="s18">The invention discloses a clean energy power supply planning method based on <b>Wasserstein</b> distance and distribution robust optimization, which relates to the technical field of power system planning, and comprises the following steps: s1: constructing a wind-solar output uncertainty set based on …</span></p>
<p class="p27"><span class="s2"><br>
</span></p>
<p class="p27"><span class="s2">2019 46 patent</span></p>
<p class="p28"><span class="s17"><a href="https://patents.google.com/?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new&amp;page=1#">… typical scene generation method based on BIRCH clustering and <span class="s38"><b>Wasserstein</b> …</span></a></span></p>
<p class="p57"><span class="s79">CN <a href="https://patentimages.storage.googleapis.com/43/9a/ba/e1eb5d3157ffde/CN110929399A.pdf"><span class="s80">CN110929399A </span></a></span><span class="s18">汤向华</span><span class="s79"> </span><span class="s18">国网江苏省电力有限公司南通供电分公司</span></p>
<p class="p30"><span class="s18">Priority 2019-11-21 • Filed 2019-11-21 • Published 2020-03-27</span></p>
<p class="p27"><span class="s18">2. The method for generating a typical wind power output scene based on BIRCH clustering and <b>Wasserstein</b> distance as claimed in claim 1, wherein: the specific steps of the BIRCH clustering are as follows: a) setting threshold parameters B, L and T, and inputting wind power scene number S; b) number …</span></p>
<p class="p27"><span class="s2"><br>
</span></p>
<p class="p27"><span class="s2">2019 47 atent</span></p>
<p class="p31"><span class="s40"><a href="https://patents.google.com/patent/CN114330486A/en?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new"><b>Wasserstein</b><span class="s38"> distance-based fault diagnosis method for deep countermeasure …</span></a></span></p>
<p class="p33"><span class="s41">CN <a href="https://patentimages.storage.googleapis.com/a8/e1/de/b044ab8a470aac/CN110907176A.pdf"><span class="s42">CN110907176A </span></a></span><span class="s43">徐娟</span><span class="s41"> </span><span class="s43">合肥工业大学</span></p>
<p class="p30"><span class="s18">Priority 2019-09-30 • Filed 2019-09-30 • Published 2020-03-24</span></p>
<p class="p27"><span class="s18">2. The method for fault diagnosis of the deep immunity migration network based on <b>Wasserstein</b> distance as claimed in claim 1, wherein in step S3, the objective function of the fault diagnosis model is determined, which includes the following specific steps: s301, extracting the source domain D from …</span></p>
<p class="p27"><span class="s2"><br>
</span></p>
<p class="p27"><span class="s2"><br>
</span></p>
<p class="p27"><span class="s2">2019 48<span class="Apple-converted-space">  </span>patent</span></p>
<p class="p28"><span class="s17"><a href="https://patents.google.com/patent/CN114722888A/en?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new">… for high-dimension unsupervised anomaly detection using kernalized <span class="s38"><b>wasserstein</b> …</span></a></span></p>
<p class="p29"><span class="s18">KR <a href="https://patentimages.storage.googleapis.com/ea/58/4a/cacf67e4c6cedc/KR102202842B1.pdf"><span class="s39">KR102202842B1 </span></a></span><span class="s78">백명희조</span><span class="s18"> </span><span class="s78">서울대학교산학협력단</span></p>
<p class="p30"><span class="s18">Priority 2019-08-13 • Filed 2019-08-13 • Granted 2021-01-14 • Published 2021-01-14</span></p>
<p class="p27"><span class="s18">The present invention relates to a learning method and a learning apparatus for high-dimension unsupervised abnormality detection using a kernalized <b>Wasserstein</b> autoencoder to decrease excessive computations of a Christoffel function, and a test method and a test apparatus using the same.</span></p>
<p class="p27"><span class="s2"><br>
</span></p>
<p class="p27"><span class="s2">2019<span class="Apple-converted-space">  </span>49 patent</span></p>
<p class="p28"><span class="s17"><a href="https://patents.google.com/patent/KR20230023464A/en?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new">Finger vein identification method based on deep learning and <span class="s38"><b>Wasserstein</b> …</span></a></span></p>
<p class="p33"><span class="s41">CN <a href="https://patentimages.storage.googleapis.com/9c/5e/85/29c204e0d55353/CN110555382A.pdf"><span class="s42">CN110555382A </span></a></span><span class="s43">张娜</span><span class="s41"> </span><span class="s43">浙江理工大学</span></p>
<p class="p30"><span class="s18">Priority 2019-07-31 • Filed 2019-07-31 • Published 2019-12-10</span></p>
<p class="p27"><span class="s18">6. the finger vein recognition method based on deep learning and <b>Wasserstein</b> distance measurement in claim 1, wherein: the step S5 includes: S51, in the registration stage, acquiring a finger vein image through the step S1, further extracting a feature code G w (x) of the image through the steps S2 …</span></p>
<p class="p27"><span class="s2"><br>
</span></p>
<p class="p27"><span class="s2">2019 50<span class="Apple-converted-space">  </span>patent</span></p>
<p class="p28"><span class="s17"><a href="https://patents.google.com/patent/CN110414383A/en?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new&amp;page=1">Convolutional neural networks based on <span class="s38"><b>Wasserstein</b> distance fight transfer …</span></a></span></p>
<p class="p33"><span class="s41">CN <a href="https://patentimages.storage.googleapis.com/62/e0/ec/08ab9f68e1b69f/CN110414383A.pdf"><span class="s42">CN110414383A </span></a></span><span class="s43">袁烨</span><span class="s41"> </span><span class="s43">华中科技大学</span></p>
<p class="p30"><span class="s18">Priority 2019-07-11 • Filed 2019-07-11 • Published 2019-11-05</span></p>
<p class="p27"><span class="s18">In the step 3.2, the <b>Wasserstein</b> distance is the real number average value and target reality of the source domain set of real numbers The difference of the real number average value of manifold. 5. a kind of convolutional neural networks based on <b>Wasserstein</b> distance according to claim 2 fight …</span></p>
<p class="p27"><span class="s2"><br>
</span></p>
<p class="p27"><span class="s2">2019 51. patent</span></p>
<p class="p28"><span class="s17"><a href="https://patents.google.com/patent/CN110110670B/en?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new&amp;page=1">Data association method in pedestrian tracking based on <span class="s38"><b>Wasserstein</b> measurement</span></a></span></p>
<p class="p29"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/61/7d/5e/1a022e4c151b86/CN110110670B.pdf"><span class="s39">CN110110670B </span></a></span><span class="s19">郭春生</span><span class="s18"> </span><span class="s19">杭州电子科技大学</span></p>
<p class="p30"><span class="s18">Priority 2019-05-09 • Filed 2019-05-09 • Granted 2022-03-25 • Published 2022-03-25</span></p>
<p class="p27"><span class="s18">5. The data association method in pedestrian tracking based on <b>Wasserstein</b> measurement as claimed in claim 1, wherein said second step is specifically: the method comprises the steps that seven video clips on a train sequence of an MOT16 data set are used for making data sets, and the made training …</span></p>
<p class="p27"><span class="s2"><br>
</span></p>
<p class="p27"><span class="s2">2019-2020 52. patent</span></p>
<p class="p31"><span class="s40"><a href="https://patents.google.com/patent/CN113276119B/en?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new"><b>Wasserstein</b><span class="s38"> barycenter model ensembling</span></a></span></p>
<p class="p29"><span class="s18">US <a href="https://patentimages.storage.googleapis.com/c3/a3/e7/a2964f59d36632/US20200342361A1.pdf"><span class="s39">US20200342361A1 </span></a>Youssef Mroueh International Business Machines Corporation</span></p>
<p class="p30"><span class="s18">Priority 2019-04-29 • Filed 2019-04-29 • Published 2020-10-29</span></p>
<p class="p27"><span class="s18">, wherein the side information includes class relationships represented by a graph or via an embedding space. 13 . The system according to claim 9 , wherein the optimal transport metric includes a <b>Wasserstein</b> distance. 14 . The system according to claim 11 , wherein the barycenter takes into account the …</span></p>
<p class="p27"><span class="s2"><br>
</span></p>
<p class="p27"><span class="s2">019 53. patent</span></p>
<p class="p28"><span class="s17"><a href="https://patents.google.com/?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new&amp;page=1#">… denoising model of confrontation network are generated based on <span class="s38"><b>Wasserstein</b></span></a></span></p>
<p class="p33"><span class="s41">CN <a href="https://patentimages.storage.googleapis.com/1e/83/8d/114112ea3396b9/CN110097512A.pdf"><span class="s42">CN110097512A </span></a></span><span class="s43">张意</span><span class="s41"> </span><span class="s43">四川大学</span></p>
<p class="p30"><span class="s18">Priority 2019-04-16 • Filed 2019-04-16 • Published 2019-08-06</span></p>
<p class="p27"><span class="s18">The invention discloses a kind of construction method of three-dimensional MRI image denoising model that confrontation network is generated based on <b>Wasserstein</b> and applications, the present invention generates confrontation network as basic model using <b>Wasserstein</b> and handles MRI noise image, it …</span></p>
<p class="p58"><span class="s2"><br>
</span></p>
<p class="p27"><span class="s2">019 54. patent</span></p>
<p class="p31"><span class="s40"><a href="https://patents.google.com/patent/CN110175567A/en?q=TI%3d(wgan)&amp;num=25&amp;oq=TI%3d(wgan)&amp;sort=new&amp;page=2">Sketch based on <span class="s38"><b>WGAN</b>-GP and U-NET-photo method for transformation</span></a></span></p>
<p class="p33"><span class="s41">CN <a href="https://patentimages.storage.googleapis.com/26/f4/3d/68f84ee9187273/CN110175567A.pdf"><span class="s42">CN110175567A </span></a></span><span class="s43">王世刚</span><span class="s41"> </span><span class="s43">吉林大学</span></p>
<p class="p30"><span class="s18">Priority 2019-05-28 • Filed 2019-05-28 • Published 2019-08-27</span></p>
<p class="p27"><span class="s18">1. a kind of sketch based on <b>WGAN</b>-GP and U-NET -- photo method for transformation, it is characterised in that include the following steps: 1.1 obtain human face sketch -- picture data library: FERET, CUHK, IIIT-D</span><span class="s19">；</span><span class="s18"> 1.2 by sketch -- photo keeps the distribution proportion of its face of …</span></p>
<p class="p27"><span class="s2"><br>
</span></p>
<p class="p27"><span class="s2">019 55. patent</span></p>
<p class="p31"><span class="s40"><a href="https://patents.google.com/patent/CN110212028A/en?q=TI%3d(wgan)&amp;num=25&amp;oq=TI%3d(wgan)&amp;sort=new&amp;page=2">A kind of horizontal proliferation <span class="s38"><b>eGaN</b> HEMT device of integrated backward …</span></a></span></p>
<p class="p33"><span class="s41">CN <a href="https://patentimages.storage.googleapis.com/52/15/4f/930d4c77a7bab6/CN110212028A.pdf"><span class="s42">CN110212028A </span></a></span><span class="s43">张士英</span><span class="s41"> </span><span class="s43">张士英</span></p>
<p class="p30"><span class="s18">Priority 2019-05-22 • Filed 2019-05-22 • Published 2019-09-06</span></p>
<p class="p27"><span class="s18">6. the horizontal proliferation <b>eGaN</b> HEMT of a kind of integrated backward dioded according to claim 1 and embedded drain electrode field plate Device, which is characterized in that MIS Schottky diode extended segment (104) and MIS Schottky diode insulating layer (105) are adopted MIS Schottky …</span></p>
<p class="p27"><span class="s2"><br>
</span></p>
<p class="p27"><span class="s2">019 56. patent</span></p>
<p class="p31"><span class="s40"><a href="https://patents.google.com/patent/CN110224579A/en?q=TI%3d(wgan)&amp;num=25&amp;oq=TI%3d(wgan)&amp;sort=new&amp;page=2">A kind of <span class="s38"><b>eGaN</b> HEMT hybrid solenoid valve circuit and control method</span></a></span></p>
<p class="p29"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/2f/52/6c/37bbc2c0891132/CN110224579A.pdf"><span class="s39">CN110224579A </span></a></span><span class="s19">彭子和</span><span class="s18"> </span><span class="s19">南京航空航天大学</span></p>
<p class="p30"><span class="s18">Priority 2019-05-16 • Filed 2019-05-16 • Published 2019-09-10</span></p>
<p class="p27"><span class="s18">4. the method for controlling <b>eGaN</b> HEMT hybrid solenoid valve circuit as claimed in claim 2, it is characterised in that: keep driving electricity Potential source U dri In running order, DC current source I is opened in starting before <b>eGaN</b> HEMT is opened on_bias , enter in <b>eGaN</b> HEMT It is closed when …</span></p>
<p class="p27"><span class="s2"><br>
</span></p>
<p class="p27"><span class="s2">019 57. patent</span></p>
<p class="p28"><span class="s17"><a href="https://patents.google.com/?q=TI%3d(wgan)&amp;num=25&amp;oq=TI%3d(wgan)&amp;sort=new&amp;page=2#">A kind of uneven learning method based on <span class="s38"><b>WGAN</b>-GP and over-sampling</span></a></span></p>
<p class="p33"><span class="s41">CN <a href="https://patentimages.storage.googleapis.com/a6/1e/b8/0c16671d33d2ec/CN109816044A.pdf"><span class="s42">CN109816044A </span></a></span><span class="s43">邓晓衡</span><span class="s41"> </span><span class="s43">中南大学</span></p>
<p class="p30"><span class="s18">Priority 2019-02-11 • Filed 2019-02-11 • Published 2019-05-28</span></p>
<p class="p27"><span class="s18">3. a kind of uneven learning method based on <b>WGAN</b>-GP and over-sampling as claimed in claim 2, which is characterized in that sentence The loss function of other device, as follows: Wherein, D (), G () respectively indicate the function expression of arbiter and Maker model, P r Indicate the number of …</span></p>
<p class="p10"><span class="s2"><br>
</span></p>
<p class="p27"><span class="s2">2019 58. 2019<a href="https://patents.google.com/patent/GB2584196B/en?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new&amp;page=1"><span class="s81">-2023</span></a></span></p>
<p class="p28"><span class="s17"><a href="https://patents.google.com/patent/GB2584196B/en?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new&amp;page=1">Methods and devices performing adaptive quadratic <span class="s38"><b>Wasserstein</b> full-waveform …</span></a></span></p>
<p class="p29"><span class="s18">US <i>BR</i> GB <i>MX</i> <a href="https://patentimages.storage.googleapis.com/97/15/26/43245732f0a03b/GB2584196B.pdf"><span class="s39">GB2584196B </span></a>Wang Diancheng Cgg Services Sas</span></p>
<p class="p30"><span class="s18">Priority 2019-03-26 • Filed 2020-03-13 • Granted 2023-01-18 • Published 2023-01-18</span></p>
<p class="p35"><span class="s1"><a href="https://patents.google.com/patent/GB2584196B/en?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new&amp;page=1"><span class="Apple-converted-space"> </span><span class="s46"></span></a></span></p>
<p class="p18"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p10"><span class="s2"><br>
</span></p>
<p class="p10"><span class="s2"><br>
</span></p>
<p class="p10"><span class="s2">&lt;— 44 till 2018</span></p>
<p class="p10"><span class="s2"><span class="Apple-converted-space">   </span>+ 58 in 2019<span class="Apple-converted-space">   </span></span></p>
<p class="p10"><span class="s2"><span class="Apple-converted-space">   </span>= 102 till 2019</span></p>
<p class="p10"><span class="s2">end 2019. e19</span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space"> </span><br>
</span></p>
<p class="p13"><span class="s2">start 2020</span></p>
<p class="p13"><span class="s2">95<span class="Apple-converted-space">  </span>patents</span></p>
<p class="p59"><span class="s2"><br>
</span></p>
<p class="p60"><span class="s1"><b>2020 1 2018-202</b><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV1LS8NAEB5sevFkRcVXyxy81ibdxKZQlagtnjQ-QPBSNslGxTapabz4A_zdziRZSkX0IoQ9JMtull2-eezMfACie2i2v2FCz-4HcZ_MC1vSEziWIjFjSjd2rTAUcaCzx6pwqBudGlNtt0bJArqjNGSveYdkj90TwrHE6eytzTxSfN-qSTVkRbYQHVvCctwa1Ltc-suA-tnwyr9dhl67gs3RGuj4KfUhC8bCH8zW5XqN__qbDWgwuM3kTGXolWdnHVZUsgGfvpyk6E3yFHVQHrIHmDoSxkxf8jmWaiqWair61CY5eouLcCQ9GK8DdvDg3TPNQSM9leG2CRYhCjiYyuz15EEWuZ7MtznoFG_wgtVZOoebcDAa3p9ftvVix1xTOSZROx8vliq2wEjSRG0DuiKy-rEylSTLzA4iabrUHoW2Yn7QsLcDzV-H2v3j-x6sdtkGZj4hdx-MPHtXzaIEZKva6xbUfOfxCzF5zqc"><span class="s82"><b>Palo Alto Research Center Submits United States Patent Application for Object Shape Regression Using </b></span><span class="s83"><b>Wasser...<span class="Apple-converted-space"> </span></b></span></a></span></p>
<p class="p47"><span class="s2">Global IP News. Information Technology Patent News, Jun 18, 2020</span></p>
<p class="p60"><span class="s69">Newspaper Article<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV1LS8NAEB5sevFkRcVXyxy81ibdxKZQlagtnjQ-QPBSNslGxTapabz4A_zdziRZSkX0IoQ9JMtull2-eezMfACie2i2v2FCz-4HcZ_MC1vSEziWIjFjSjd2rTAUcaCzx6pwqBudGlNtt0bJArqjNGSveYdkj90TwrHE6eytzTxSfN-qSTVkRbYQHVvCctwa1Ltc-suA-tnwyr9dhl67gs3RGuj4KfUhC8bCH8zW5XqN__qbDWgwuM3kTGXolWdnHVZUsgGfvpyk6E3yFHVQHrIHmDoSxkxf8jmWaiqWair61CY5eouLcCQ9GK8DdvDg3TPNQSM9leG2CRYhCjiYyuz15EEWuZ7MtznoFG_wgtVZOoebcDAa3p9ftvVix1xTOSZROx8vliq2wEjSRG0DuiKy-rEylSTLzA4iabrUHoW2Yn7QsLcDzV-H2v3j-x6sdtkGZj4hdx-MPHtXzaIEZKva6xbUfOfxCzF5zqc"><span class="s5">Full Text Online</span></a> <br>
<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV1NT8JAEJ0oXDyJUeMXZkI86AHZpaW0ETWoEL1IFYxHsm23asQWK178Pf5Qd5ZuCMboxaRpmnaz2Wy3bzszb94AWPVDVv2GCU3bC2JPmRe2UEfQ4FJtM0y4scvD0IoDkz2W06FuTGpM_roNSmrojtKQvOY1HcwkwTp2On6tUh0pireaohoiL7YQHXOLN9xFKNZJ-qsAxbPOtX9r0NpRG5Y2yjy7oZCB83lMdnI87S6DIVbJD6FLGf5gz84LOf7r-EtQItQbi7HMsD1dVCuwIJNV-PTFKMX2aJKiYeshuYZVwyvSwtR6yDI6wkovIN8O9h9VL6rtw5Rpm6BmJ2DrRWTPJ_dCp3lSqc1WTd_BC_qTVUuwgk8J-qqvZILtWXidrrNUfReY5zbg_l3fH_Swzoiw5VkOax6swV63Mzi_rJqpGJIUc6x26LfhbCKsdSgkaSI3AF0r4l4smRTKoLODSDBXnZ3QllRWNGxuQvnXrrb-eL4NSzQ-zbx1dqAwyd5lWStH7uZL5AvWIdoL"><span class="s82"><b>Palo Alto Research Center Incorporated; "Object Shape Regression Using </b></span><span class="s84"><b>Wasserstein</b></span><span class="s82"><b> Distance" in Patent...<span class="Apple-converted-space"> </span></b></span></a></span></p>
<p class="p47"><span class="s2">Journal of engineering (Atlanta, Ga.), Jul 6, 2020, 5046 <span class="Apple-converted-space">  </span>patent</span></p>
<p class="p47"><span class="s2">Newspaper Article<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV1NT8JAEJ0oXDyJUeMXZkI86AHZpaW0ETWoEL1IFYxHsm23asQWK178Pf5Qd5ZuCMboxaRpmnaz2Wy3bzszb94AWPVDVv2GCU3bC2JPmRe2UEfQ4FJtM0y4scvD0IoDkz2W06FuTGpM_roNSmrojtKQvOY1HcwkwTp2On6tUh0pireaohoiL7YQHXOLN9xFKNZJ-qsAxbPOtX9r0NpRG5Y2yjy7oZCB83lMdnI87S6DIVbJD6FLGf5gz84LOf7r-EtQItQbi7HMsD1dVCuwIJNV-PTFKMX2aJKiYeshuYZVwyvSwtR6yDI6wkovIN8O9h9VL6rtw5Rpm6BmJ2DrRWTPJ_dCp3lSqc1WTd_BC_qTVUuwgk8J-qqvZILtWXidrrNUfReY5zbg_l3fH_Swzoiw5VkOax6swV63Mzi_rJqpGJIUc6x26LfhbCKsdSgkaSI3AF0r4l4smRTKoLODSDBXnZ3QllRWNGxuQvnXrrb-eL4NSzQ-zbx1dqAwyd5lWStH7uZL5AvWIdoL"><span class="s10">Full Text Online</span></a><span class="Apple-converted-space"> </span></span></p>
<p class="p61"><span class="s85"><a href="https://patentimages.storage.googleapis.com/9c/84/71/4bb1a084e2e016/US20200193607A1.pdf"><b>[PDF]</b><span class="s86"> googleapis.com</span></a></span></p>
<p class="p61"><span class="s1"><a href="https://patents.google.com/patent/US20200193607A1/en">Object shape regression using <span class="s87"><b>wasserstein </b>distance</span></a></span></p>
<p class="p62"><span class="s7"><a href="https://scholar.google.com/citations?user=Gw10rFEAAAAJ&amp;hl=en&amp;oi=sra">J Sun</a></span><span class="s2">, SKP Kumar, <a href="https://scholar.google.com/citations?user=hY3uN8oAAAAJ&amp;hl=en&amp;oi=sra"><span class="s88">R Bala</span></a> - US Patent App. 16/222,062, 2020 - Google Patents</span></p>
<p class="p62"><span class="s2">One embodiment can provide a system for detecting outlines of objects in images. During<span class="Apple-converted-space"> </span></span></p>
<p class="p62"><span class="s2">operation, the system receives an image that includes at least one object, generates a<span class="Apple-converted-space"> </span></span></p>
<p class="p62"><span class="s2">random noise signal, and provides the received image and the random noise signal to a …</span></p>
<p class="p63"><span class="s1"><a href="https://scholar.google.com/scholar?cluster=9266740532559623131&amp;hl=en&amp;as_sdt=0,39&amp;as_ylo=2020&amp;as_yhi=2020">All 2 versions</a></span><span class="s89">\</span></p>
<p class="p64"><span class="s2"><br>
</span></p>
<p class="p64"><span class="s2">2020 2</span></p>
<p class="p65"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV1LSwMxEB60vXiyouKrZQ5e1-7T7kJVqm3poUqtL_BSspssFG127bYXf4E_20x2F6mIXoSwhwRCQoZvZjaZ7wNw7BPT-IYJLTcI40ClFy5TLfQsodyMyfzYt6LIicOyeqx4DnVblsYUx12ipIZunkT017xJot4WOSzvIn0zSEeK7ltLUQ1WiC3wM8uxPH8dqjZRf1Wgetm7GY1XoTcoYLO_CeX7KfHOtGLhD2nrKl_jvy6zBjUCt5SlYo6d3Ha2YE3IbfgYjIc4zC0jofVgHqdmqKJbHKnIVC4wkZgznSOTHK-1CLUef5DZMiX0yQTHbjJjU4kdztL8vh8fpwzvXhU0caM9Y_OX8yemqz1JcbPd1D3YpYBWWeIOHPd791cDo9zuhFiVY-Vss8nXZp1dqMhEij1A3-FWEAtTMJWbuSFnpq--p5ErSCE0au1D_depDv4YP4QNm7Jg0zVs5wgqi_lS1DUJZKM47Qasj7znT9VWzzo"><b>HRL Laboratories Applies for Patent on System and Method for Unsupervised Domain Adaptation Via Sliced-</b><span class="s83"><b>Wasserstein</b></span></a></span><span class="s5"><b> Distance</b></span></p>
<p class="p61"><span class="s1"><a href="http://www.freepatentsonline.com/y2020/0125982.html">System and method for unsupervised domain adaptation via sliced-<span class="s87"><b>wasserstein </b>distance</span></a></span></p>
<p class="p62"><span class="s7"><a href="https://scholar.google.com/citations?user=V1Z-DdgAAAAJ&amp;hl=en&amp;oi=sra">AJ Gabourie</a></span><span class="s2">, M Rostami, <a href="https://scholar.google.com/citations?user=yREBSy0AAAAJ&amp;hl=en&amp;oi=sra"><span class="s88">S Kolouri</span></a>… - US Patent App. 16 …, 2020 - freepatentsonline.com</span></p>
<p class="p62"><span class="s2">Described is a system for unsupervised domain adaptation in an autonomous learning<span class="Apple-converted-space"> </span></span></p>
<p class="p62"><span class="s2">agent. The system adapts a learned model with a set of unlabeled data from a target<span class="Apple-converted-space"> </span></span></p>
<p class="p62"><span class="s2">domain, resulting in an adapted model. The learned model was previously trained to …</span></p>
<p class="p64"><span class="s7"><a href="https://scholar.google.com/scholar?cites=4263445864112620866&amp;as_sdt=5,39&amp;sciodt=0,39&amp;hl=en">Cited by 2</a></span><span class="s90"> <a href="https://scholar.google.com/scholar?q=related:QoWKuWzNKjsJ:scholar.google.com/&amp;scioq=allintitle:+wasserstein+OR+Vaserstein&amp;hl=en&amp;as_sdt=0,39&amp;as_ylo=2020&amp;as_yhi=2020"><span class="s91">Related articles</span></a></span></p>
<p class="p60"><span class="s2"><br>
</span></p>
<p class="p60"><span class="s1"><b>2020 3</b></span></p>
<p class="p65"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtZ1ZT8JAEMc3gi-8abwPsiHRF6iWbqFtgiaoEH3wCODxRpZ2m6C2kFL0q_hxnen2woREH0xIQxYyafc3mT06819CmHaiKj9igqFbI9eC5YXO4TNq1AUMMyo3XbNu28wdJdVjMh0qPvE-nyL1r-ChDdBjIe0f4KdGoQG-gwvAFZwArr9ygySzDut0IUh44xBV-TEBoJ29usZ-PtI0qV6OOY7V2-hg6Wp3EsCsdDafYkSZwdz0auJx3CFx-DROU3wa82ofDAlHeeZR7Saen4mqniE6FJhF65jM2Eb58o_4hl-TDPq0ejK3yx-F3s9U6z_ZldCiF-r1bA2Lf-u9pAcfy9hq6TqqocrxVeTaTFXNxVCDSfngRXHsm_vuYqMU7YXZGzNhmmgeo1S654zt8Ez4ymO_QApgtkhWLzp3D710201lmqVLjYrkduLBWB7LE00rBmukhE_wHlVUrZMV4W-QrxwwKoFRCYzmgNVoRcKiAItKWBRg0TwsKmHRDBYFWDSG1fJ48HaeQ9Y6jVpoQq5So8CGJtQ2SbnbGVxeK_gUQ3TNMOD2MO0ZtkWK_sQXO4Q6mmCugBUmazLd5RrnKmPNkaob3DAaNtsl20uM7C39ZZ-UMgc4IMUwmIvDSIKzHHf-N8DKSno"><b>Researchers Submit Patent Application, "System And Method For Unsupervised Domain Adaptation Via Sliced-</b><span class="s83"><b>Wasserstein</b></span><span class="s66"><b>...</b></span></a></span><span class="s4"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p47"><span class="s2">Information Technology Newsweekly, 05/2020</span></p>
<p class="p10"><span class="s4">Newsletter<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtZ1ZT8JAEMc3gi-8abwPsiHRF6iWbqFtgiaoEH3wCODxRpZ2m6C2kFL0q_hxnen2woREH0xIQxYyafc3mT06819CmHaiKj9igqFbI9eC5YXO4TNq1AUMMyo3XbNu28wdJdVjMh0qPvE-nyL1r-ChDdBjIe0f4KdGoQG-gwvAFZwArr9ygySzDut0IUh44xBV-TEBoJ29usZ-PtI0qV6OOY7V2-hg6Wp3EsCsdDafYkSZwdz0auJx3CFx-DROU3wa82ofDAlHeeZR7Saen4mqniE6FJhF65jM2Eb58o_4hl-TDPq0ejK3yx-F3s9U6z_ZldCiF-r1bA2Lf-u9pAcfy9hq6TqqocrxVeTaTFXNxVCDSfngRXHsm_vuYqMU7YXZGzNhmmgeo1S654zt8Ez4ymO_QApgtkhWLzp3D710201lmqVLjYrkduLBWB7LE00rBmukhE_wHlVUrZMV4W-QrxwwKoFRCYzmgNVoRcKiAItKWBRg0TwsKmHRDBYFWDSG1fJ48HaeQ9Y6jVpoQq5So8CGJtQ2SbnbGVxeK_gUQ3TNMOD2MO0ZtkWK_sQXO4Q6mmCugBUmazLd5RrnKmPNkaob3DAaNtsl20uM7C39ZZ-UMgc4IMUwmIvDSIKzHHf-N8DKSno"><span class="s13">Full Text Online</span></a></span></p>
<p class="p60"><span class="s2"><br>
</span></p>
<p class="p60"><span class="s1"><b>2020 4</b></span></p>
<p class="p6"><span class="s1"><a href="https://arxiv.org/pdf/1901.07450">[PDF] arxiv.org<span class="s3"></span></a></span></p>
<p class="p65"><span class="s1"><a href="https://link.springer.com/content/pdf/10.1007/s00780-020-00426-3.pdf"><b>Adapted wasserstein distances and stability in mathematical finance</b><span class="s66"><b></b></span></a></span></p>
<p class="p47"><span class="s7"><a href="https://scholar.google.com/citations?user=tYTe58sAAAAJ&amp;hl=en&amp;oi=sra">BV Julio</a></span><span class="s2">, <a href="https://scholar.google.com/citations?user=V_uqDtUAAAAJ&amp;hl=en&amp;oi=sra"><span class="s10">D Bartl</span></a>, <a href="https://scholar.google.com/citations?user=vA3TmxcAAAAJ&amp;hl=en&amp;oi=sra"><span class="s10">B Mathias</span></a>, E Manu - Finance and Stochastics, 2020 - Springer</span></p>
<p class="p47"><span class="s2">Assume that an agent models a financial asset through a measure Q with the goal to<span class="Apple-converted-space"> </span></span></p>
<p class="p47"><span class="s2">price/hedge some derivative or optimise some expected utility. Even if the model Q is<span class="Apple-converted-space"> </span></span></p>
<p class="p47"><span class="s2">chosen in the most skilful and sophisticated way, the agent is left with the possibility that Q<span class="Apple-converted-space"> </span></span></p>
<p class="p47"><span class="s2">does not provide an exact description of reality. This leads us to the following question: will<span class="Apple-converted-space"> </span></span></p>
<p class="p47"><span class="s2">the hedge still be somewhat meaningful for models in the proximity of Q? If we measure<span class="Apple-converted-space"> </span></span></p>
<p class="p47"><span class="s2">proximity with the usual Wasserstein distance (say), the answer is No. Models which are …</span></p>
<p class="p10"><span class="s7"><a href="https://scholar.google.com/scholar?cites=6169951698317222778&amp;as_sdt=5,39&amp;sciodt=0,39&amp;hl=en">Cited by 6</a></span><span class="s4"> <a href="https://scholar.google.com/scholar?q=related:eiOEO2ESoFUJ:scholar.google.com/&amp;scioq=Adapted+Wasserstein+Distances+and+Stability+In+Mathematical+Finance&amp;hl=en&amp;as_sdt=0,39&amp;as_vis=1"><span class="s13">Related articles</span></a> <a href="https://scholar.google.com/scholar?cluster=6169951698317222778&amp;hl=en&amp;as_sdt=0,39&amp;as_vis=1"><span class="s13">All 11 versions</span></a></span></p>
<p class="p65"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV27TsMwFLWgXZgoAsSr6A4MMITm4ZBEFFCBVjCAoFAYK8dxVImShD6G8o_8E75OTCnisSBliGLFsRzr2Nc-9xxCHHvfNL5ggkeDMA5keEGZvELXEnKaMZkf-xbnThzq7LGCDnWrU2OK361RUkF3lHLcNa_ZVAUPnhecZC8G-kjheas21WCF2UJ0ZDmW68-Tso3SXyVSPm1e37Q1Wh_ICSs_eaauRAbHn8VkWuBqa5FoYpV4ZcrK8Jt4dlbI8V_bXyEVRL2MZWIAjXxQLZE5kSyTt9zJV4AB-o4lEdyNUt5jSuz5EJCUOIG2GI77oyFg5gpMiR-QxvCA9DIGnQz3GaDzObEGi3-oGHYbEcvk0hjqz2zwdPzIVI4o-nTWa-oJnOMyGBnhxbu5-vgELhO4-hCmZX39hb0VstNq3p9dGLrPuqjZHMupfNid9pizSkpJmog1ApSywOS-63E3pL5rMwlJgRlxzgMZ_NreOqn-WtXGH-WbZMHGGFtxBLdIaTQYi6qSmNwuxtI7gOXryg"><b>Finance - Finance and Stochastics; Study Results from University of Vienna Update Understanding of Finance and Stochastics (Adapted </b><span class="s83"><b>Wasserstein</b></span><span class="s66"><b>...</b></span></a></span><span class="s4"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p47"><span class="s2">Journal of mathematics (Atlanta, Ga.), Jun 30, 2020, 949</span></p>
<p class="p47"><span class="s2">Newspaper Article<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV27TsMwFLWgXZgoAsSr6A4MMITm4ZBEFFCBVjCAoFAYK8dxVImShD6G8o_8E75OTCnisSBliGLFsRzr2Nc-9xxCHHvfNL5ggkeDMA5keEGZvELXEnKaMZkf-xbnThzq7LGCDnWrU2OK361RUkF3lHLcNa_ZVAUPnhecZC8G-kjheas21WCF2UJ0ZDmW68-Tso3SXyVSPm1e37Q1Wh_ICSs_eaauRAbHn8VkWuBqa5FoYpV4ZcrK8Jt4dlbI8V_bXyEVRL2MZWIAjXxQLZE5kSyTt9zJV4AB-o4lEdyNUt5jSuz5EJCUOIG2GI77oyFg5gpMiR-QxvCA9DIGnQz3GaDzObEGi3-oGHYbEcvk0hjqz2zwdPzIVI4o-nTWa-oJnOMyGBnhxbu5-vgELhO4-hCmZX39hb0VstNq3p9dGLrPuqjZHMupfNid9pizSkpJmog1ApSywOS-63E3pL5rMwlJgRlxzgMZ_NreOqn-WtXGH-WbZMHGGFtxBLdIaTQYi6qSmNwuxtI7gOXryg"><span class="s10">Full Text Online</span></a><span class="Apple-converted-space"> </span></span></p>
<p class="p47"><span class="s2">Global IP News. Information Technology Patent News, Apr 23, 2020<span class="Apple-converted-space">  </span>pate\</span></p>
<p class="p47"><span class="s2">Newspaper Article<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV1LSwMxEB60vXiyouKrZQ5e1-7T7kJVqm3poUqtL_BSspssFG127bYXf4E_20x2F6mIXoSwhwRCQoZvZjaZ7wNw7BPT-IYJLTcI40ClFy5TLfQsodyMyfzYt6LIicOyeqx4DnVblsYUx12ipIZunkT017xJot4WOSzvIn0zSEeK7ltLUQ1WiC3wM8uxPH8dqjZRf1Wgetm7GY1XoTcoYLO_CeX7KfHOtGLhD2nrKl_jvy6zBjUCt5SlYo6d3Ha2YE3IbfgYjIc4zC0jofVgHqdmqKJbHKnIVC4wkZgznSOTHK-1CLUef5DZMiX0yQTHbjJjU4kdztL8vh8fpwzvXhU0caM9Y_OX8yemqz1JcbPd1D3YpYBWWeIOHPd791cDo9zuhFiVY-Vss8nXZp1dqMhEij1A3-FWEAtTMJWbuSFnpq--p5ErSCE0au1D_depDv4YP4QNm7Jg0zVs5wgqi_lS1DUJZKM47Qasj7znT9VWzzo"><span class="s10">Full Text Online</span></a><span class="Apple-converted-space"> </span></span></p>
<p class="p47"><span class="s2"><br>
</span></p>
<p class="p47"><span class="s2">2020 5</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=AdvancedSearch&amp;qid=1&amp;SID=5DAhiL6Y9nmTB2u2kek&amp;page=1&amp;doc=21">Wasserstein distance based rapid image enhancing method, involves inputting constructed data set into deep learning model, and inputting to-be-processed motion blur image into deep learning model to obtain clear and full-color image<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p47"><span class="s2">Patent Number: CN111476721-A<span class="Apple-converted-space"> </span></span></p>
<p class="p47"><span class="s2">Patent Assignee: UNIV CHONGQING POSTS &amp; TELECOM<span class="Apple-converted-space"> </span></span></p>
<p class="p47"><span class="s2">Inventor(s): FENG J; QI S; WU S.</span></p>
<p class="p60"><span class="s2"><br>
</span></p>
<p class="p66"><span class="s23"><a href="https://www.sci-en-tech.com/ICCM2020/PDFs/4455-14251-1-PB.pdf"><b><span class="Apple-converted-space"> </span></b></a></span><span class="s18"><b>2020 6</b></span></p>
<p class="p66"><span class="s23"><a href="https://patentimages.storage.googleapis.com/c3/a3/e7/a2964f59d36632/US20200342361A1.pdf"><b>[PDF]</b><span class="s92"> googleapis.com</span></a></span></p>
<p class="p67"><span class="s23"><a href="https://patents.google.com/patent/US20200342361A1/en"><b>Wasserstein </b><span class="s92">barycenter <b>model </b>ensembling</span></a></span></p>
<p class="p68"><span class="s23"><a href="https://scholar.google.com/citations?user=6F90JHgAAAAJ&amp;hl=en&amp;oi=sra">Y Mroueh</a></span><span class="s18">, <a href="https://scholar.google.com/citations?user=goQ8S1YAAAAJ&amp;hl=en&amp;oi=sra"><span class="s13">PL Dognin</span></a>, I Melnyk, J Ross… - US Patent App. 16 …, 2020 - Google Patents</span></p>
<p class="p68"><span class="s18">A method, system and apparatus of ensembling, including inputting a set of models that</span></p>
<p class="p68"><span class="s18">predict different sets of attributes, determining a source set of attributes and a target set of</span></p>
<p class="p68"><span class="s18">attributes using a barycenter with an optimal transport metric, and determining a consensus …</span></p>
<p class="p66"><span class="s93">  <a href="https://scholar.google.com/scholar?cluster=6840644073282028729&amp;hl=en&amp;as_sdt=7,39&amp;as_ylo=2020&amp;as_yhi=2020"><span class="s94">All 2 versions</span></a> </span></p>
<p class="p60"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2020 7</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN111460367A/en?q=wgan&amp;oq=wgan">… data leakage of halogen conveying pipeline based on S transformation/<span class="s1"><b>WGAN</b></span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/0d/14/20/89781e4abb4878/CN111460367A.pdf"><span class="s5">CN111460367A</span></a> </span><span class="s19">徐敏</span><span class="s18"> </span><span class="s19">淮阴工学院</span></p>
<p class="p14"><span class="s18">Priority 2020-03-20 • Filed 2020-03-20 • Published 2020-07-28</span></p>
<p class="p15"><span class="s2">4. The algorithm for resolving data imbalance of leakage in a brine transporting pipeline based on S transform/<b>WGAN</b> of claim 1, wherein the <b>WGAN</b> model mainly comprises a generator g (z) and a discriminator d (x); the generator G (z) is used for learning the real signal distribution of the leakage …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p69"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p15"><span class="s2">2020 8<span class="Apple-tab-span">	</span></span></p>
<p class="p15"><span class="s2">online <span class="Apple-converted-space">  </span>OPEN ACCESS<span class="Apple-tab-span">	</span></span></p>
<p class="p15"><span class="s2">METHODS AND DEVICES PERFORMING ADAPTIVE QUADRATIC WASSERSTEIN FULL-WAVEFORM...</span></p>
<p class="p15"><span class="s2">by WANG, Diancheng; WANG, Ping</span></p>
<p class="p15"><span class="s2">10/2020</span></p>
<p class="p15"><span class="s2">Methods and devices for seismic exploration of an underground structure apply W2-based full-wave inversion to transformed synthetic and seismic data. Data...</span></p>
<p class="p15"><span class="s2">PatentAvailable Online</span></p>
<p class="p15"><span class="s2"><span class="Apple-converted-space"> </span>Preview<span class="Apple-converted-space"> </span></span></p>
<p class="p15"><span class="s2"><span class="Apple-converted-space"> </span>Cite this item Email this item Save this item More actions</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p69"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p15"><span class="s2">2020 9<span class="Apple-tab-span">	</span>online<span class="Apple-converted-space">  </span>OPEN ACCESS<span class="Apple-tab-span">	</span></span></p>
<p class="p15"><span class="s2">Image rapid enhancement method based on Wasserstein distance</span></p>
<p class="p15"><span class="s2">by QI SHUANG; WU SHANHONG; FENG JIANGFAN</span></p>
<p class="p15"><span class="s2">07/2020</span></p>
<p class="p15"><span class="s2">The invention relates to an image rapid enhancement method based on a Wasserstein distance, and belongs to the field of computer vision. The method comprises...</span></p>
<p class="p15"><span class="s2">PatentAvailable Online</span></p>
<p class="p14"><span class="s18"><span class="Apple-converted-space"> </span></span><span class="s2"><br>
</span></p>
<p class="p15"><span class="s2">2020 10<span class="Apple-tab-span">	</span>online OPEN ACCESS<span class="Apple-tab-span">	</span></span></p>
<p class="p15"><span class="s2">Depth domain adaptive image classification method based on Waserstein distance</span></p>
<p class="p15"><span class="s2">by WU QIANG; LIU JU; SUN SHUANG ; More...</span></p>
<p class="p15"><span class="s2">07/2020</span></p>
<p class="p15"><span class="s2">The invention provides a Wasserstein distance-based depth domain adaptive image classification method and apparatus, and a computer readable storage medium....</span></p>
<p class="p15"><span class="s2">PatentAvailable Online</span></p>
<p class="p69"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p15"><span class="s2">2020 11<span class="Apple-tab-span">	</span>online OPEN ACCESS<span class="Apple-tab-span">	</span></span></p>
<p class="p70"><span class="s1"><a href="https://patents.google.com/?q=Method+for+embedding+and+clustering+depth+self-coding+based+on+Sliced-Waserstein&amp;oq=Method+for+embedding+and+clustering+depth+self-coding+based+on+Sliced-Waserstein+">Method for embedding and clustering depth self-coding based on Sliced-Waserstein distance<span class="s95"></span></a></span></p>
<p class="p15"><span class="s2">by CHEN HUAHUA; YING NA; GUO CHUNSHENG ; More...</span></p>
<p class="p15"><span class="s2">05/2020</span></p>
<p class="p15"><span class="s2">The invention discloses a deep self-encoding embedding clustering method based on a Sliced-Waserstein distance. The method comprises the following steps: S11,...</span></p>
<p class="p15"><span class="s2">PatentAvailable Online</span></p>
<p class="p14"><span class="s18"><span class="Apple-converted-space"> </span></span><span class="s2"><br>
</span></p>
<p class="p15"><span class="s2">2020 12<span class="Apple-tab-span">	</span>online OPEN ACCESS<span class="Apple-tab-span">	</span></span></p>
<p class="p15"><span class="s2">Semi-supervised deep learning fault diagnosis method based on Wasserstein distance and...</span></p>
<p class="p15"><span class="s2">by SONG ZHIHUAN; GE ZHIQIANG; ZHANG HONGYI</span></p>
<p class="p15"><span class="s2">04/2020</span></p>
<p class="p15"><span class="s2">The invention discloses a semi-supervised deep learning fault diagnosis method based on a Wasserstein distance and an auto-encoder. The semi-supervised deep...</span></p>
<p class="p15"><span class="s2">PatentAvailable Online</span></p>
<p class="p15"><span class="s2"><span class="Apple-converted-space"> </span>Preview<span class="Apple-converted-space"> </span></span></p>
<p class="p15"><span class="s2"><span class="Apple-converted-space"> </span>Cite this item Email this item Save this item More actions</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p15"><span class="s2">2020 13<span class="Apple-tab-span">	</span>online OPEN ACCESS<span class="Apple-tab-span">	</span></span></p>
<p class="p15"><span class="s2">Wind power output typical scene generation method based on BIRCH clustering and Wasserstein distance</span></p>
<p class="p15"><span class="s2">by JIANG HUI; WANG SHENGQIANG; WANG DONG ; More...</span></p>
<p class="p15"><span class="s2">03/2020</span></p>
<p class="p15"><span class="s2">The invention discloses a wind power output typical scene generation method based on BIRCH clustering and a Wasserstein distance, and the method comprises the...</span></p>
<p class="p15"><span class="s2">PatentAvailable Online</span></p>
<p class="p15"><span class="s2"><span class="Apple-converted-space"> </span>Preview<span class="Apple-converted-space"> </span></span></p>
<p class="p15"><span class="s2"><span class="Apple-converted-space"> </span>Cite this item Email this item Save this item More actions</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p15"><span class="s2">2020 14<span class="Apple-converted-space">  </span>online<span class="Apple-converted-space">  </span>OPEN ACCESS<span class="Apple-tab-span">	</span></span></p>
<p class="p15"><span class="s2">Fault diagnosis method for deep adversarial migration network based on Wasserstein distance</span></p>
<p class="p15"><span class="s2">by SHI YONGFANG; XU PENGFEI; HUANG JINGKUN ; More...</span></p>
<p class="p15"><span class="s2">03/2020</span></p>
<p class="p15"><span class="s2">The invention discloses a fault diagnosis method for a deep adversarial migration network based on a Wasserstein distance. The distance of the feature...</span></p>
<p class="p15"><span class="s2">PatentAvailable Online</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p15"><span class="s2">2020 15<span class="Apple-tab-span">	</span>online<span class="Apple-converted-space">  </span>OPEN ACCESS<span class="Apple-tab-span">	</span></span></p>
<p class="p20"><span class="s2">基于</span><span class="s9">Wasserstein</span><span class="s2">距离的人脸性别判别算法</span></p>
<p class="p15"><span class="s2">04/2020<span class="Apple-converted-space">  </span>...</span></p>
<p class="p15"><span class="s2">PatentAvailable Online</span></p>
<p class="p14"><span class="s18"><span class="Apple-converted-space"> </span></span><span class="s2"><br>
</span></p>
<p class="p15"><span class="s2">2020 16<span class="Apple-tab-span">	</span></span></p>
<p class="p15"><span class="s2">online</span></p>
<p class="p15"><span class="s2"><span class="Apple-converted-space"> </span>OPEN ACCESS<span class="Apple-tab-span">	</span></span></p>
<p class="p20"><span class="s2">基于信号分布</span><span class="s9">Wasserstein</span><span class="s2">距离度量的</span><span class="s9">Wi-Fi</span><span class="s2">室内定位方法</span></p>
<p class="p15"><span class="s2">10/2020<span class="Apple-converted-space">  </span>...</span></p>
<p class="p15"><span class="s2">PatentAvailable Online</span></p>
<p class="p42"><span class="s18"><span class="Apple-converted-space"> </span></span></p>
<p class="p15"><span class="s2">2020 17<span class="Apple-tab-span">	</span>online OPEN ACCESS<span class="Apple-tab-span">	</span></span></p>
<p class="p15"><span class="s11">一种基于</span><span class="s2">Wasserstein GAN</span><span class="s11">的光伏阵列故障诊断方法</span></p>
<p class="p15"><span class="s2">05/2020</span></p>
<p class="p20"><span class="s2">本发明涉及一种基于</span><span class="s9">Wasserstein GAN</span><span class="s2">的光伏阵列故障诊断方法，首先对光伏阵列电流、电压时序数据进行采集；接着将获取的光伏阵列时序电流与时序电压数据绘制为曲线图形并保存为样本；然后设计</span><span class="s9">Wasserstein GAN</span><span class="s2">网络中的鉴别器</span><span class="s9">D</span><span class="s2">与生成器</span><span class="s9">G</span><span class="s2">；然后训练</span><span class="s9">Wasserstein...</span></p>
<p class="p15"><span class="s2">PatentAvailable Online</span></p>
<p class="p15"><span class="s2"><span class="Apple-converted-space"> </span>Preview<span class="Apple-converted-space"> </span></span></p>
<p class="p10"><span class="s2"><br>
</span></p>
<p class="p10"><span class="s2">2020 18</span></p>
<p class="p71"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwfV1bT8IwFD5RvL4pahQvqS97Q3S3joRpoAN9cRAl-kjGVgSBbYEZo7_ecyoIMdG3rU26tN25ff3OKYChX1wWf-mEKx7ZaBkC0wx70uE8Mi1DlsPQDCgC-eaSL9GhXuepMaps6LuqlYgCFqL4Z0p9pwtMy1NUy2mpO8Cm5KbRdj1tFiwTDqc7mldz662m1xSaEK7wNf_BpW_aqLx5dRXW0KV3SDjqTzVKUkmXLUxjB9ZbOFqc7cLKZz8PW2J-EVseNu9n59952FCEzXCKjTOhnO7BR3X0kmCM3x8z9EAZ_kwEErDBuEu0xVCypMdGMhii5mBECKX3PmE2MmaKdE6ZTiwdpJSaLhnZtYglMXtk2ZJXm8SlyjiYDK-fb6t-paQe9-G8UW-LuyLOpvOzdB3hLyZuHEAuTmJ5CCyyI84tKuyud02u01FfGNnoOFi25FZQPoLC3-MU_us8hm3aBgJDdecEctnkTZ6q-oxnar2_ALz2oKU">Algorithm for solving imbalance of leakage data of halogen conveying pipeline based on S transformation/<span class="s96"><b>WGAN</b></span></a></span></p>
<p class="p72"><span class="s2">by </span><span class="s1">ZHAO JIANYANG</span><span class="s2">; </span><span class="s1">SHAN JINGSONG</span><span class="s2">; </span><span class="s1">DING WEIHONG</span><span class="s2"> ; </span><span class="s1">More...</span></p>
<p class="p73"><span class="s2">07/2020</span></p>
<p class="p74"><span class="s2">The invention relates to the technical field of halogen conveying pipeline detection, and discloses an algorithm for solving imbalance of leakage data of a...</span></p>
<p class="p74"><span class="s2">Patent<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwfV1bT8IwFD5RvL4pahQvqS97Q3S3joRpoAN9cRAl-kjGVgSBbYEZo7_ecyoIMdG3rU26tN25ff3OKYChX1wWf-mEKx7ZaBkC0wx70uE8Mi1DlsPQDCgC-eaSL9GhXuepMaps6LuqlYgCFqL4Z0p9pwtMy1NUy2mpO8Cm5KbRdj1tFiwTDqc7mldz662m1xSaEK7wNf_BpW_aqLx5dRXW0KV3SDjqTzVKUkmXLUxjB9ZbOFqc7cLKZz8PW2J-EVseNu9n59952FCEzXCKjTOhnO7BR3X0kmCM3x8z9EAZ_kwEErDBuEu0xVCypMdGMhii5mBECKX3PmE2MmaKdE6ZTiwdpJSaLhnZtYglMXtk2ZJXm8SlyjiYDK-fb6t-paQe9-G8UW-LuyLOpvOzdB3hLyZuHEAuTmJ5CCyyI84tKuyud02u01FfGNnoOFi25FZQPoLC3-MU_us8hm3aBgJDdecEctnkTZ6q-oxnar2_ALz2oKU"><span class="s97">Available Online</span></a></span></p>
<p class="p74"><span class="s2"><br>
</span></p>
<p class="p10"><span class="s97"><span class="Apple-converted-space">  </span></span><span class="s2">2020<span class="Apple-tab-span">	</span>19</span></p>
<p class="p51"><span class="s2">一种基于</span><span class="s9">WGAN</span><span class="s2">的超参数动态调整方法</span></p>
<p class="p10"><span class="s2">09/2020</span></p>
<p class="p10"><span class="s2">PatentAvailable Onlin<br>
</span></p>
<p class="p10"><span class="s2">2020<span class="Apple-tab-span">	</span>20</span></p>
<p class="p10"><span class="s2">online</span></p>
<p class="p10"><span class="s2"><span class="Apple-converted-space"> </span>OPEN ACCESS<span class="Apple-tab-span">	</span></span></p>
<p class="p10"><span class="s2">Building energy consumption prediction method based on WGAN algorithm and monitoring and...</span></p>
<p class="p10"><span class="s2">by LU YOU; WANG ZHECHAO; WU HONGJIE ; More...</span></p>
<p class="p10"><span class="s2">05/2020</span></p>
<p class="p10"><span class="s2">The invention relates to a building energy consumption prediction method based on a WGAN algorithm and a building energy consumption monitoring and prediction...</span></p>
<p class="p10"><span class="s2">PatentAvailable Online<br>
</span></p>
<p class="p10"><span class="s2">2020<span class="Apple-tab-span">	</span>21</span></p>
<p class="p10"><span class="s2">online</span></p>
<p class="p10"><span class="s2"><span class="Apple-converted-space"> </span>OPEN ACCESS<span class="Apple-tab-span">	</span></span></p>
<p class="p51"><span class="s2">基于改进</span><span class="s9">WGAN-GP</span><span class="s2">的多波段图像同步融合与增强方法</span></p>
<p class="p10"><span class="s2">09/2020</span></p>
<p class="p10"><span class="s2">PatentAvailable Online</span></p>
<p class="p10"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2020 22</span></p>
<p class="p9"><span class="s4"><span class="Apple-converted-space"> </span><a href="https://patents.google.com/patent/US20200342361A1/en?q=wasserstein"><span class="s21"><b>Wasserstein</b> barycenter model ensembling</span></a></span></p>
<p class="p14"><span class="s18">US <a href="https://patentimages.storage.googleapis.com/c3/a3/e7/a2964f59d36632/US20200342361A1.pdf"><span class="s5">US20200342361A1</span></a> Youssef Mroueh International Business Machines Corporation</span></p>
<p class="p14"><span class="s18">Priority 2019-04-29 • Filed 2019-04-29 • Published 2020-10-29</span></p>
<p class="p15"><span class="s2">10 . The system according to claim 9 , further comprising inputting side information into the barycenter, wherein the barycenter comprises a <b>Wasserstein</b> barycenter with a <b>Wasserstein</b> distance metric. 11 . The system according to claim 9 , further comprising a plurality of the barycenters to determine …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p10"><span class="s2">2020 23</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN112307514A/en?q=wasserstein">Difference privacy greedy grouping method adopting <span class="s1"><b>Wasserstein</b> distance</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/00/3d/e3/36a06d2a3c1bdf/CN112307514A.pdf"><span class="s5">CN112307514A</span></a> </span><span class="s19">杨悦</span><span class="s18"> </span><span class="s19">哈尔滨工程大学</span></p>
<p class="p14"><span class="s18">Priority 2020-11-26 • Filed 2020-11-26 • Published 2021-02-02</span></p>
<p class="p14"><span class="s18">1. A differential privacy greedy grouping method adopting <b>Wasserstein</b> distance is characterized by comprising the following steps: step 1: reading a data set D received at the ith time point i </span><span class="s19">；</span><span class="s18"> Step 2: will D i Data set D released from last time point i-1 Performing <b>Wasserstein</b> distance similarity …</span></p>
<p class="p10"><span class="s2"><br>
2020 24</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN111741429A/en?q=wasserstein">Wi-Fi indoor positioning method based on signal distribution <span class="s1"><b>Wasserstein</b> …</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/10/70/db/0397a4bcc2caa9/CN111741429A.pdf"><span class="s5">CN111741429A</span></a> </span><span class="s19">周牧</span><span class="s18"> </span><span class="s19">重庆邮电大学</span></p>
<p class="p14"><span class="s18">Priority 2020-06-23 • Filed 2020-06-23 • Published 2020-10-02</span></p>
<p class="p15"><span class="s2">2. The Wi-Fi indoor positioning method based on the signal distribution <b>Wasserstein</b> distance metric according to claim 1, wherein said ninth step comprises the steps of: step nine (one), w corresponding to each RP m,n Sequencing all RPs from small to large to obtain an RP sequencing set u related to …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p15"><span class="s2">2020 25</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN111476721A/en?q=wasserstein&amp;page=1"><b>Wasserstein</b><span class="s1"> distance-based image rapid enhancement method</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/cc/2c/89/09bba020aa1a16/CN111476721A.pdf"><span class="s5">CN111476721A</span></a> </span><span class="s19">丰江帆</span><span class="s18"> </span><span class="s19">重庆邮电大学</span></p>
<p class="p14"><span class="s18">Priority 2020-03-10 • Filed 2020-03-10 • Published 2020-07-31</span></p>
<p class="p14"><span class="s18">4. The <b>Wasserstein</b> distance-based image rapid enhancement method according to claim 3, characterized in that: in step S21, the motion-blurred image has 256 features, including texture features, color features, and edge features. 5. The <b>Wasserstein</b> distance-based image rapid enhancement method …</span><span class="s98"><br>
</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s18">2020 26</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=1">Method for model ensembling e.g. Wasserstein barycenter model ensembling, involves inputting set of models that predict different sets of attributes and determining source set of attributes and target set of attributes using barycenter<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: US2020342361-A1<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: INT BUSINESS MACHINES CORP<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): MROUEH Y; DOGNIN P L; MELNYK I; et al.</span></p>
<p class="p14"><span class="s12"><span class="Apple-converted-space"> </span></span><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2"><span class="Apple-converted-space"> </span>2020<span class="Apple-converted-space">  </span>27</span></p>
<p class="p10"><span class="s23"><a href="https://patents.google.com/patent/CN112634390A/en?q=wasserstein&amp;before=priority:20201231&amp;after=priority:20200101&amp;oq=2020+wasserstein"><b>Wasserstein</b><span class="s13">-based high-energy image synthesis method and device for generating …</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/78/56/b2/0fdbf4cef037ff/CN112634390A.pdf"><span class="s5">CN112634390A </span></a></span><span class="s19">郑海荣</span><span class="s18"> </span><span class="s19">深圳先进技术研究院</span></p>
<p class="p14"><span class="s18">Priority 2020-12-17 • Filed 2020-12-17 • Published 2021-04-09</span></p>
<p class="p14"><span class="s18">updating the preset generation countermeasure network model based on the first loss value and the first judgment result until the preset generation countermeasure network model converges, and determining the converged preset generation countermeasure network model as the <b>Wasserstein</b> generation …</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space"> </span>2020 78</span></p>
<p class="p10"><span class="s12"> <a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=AdvancedSearch&amp;qid=1&amp;SID=6D6mCWjr9ONXqijKiNB&amp;page=1&amp;doc=21"><span class="s13">Method for estimating time delay distance, involves calculating time delay for each unique pair of multiple sensors by minimizing Wasserstein distance between two cumulative distribution transforms corresponding to unique pair</span></a></span></p>
<p class="p5"><span class="s2">Patent Number: US2021281361-A1</span></p>
<p class="p5"><span class="s2">Patent Assignee: US SEC OF NAVY</span></p>
<p class="p5"><span class="s2"><br>
<span class="Apple-converted-space"> </span>2020 79</span></p>
<p class="p9"><span class="s27"><a href="https://patents.google.com/patent/CN111476721A/en?q=wasserstein&amp;page=1"><b>Wasserstein</b><span class="s35"> distance-based image rapid enhancement method</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/cc/2c/89/09bba020aa1a16/CN111476721A.pdf"><span class="s16">CN111476721A</span></a> </span><span class="s19">丰江帆</span><span class="s18"> </span><span class="s19">重庆邮电大学</span></p>
<p class="p14"><span class="s18">Priority 2020-03-10 • Filed 2020-03-10 • Published 2020-07-31</span></p>
<p class="p15"><span class="s2">4. The <b>Wasserstein</b> distance-based image rapid enhancement method according to claim 3, characterized in that: in step S21, the motion-blurred image has 256 features, including texture features, color features, and edge features. 5. The <b>Wasserstein</b> distance-based image rapid enhancement method …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p75"><span class="s2"><br>
</span></p>
<p class="p17"><span class="s1"><a href="https://patents.google.com/?q=Text+generation+based+method+for+realizing+Wasserstein+generative+adversarial+network%2c+involves+encoding+text+data%2c+ob&amp;scholar&amp;oq=Text+generation+based+method+for+realizing+Wasserstein+generative+adversarial+network%2c+involves+encoding+text+data%2c+ob">2020<span class="Apple-converted-space"> </span></a></span><span class="s5"> 80</span></p>
<p class="p17"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=30">Text generation based method for realizing Wasserstein generative adversarial network, involves encoding text data, obtaining output text producer, and obtaining input and output arbiter text by generator for performing network training<span class="Apple-converted-space"> </span><span class="s95"></span></a></span></p>
<p class="p75"><span class="s2">Patent Number: CN107590531-A<span class="Apple-converted-space"> </span></span></p>
<p class="p75"><span class="s2">Patent Assignee: UNIV SOUTH CHINA TECHNOLOGY<span class="Apple-converted-space"> </span></span></p>
<p class="p75"><span class="s2">Inventor(s): ZHOU Z; LI L.</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2020 81</span></p>
<p class="p17"><span class="s1"><a href="https://patents.google.com/patent/CN111741429A/en?q=wasserstein&amp;oq=wasserstein">Wi-Fi indoor positioning method based on signal distribution Wasserstein<span class="s95"></span></a></span></p>
<p class="p76"><span class="s2">distance measurement.</span></p>
<p class="p14"><span class="s2">CN CN111741429A </span><span class="s11">周牧</span><span class="s2"> </span><span class="s11">重庆邮电大学</span></p>
<p class="p14"><span class="s2">Priority 2020-06-23 • Filed 2020-06-23 • Published 2020-10-02</span></p>
<p class="p14"><span class="s2">2. The Wi-Fi indoor positioning method based on the signal distribution Wasserstein distance metric according to claim 1, wherein said ninth step comprises the steps of: step nine (one), w corresponding to each RP m,n Sequencing all RPs from small to large to obtain an RP sequencing set u related to …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2020 82</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/WO2022126480A1/en?q=wasserstein&amp;before=priority:20201231&amp;after=priority:20200101&amp;oq=2020+wasserstein">High-energy image synthesis method and device based on <span class="s16"><b>wasserstein</b> generative …</span></a></span></p>
<p class="p14"><span class="s18"><i>WO</i> <a href="https://patentimages.storage.googleapis.com/ef/a1/e1/54cadadb290582/WO2022126480A1.pdf"><span class="s16">WO2022126480A1</span></a> </span><span class="s19">郑海荣</span><span class="s18"> </span><span class="s19">深圳先进技术研究院</span></p>
<p class="p14"><span class="s18">Filed 2020-12-17 • Published 2022-06-23</span></p>
<p class="p14"><span class="s18">The preset generative adversarial network model is updated based on the first loss value and the first discrimination result until the preset generative adversarial network model converges, and the converged preset generative adversarial network model is determined as the <b>Wasserstein</b> generative …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2020 83</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN112307514A/en?q=wasserstein&amp;before=priority:20201231&amp;after=priority:20200101&amp;oq=2020+wasserstein">Difference privacy greedy grouping method adopting <span class="s16"><b>Wasserstein</b> distance</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/00/3d/e3/36a06d2a3c1bdf/CN112307514A.pdf"><span class="s16">CN112307514A</span></a> </span><span class="s19">杨悦</span><span class="s18"> </span><span class="s19">哈尔滨工程大学</span></p>
<p class="p14"><span class="s18">Priority 2020-11-26 • Filed 2020-11-26 • Published 2021-02-02</span></p>
<p class="p14"><span class="s18">1. A differential privacy greedy grouping method adopting <b>Wasserstein</b> distance is characterized by comprising the following steps: step 1: reading a data set D received at the ith time point i </span><span class="s19">；</span><span class="s18"> Step 2: will D i Data set D released from last time point i-1 Performing <b>Wasserstein</b> distance similarity …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2020 84</span></p>
<p class="p10"><span class="s18">System and Method for Generaring Highly Dense 3D Point Clouds using <b>Wasserstein</b> …</span></p>
<p class="p14"><span class="s27"><a href="https://patentimages.storage.googleapis.com/ff/2f/90/c72aaaedb0bc6c/KR20220088216A.pdf">KR20220088216A</a></span><span class="s18"> </span><span class="s78">권준석</span><span class="s18"> </span><span class="s78">중앙대학교</span><span class="s18"> </span><span class="s78">산학협력단</span></p>
<p class="p14"><span class="s18">Filed 2020-12-18 • Published 2022-06-27</span></p>
<p class="p14"><span class="s18">The present invention generates a high-resolution 3D point cloud using a <b>Wasserstein</b> distribution to generate a set of several 3D points by generating several input vectors from a prior distribution and expressing it as a <b>Wasserstein</b> distribution A prior distribution input unit for inputting a …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2020 85</span></p>
<p class="p10"><span class="s15">Multi<a href="https://patents.google.com/patent/CN111696066A/en?q=wgan&amp;before=priority:20201231&amp;after=priority:20200101&amp;oq=2020+wgan"><span class="s99">-band image synchronous fusion and enhancement method based on improved <b>WGAN</b>-GP</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/e9/fa/5c/e64cc2b9dfeed1/CN111696066A.pdf"><span class="s16">CN111696066A</span></a> </span><span class="s19">李大威</span><span class="s18"> </span><span class="s19">中北大学</span></p>
<p class="p14"><span class="s18">Priority 2020-06-13 • Filed 2020-06-13 • Published 2020-09-22</span></p>
<p class="p14"><span class="s18">1. The multiband image synchronous fusion and enhancement method based on the improved <b>WGAN</b>-GP is characterized by comprising the following steps of: designing and constructing a generation countermeasure network: generating a countermeasure network into a generator model and a discriminator model;</span><span class="s100"><span class="Apple-converted-space"> </span></span></p>
<p class="p12"><span class="s17"><a href="https://link.springer.com/chapter/10.1007/978-3-030-32692-0_19"><span class="Apple-converted-space"> </span><span class="s1"></span></a></span></p>
<p class="p77"><span class="s2">2020 86</span></p>
<p class="p8"><span class="s17"><a href="https://patents.google.com/patent/CN112966429A/en?q=wgans&amp;oq=wgans">Non-linear industrial process modeling method based on <span class="s16"><b>WGANs</b> data enhancement</span></a></span></p>
<p class="p9"><span class="s93">CN <a href="https://patentimages.storage.googleapis.com/f5/b1/6b/28b87e182216c8/CN112966429A.pdf"><span class="s16">CN112966429A </span></a></span><span class="s101">褚菲</span><span class="s93"> </span><span class="s101">中国矿业大学</span></p>
<p class="p77"><span class="s18">Priority 2020-08-11 • Filed 2020-08-11 • Published 2021-06-15</span></p>
<p class="p78"><span class="s2">2. The <b>WGANs</b> data enhancement-based nonlinear industrial process modeling method of claim 1, wherein: the step B comprises the following steps: preprocessing the data set acquired in the step A, and specifically comprises the following steps: 1) the initial acquisition data comprises industrial …<a href="https://patents.google.com/patent/CN112634390A/en?q=wasserstein&amp;before=priority:20201231&amp;after=priority:20200101&amp;oq=2020+wasserstein"><span class="s8"><b> </b></span></a><a href="https://link.springer.com/chapter/10.1007/978-3-030-34914-1_29"><span class="s8"><span class="Apple-converted-space"> </span></span></a></span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s52">2</span><span class="s2">2020 87</span></p>
<p class="p10"><span class="s18">… attack flow data enhancement method and system combining self-encoder and <b>WGAN</b></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/09/a9/5a/45b27fbb694e4c/CN112688928A.pdf"><span class="s16">CN112688928A </span></a></span><span class="s19">姚叶鹏</span><span class="s18"> </span><span class="s19">中国科学院信息工程研究所</span></p>
<p class="p14"><span class="s18">Priority 2020-12-18 • Filed 2020-12-18 • Published 2021-04-20</span></p>
<p class="p14"><span class="s18">The invention discloses a network attack flow data enhancement method and system combining a self-encoder and a <b>WGAN</b>, which relate to the field of network space security, abnormal flow detection of a communication network and the field of artificial intelligence.</span></p>
<p class="p79"><span class="s2"><br>
</span></p>
<p class="p80"><span class="s2">2020 88. patent</span></p>
<p class="p81"><span class="s17"><a href="https://patents.google.com/patent/CN112966429A/en?q=TI%3d(wgans)&amp;num=25&amp;oq=TI%3d(wgans)&amp;sort=new">Non-linear industrial process modeling method based on <span class="s102"><b>WGANs</b> data enhancement</span></a></span></p>
<p class="p82"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/f5/b1/6b/28b87e182216c8/CN112966429A.pdf"><span class="s103">CN112966429A </span></a></span><span class="s19">褚菲</span><span class="s18"> </span><span class="s19">中国矿业大学</span></p>
<p class="p83"><span class="s18">Priority 2020-08-11 • Filed 2020-08-11 • Published 2021-06-15</span></p>
<p class="p84"><span class="s18">2. The <b>WGANs</b> data enhancement-based nonlinear industrial process modeling method of claim 1, wherein: the step B comprises the following steps: preprocessing the data set acquired in the step A, and specifically comprises the following steps: 1) the initial acquisition data comprises industrial …</span></p>
<p class="p84"><span class="s2"><br>
</span></p>
<p class="p80"><span class="s2">2020 89. patent</span></p>
<p class="p81"><span class="s17"><a href="https://patents.google.com/patent/CN112307514A/en?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new&amp;page=1">Difference privacy greedy grouping method adopting <span class="s102"><b>Wasserstein</b> distance</span></a></span></p>
<p class="p82"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/00/3d/e3/36a06d2a3c1bdf/CN112307514A.pdf"><span class="s103">CN112307514A </span></a></span><span class="s19">杨悦</span><span class="s18"> </span><span class="s19">哈尔滨工程大学</span></p>
<p class="p83"><span class="s18">Priority 2020-11-26 • Filed 2020-11-26 • Published 2021-02-02</span></p>
<p class="p84"><span class="s18">1. A differential privacy greedy grouping method adopting <b>Wasserstein</b> distance is characterized by comprising the following steps: step 1: reading a data set D received at the ith time point i </span><span class="s19">；</span><span class="s18"> Step 2: will D i Data set D released from last time point i-1 Performing <b>Wasserstein</b> distance similarity …</span></p>
<p class="p84"><span class="s2"><br>
</span></p>
<p class="p80"><span class="s2">2020 90. patent</span></p>
<p class="p81"><span class="s17"><a href="https://patents.google.com/patent/CN111741429B/en?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new&amp;page=1">Wi-Fi indoor positioning method based on signal distribution <span class="s102"><b>Wasserstein</b> …</span></a></span></p>
<p class="p82"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/e6/10/71/3470113aa38d0c/CN111741429B.pdf"><span class="s103">CN111741429B </span></a></span><span class="s19">周牧</span><span class="s18"> </span><span class="s19">重庆邮电大学</span></p>
<p class="p83"><span class="s18">Priority 2020-06-23 • Filed 2020-06-23 • Granted 2022-05-03 • Published 2022-05-03</span></p>
<p class="p84"><span class="s18">1. the Wi-Fi indoor positioning method based on signal distribution <b>Wasserstein</b> distance measurement is characterized by comprising the following steps of: step one, off-line stage, the Wi-Fi received signal from the mth AP at the nth Reference Point (RP) is strengthenedThe sequence of degrees ( …</span></p>
<p class="p84"><span class="s2"><br>
</span></p>
<p class="p80"><span class="s2">2020 91. patent</span></p>
<p class="p85"><span class="s23"><a href="https://patents.google.com/patent/CN111428803A/en?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new&amp;page=1"><b>Wasserstein</b><span class="s102"> distance-based depth domain adaptive image classification method</span></a></span></p>
<p class="p82"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/af/c1/06/95a3e2be27b757/CN111428803A.pdf"><span class="s103">CN111428803A </span></a></span><span class="s19">吴强</span><span class="s18"> </span><span class="s19">山东大学</span></p>
<p class="p83"><span class="s18">Priority 2020-03-31 • Filed 2020-03-31 • Published 2020-07-17</span></p>
<p class="p84"><span class="s18">The invention provides a <b>Wasserstein</b> distance-based depth domain adaptive image classification method and device and a computer-readable storage medium. First, features are extracted using a convolution structure. Secondly, the number of features is reduced by adopting layer-by-layer mapping of the …</span></p>
<p class="p84"><span class="s2"><br>
</span></p>
<p class="p80"><span class="s2">2020 92. patent</span></p>
<p class="p85"><span class="s23"><a href="https://patents.google.com/patent/CN111476721B/en?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new&amp;page=1"><b>Wasserstein</b><span class="s102"> distance-based image rapid enhancement method</span></a></span></p>
<p class="p82"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/9a/ff/a7/6365479cc5c8ae/CN111476721B.pdf"><span class="s103">CN111476721B </span></a></span><span class="s19">丰江帆</span><span class="s18"> </span><span class="s19">重庆邮电大学</span></p>
<p class="p83"><span class="s18">Priority 2020-03-10 • Filed 2020-03-10 • Granted 2022-04-29 • Published 2022-04-29</span></p>
<p class="p84"><span class="s18">5. The <b>Wasserstein</b> distance-based image rapid enhancement method according to claim 1, characterized in that: the up-samplin</span><span class="s15"><br>
<span class="Apple-converted-space"> </span></span></p>
<p class="p34"><span class="s2">2020 93 . 2020-2023</span></p>
<p class="p17"><span class="s17"><a href="https://patents.google.com/patent/CN112634390B/en?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new&amp;page=1">… and device for generating countermeasure network model based on <span class="s104"><b>Wasserstein</b></span></a></span></p>
<p class="p86"><span class="s18">CN112634390B </span><span class="s19">郑海荣</span><span class="s18"> </span><span class="s19">深圳先进技术研究院</span></p>
<p class="p87"><span class="s18">Filed 2020-12-17 • Granted 2023-06-13 • Published 2023-06-13</span></p>
<p class="p34"><span class="s18">the <b>Wasserstein</b> generation countermeasure network model is obtained through training of a preset generation countermeasure network model based on a low-energy image sample, a standard high-energy image and a preset loss function, and the <b>Wasserstein</b> generation countermeasure network model comprises …</span></p>
<p class="p34"><span class="s2"><br>
</span></p>
<p class="p88"><span class="s2">2020 94. patent</span></p>
<p class="p17"><span class="s17"><a href="https://patents.google.com/patent/CN112307514A/en?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new&amp;page=1">Difference privacy greedy grouping method adopting <span class="s104"><b>Wasserstein</b> distance</span></a></span></p>
<p class="p86"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/00/3d/e3/36a06d2a3c1bdf/CN112307514A.pdf"><span class="s105">CN112307514A </span></a></span><span class="s19">杨悦</span><span class="s18"> </span><span class="s19">哈尔滨工程大学</span></p>
<p class="p87"><span class="s18">Priority 2020-11-26 • Filed 2020-11-26 • Published 2021-02-02</span></p>
<p class="p34"><span class="s18">1. A differential privacy greedy grouping method adopting <b>Wasserstein</b> distance is characterized by comprising the following steps: step 1: reading a data set D received at the ith time point i </span><span class="s19">；</span><span class="s18"> Step 2: will D i Data set D released from last time point i-1 Performing <b>Wasserstein</b> distance similarity …</span></p>
<p class="p34"><span class="s2"><br>
</span></p>
<p class="p34"><span class="s2">2020 95</span></p>
<p class="p17"><span class="s17"><a href="https://patents.google.com/patent/CN111741429B/en?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new&amp;page=1">Wi-Fi indoor positioning method based on signal distribution <span class="s104"><b>Wasserstein</b> …</span></a></span></p>
<p class="p86"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/e6/10/71/3470113aa38d0c/CN111741429B.pdf"><span class="s105">CN111741429B </span></a></span><span class="s19">周牧</span><span class="s18"> </span><span class="s19">重庆邮电大学</span></p>
<p class="p87"><span class="s18">Priority 2020-06-23 • Filed 2020-06-23 • Granted 2022-05-03 • Published 2022-05-03</span></p>
<p class="p34"><span class="s18">1. the Wi-Fi indoor positioning method based on signal distribution <b>Wasserstein</b> distance measurement is characterized by comprising the following steps of: step one, off-line stage, the Wi-Fi received signal from the mth AP at the nth Reference Point (RP) is strengthenedThe sequence of degrees ( …</span></p>
<p class="p34"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p10"><span class="s2">&lt;—102 till 2019</span></p>
<p class="p10"><span class="s2">+<span class="Apple-converted-space">  </span>95 for 2020</span></p>
<p class="p10"><span class="s2">=197<span class="Apple-converted-space">  </span>till 2020</span></p>
<p class="p10"><span class="s2">end 2020 <span class="Apple-converted-space">  </span>e20</span></p>
<p class="p18"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p13"><span class="s9"><br>
<span class="Apple-converted-space"> </span></span><span class="s2"> start 2021</span></p>
<p class="p13"><span class="s2">115 <span class="Apple-converted-space">  </span>patents in 2021</span></p>
<p class="p89"><span class="s2"><br>
</span></p>
<p class="p10"><span class="s1"><b>2021 1</b></span></p>
<p class="p68"><span class="s7"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=2&amp;SID=6C8YwxuCSwLSTB5EXGD&amp;page=1&amp;doc=5"><b>Method for training </b><span class="s106"><b>Wasserstein</b></span><span class="s107"><b> generative adversarial network, involves adapting discriminator parameter as function of loss function, and creating second input date on basis of first input date using method of virtual adversarial training</b></span></a></span></p>
<p class="p47"><span class="s2"><b>Patent Number: DE102019210270-A1 US2020372297-A1 CN111985638-A</b></span></p>
<p class="p47"><span class="s2"><b>Patent Assignee: BOSCH GMBH ROBERT</b></span></p>
<p class="p47"><span class="s2"><b>Inventor(s): TERJEK D.</b></span></p>
<p class="p47"><span class="s2"><br>
</span></p>
<p class="p47"><span class="s2"><b>2021 2</b></span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=1&amp;SID=5D7EwaBevRFiySQ2CCX&amp;page=1&amp;doc=3">Apparatus for measuring distance between two signal distributions, has measurement network receives two received signal distributions as input output measurement of wasserstein distance between distributions in receiver domain<span class="s3"></span></a></span></p>
<p class="p47"><span class="s2">Patent Number: WO2021022850-A1</span></p>
<p class="p47"><span class="s2">Patent Assignee: HUAWEI TECHNOLOGIES CO LTD</span></p>
<p class="p47"><span class="s2">Inventor(s): GE Y; SHI W; TONG W.</span></p>
<p class="p47"><span class="s2"><br>
</span></p>
<p class="p47"><span class="s2"><b>2021 3</b></span></p>
<p class="p6"><span class="s1"><a href="https://advance-lexis-com.ezaccess.libraries.psu.edu/search?crid=36426020-9af5-474c-a95a-75731214bdbb&amp;pdsearchterms=Headline(Palo+Alto+Research+Center+Incorporated+issued+patent+titled+Object+shape+regression+using+wasserstein+distance)&amp;pdtypeofsearch=urlapi&amp;pdfiltertext=urn%3Ahlct%3A16&amp;pdstartin=urn%3Ahlct%3A16&amp;pdsearchtype=bool&amp;pdpost=%2CMTA4MzQ0NQ%5Esource%5ENews+Bites+-+Private+Companies%5ESource%5EFalse%5Enews&amp;pdmfid=1516831&amp;pdisurlapi=true#">March 09, 2021: Palo Alto Research Center Incorporated issued patent titled "Object shape regression using wasserstein distance"<span class="s3"></span></a></span></p>
<p class="p90"><span class="s2">Palo Alto Research Center Incorporated issued patent titled "Object shape regression using wasserstein...</span></p>
<p class="p90"><span class="s2">News Bites - Private Companies, Mar 11, 2021</span></p>
<p class="p90"><span class="s2">Newspaper ArticleCitation Online</span></p>
<p class="p68"><span class="s18"><span class="Apple-converted-space"> </span>Preview <span class="Apple-converted-space">  </span>Cite this item Email this item Save this item More actions</span></p>
<ul class="ul1">
  <li class="li47"><span class="s108"><b></b></span><span class="s2"><b>Full Text</b>Wire Feeds</span></li>
</ul>
<p class="p68"><span class="s2">Palo Alto Research Center Obtains Patent for Object Shape Regression Using Wasserstein Distance</span></p>
<p class="p6"><span class="s1"><a href="https://search-proquest-com.ezaccess.libraries.psu.edu/pubidlinkhandler/sng/pubtitle/Global+IP+News.+Optics+$26+Imaging+Patent+News/$N/2028757/DocView/2499351638/fulltext/925264A1287C4FDEPQ/1?accountid=13158"><b>Global IP News. Optics &amp; Imaging Patent News</b></a></span><span class="s4"><b>; New Delhi</b> [New Delhi]09 Mar 2021.</span></p>
<p class="p90"><span class="s2">Palo Alto Research Center Obtains Patent for Object Shape Regression Using Wasserstein Distance</span></p>
<p class="p90"><span class="s2">Global IP News. Optics &amp; Imaging Patent News, Mar 9, 2021</span></p>
<p class="p90"><span class="s2">Newspaper ArticleFull Text Online</span></p>
<p class="p90"><span class="s2"><span class="Apple-converted-space"> </span>Preview<span class="Apple-converted-space">  </span>Cite this item Email this item Save this item More actions</span></p>
<p class="p91"><span class="s20"><span class="Apple-converted-space"> </span><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV3PS8MwFH7ovHhyouKvSQ5e62ybrC1MZajDmxUFwctIm0TB2dauXjz4t_te1iAT0YvXNKQNSb5-efnyPoAwODr2vmGCn5k8iUSmsjzgKjCR4NlAD4zUJuKKa3d7rJVD3birMe1wO5S00K3KnKLmfdw4JKEgPnFWvXrkI0Xnrc5UQ7ZmC-rED30RL8OKj9yI1kAqHhaBl7cgOV6DD_di_S6tYeEPu9bFdI3_-pVd6BK2VbLSNRvNp846LOliA6apnJZsNG1K5jR5jALAWPE6oyjCjKXITouGIdnFIorisNsnbAnrP841tQWzOgQ2fJH18-m9tBc6yVRz2Lcl7II4K062TTgcX96dX3muSxNKnGzwfzqbfHUo3IJOURZ6G1gc-0YYJXH5xzzLeaI0UgMyDUdCx_1kB3q_NrX7x_M9WA1ITELir2QfOk39pns2z-OBHdBPWQ3DgA"><span class="s13">Palo Alto Research Center Obtains Patent for Object Shape Regression Using Wasserstein Distance</span></a></span></p>
<p class="p92"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV1LT8MwDI4YXLgNAeIp-QKX0rGW9CUNpAmB2GmTGILb1EcyAVs3rYPfj530yWkcuESVFaXJZytJXfszYzd2p2v-2hOsSMaB50RJFNs8saXn8MgVrgyF9HjCRZE9psOhdCnRrBEj9a-aRxnqnjJp_6D9clAU4DPaALZoBdhuZAejcLYw-jO8YhZBdsqjK1bGMCK3QEYs_YqhaUEicssQi_OS6jlMdZBsaujAgtdQ5WZSfUxi7VyXBvNRrx9gDEZq6yRfw3CpWKDJvAZzXQ8pf1s9vYI8DrYOuar2NVVDxFDkWdi99N4Zo-91p4xFahBbvw28plAT7roOfovSf-9LojmfJ-_x-lak5stzi7XswM8PSTwZnfwUG7dZm6a3RBBW0NeQ7rEtke6zGcEJBCcUcIKGE3I4QS8QEE7QcIKCEyo4QcEJvXm4-ryrgdq7VhIosD1gV48P4_snkyY4ycuFYpORQyWbhl9ZNqmW1z1k2-kiFUcMfN-SjkxC3CZ9HsU8SAReoai4Ol58uRUcs4uNhjzZsN8p2600eMZ2JFq1OFcEmT88HzIA">Palo Alto Research Center Obtains Patent for Object Shape Regression Using Wasserstein Distance<span class="s3"></span></a></span></p>
<p class="p68"><span class="s2"><br>
</span></p>
<p class="p47"><span class="s2"><b>2021 4</b></span></p>
<p class="p47"><span class="s2">(03/10/2021). "US Patent Issued to Palo Alto Research Center on March 9 for "Object shape regression using wasserstein distance" (California, New York Inventors)". US Fed News Service, Including US State News US Patent Issued to Palo Alto Research Center on March 9 for "Object shape regression using wasser...</span></p>
<p class="p47"><span class="s2">US Fed News Service, Including US State News, Mar 10, 2021</span></p>
<p class="p47"><span class="s2">Newspaper ArticleCitation Online</span></p>
<p class="p92"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtZ1JS8NAFIAHqxdvFRV3HoWCUqvpNGkzUIUiFj2IQttzyTJRsU1KF_w5_lXfe9Pp4sHl4CWkQ5bJN6-Tl3mbEFV54ZS_zAmVMIlU3QvjMJJuLJO654Y1XUsCndTd2NU2esy4Q5kCoOMVH6l_HXlsw7GnSNo_jP78otiA-ygDuEUpwO2v5KDbpjT8ZPHnQnsxKZtPQT8rNfu4Zx3veJVXj8h08MC_FfsfFqV8DGmlpjR-CYZUYeXZ-M2mpSkvMrwHHK5JJTPJ1jMhGcKT2DY8j_piibPpoe7Zyz2jShNqWTPGfrawdzTp2glsNn_1pxx4gwewZrwSmUGLFZK9tWZuqyRedx2ym1E1FDa6U84JG8dFmc4H8Ws0udJpudvOiZxcTkzoS-U5ldUXZm32cuvkRZ5uPUQQI2ga0ltiTafb4qPbBkMZDGWYZECUgSiDpQyGMmQpMGVQgISgYBgDM4YFY2DG0BgEo7frJdKNS24BC7wApwvY54CdBEINc9RnO6LYuu3c3JXtc_VS-yTjHn4aqyolrHScXbGeZqneE-D7lcRL4gBnWt8NI1fFGrUwqs-OurNbUfvi5PtrHfx0wKHYXIzdkdhI8K-gjzmr5id7lEBl">US Patent Issued to Palo Alto Research Center on March 9 for "Object shape regression using wasser...<span class="s3"></span></a></span></p>
<p class="p91"><span class="s1">US Fed News Service, Including US State News, Mar 10, 2021</span></p>
<p class="p47"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2021 5</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=1&amp;SID=8BMMnYA8SlejkIehvzU&amp;page=1&amp;doc=13">Image analysis system for assessing accuracy of localization from single molecule localization microscopy dataset, comprises non-volatile computer-readable memory containing instructions of Wasserstein-induced flux component<span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: US2021033536-A1</span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV WASHINGTON; LEW M; NEHORAI A; et. al</span></p>
<p class="p5"><span class="s2">Inventor(s): LEW M; NEHORAI A; MAZIDISHARFABADI H.</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=1&amp;SID=8BMMnYA8SlejkIehvzU&amp;page=1&amp;doc=14">WASSERSTEIN F-TESTS AND CONFIDENCE BANDS FOR THE FRECHET REGRESSION OF DENSITY RESPONSE CURVES<span class="s3"></span></a></span></p>
<p class="p10"><span class="s12">By: <a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/OneClickSearch.do?product=UA&amp;search_mode=OneClickSearch&amp;excludeEventConfig=ExcludeIfFromFullRecPage&amp;SID=8BMMnYA8SlejkIehvzU&amp;field=AU&amp;value=Petersen,%20Alexander"><span class="s13">Petersen, Alexander</span></a>; <a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/OneClickSearch.do?product=UA&amp;search_mode=OneClickSearch&amp;excludeEventConfig=ExcludeIfFromFullRecPage&amp;SID=8BMMnYA8SlejkIehvzU&amp;field=AU&amp;value=Liu,%20Xi"><span class="s13">Liu, Xi</span></a>; <a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/OneClickSearch.do?product=UA&amp;search_mode=OneClickSearch&amp;excludeEventConfig=ExcludeIfFromFullRecPage&amp;SID=8BMMnYA8SlejkIehvzU&amp;field=AU&amp;value=Divani,%20Afshin%20A."><span class="s13">Divani, Afshin A.</span></a></span></p>
<p class="p5"><span class="s2">ANNALS OF STATISTICS  Volume: ‏ 49   Issue: ‏ 1   Pages: ‏ 590-611   Published: ‏ FEB 2021</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2021 6</span></p>
<p class="p93"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwfV1RT8IwEL4IMVGeNEpE0PQPTHSblCUEHggLb_Lgu-na20gIc-lG_PveHWKIiby2117Tpr1-ve96AFH49Bz8ORNetBuRZTBxbHMca-3i1wgTa2PDCGTPJT-iQx3e3yrTkNZdXTWfQrIktG4IIg7Lah2sCPihn5EInc4_6TMIkXMMUQtaY_HZLtJlBy6ovQjVR5YjvYLzlZRewxmWNzB7y_jhQ9VrU6HyWOxpqKVi_nmhJlvjN9MvIzGQnIdyMpQS5fiaR-tzCypdvM-Xwa-2j8IzlYV9vDKqqAttgvR4BypzSJsbtbWO4FhuEwwtf-yXG-2SaJT1oPdvN_cn6vpwGTLngjlSyQDajd_hg3yH-CiT8Q1Vd3ez">Object shape regression using wasserstein distance<span class="s109"></span></a></span></p>
<p class="p94"><span class="s2">by Palo Alto Research Center Incorporated</span></p>
<p class="p95"><span class="s2">03/2021</span></p>
<p class="p96"><span class="s2">One embodiment can provide a system for detecting outlines of objects in images. During operation, the system receives an image that includes at least one...</span></p>
<p class="p97"><span class="s12">Patent<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwfV1RT8IwEL4IMVGeNEpE0PQPTHSblCUEHggLb_Lgu-na20gIc-lG_PveHWKIiby2117Tpr1-ve96AFH49Bz8ORNetBuRZTBxbHMca-3i1wgTa2PDCGTPJT-iQx3e3yrTkNZdXTWfQrIktG4IIg7Lah2sCPihn5EInc4_6TMIkXMMUQtaY_HZLtJlBy6ovQjVR5YjvYLzlZRewxmWNzB7y_jhQ9VrU6HyWOxpqKVi_nmhJlvjN9MvIzGQnIdyMpQS5fiaR-tzCypdvM-Xwa-2j8IzlYV9vDKqqAttgvR4BypzSJsbtbWO4FhuEwwtf-yXG-2SaJT1oPdvN_cn6vpwGTLngjlSyQDajd_hg3yH-CiT8Q1Vd3ez"><span class="s110">Available Online</span></a></span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2021 7</span></p>
<p class="p98"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwfR1dT9sw0JpgY3uDbmgfDJ00qW8dtA2kSJQptS9N1MaOErdTeUHBDdJUrUW0iL--x53dFBAPvEUX52yf78Pn3J0Za7d-Hjde6ISmPz0ly1B4nrkpO74_9U7a5ZkxXmE9kHUs-bNwqNkmNcaVDX1wtRJJwAyJ_8qp79unMy3hQi2XR9d_CLT4FequqFfOMrkzhLsuel1MlVC8znl3kNVl1rV-DllWr9Ujz2mb9vQdKx047tkslVtrYjqV5gx32duU0M1Xe-zNbFFj7_nmJrYa20mqH-A19s5FbJolASupXH5k_4YYZDKWfUhQR0pAIAU8wgSOY45A3h5EcT9qiDhBackFI5mPUszGcY72G5UEwwk11-gCS8DeyNGHga2YO4wvqcn53-JudvE7yHPMco2xPD9yECAmVyi5EpiBVtQ1tZD0pCAJ5AS4StKRXicsgwqBR1mca5VGOIRwJNe92TFrzPWLaWxA1SzWY9IRQh4k-In9CFHzqEHEvHpcuqtB9kT4XrO9z7bmi3n5mUGraBeFMbTXOTVek9jC-OX07GR67F8XtAW7-cIOXsP09fXX39gHywz25KTpHbCt1d19-d1ViTx0i_4fzUy8YQ">LEARNING METHOD AND LEARNING DEVICE FOR HIGH-DIMENSION UNSUPERVISED ANOMALY DETECTION USING KERNALIZED <span class="s111"><b>WASSERSTEIN</b>...</span></a></span></p>
<p class="p73"><span class="s2">01/2021</span></p>
<p class="p99"><span class="s2">크리스토펠</span><span class="s112"> </span><span class="s2">함수의</span><span class="s112"> </span><span class="s2">과다한</span><span class="s112"> </span><span class="s2">연산량을</span><span class="s112"> </span><span class="s2">커널화</span><span class="s112"> </span><span class="s2">와서스타인</span><span class="s112"> </span><span class="s2">오토인코더를</span><span class="s112"> </span><span class="s2">이용하여</span><span class="s112"> </span><span class="s2">개선한</span><span class="s112"> </span><span class="s2">고차원</span><span class="s112"> </span><span class="s2">비지도</span><span class="s112"> </span><span class="s2">이상</span><span class="s112"> </span><span class="s2">탐지</span><span class="s112"> </span><span class="s2">학습</span><span class="s112"> </span><span class="s2">방법이</span><span class="s112"> </span><span class="s2">개시된다</span><span class="s112">. </span><span class="s2">즉</span><span class="s112">, (a) </span><span class="s2">학습</span><span class="s112"> </span><span class="s2">장치가</span><span class="s112">, </span><span class="s2">복수</span><span class="s112"> </span><span class="s2">개의</span><span class="s112"> </span><span class="s2">성분을</span><span class="s112"> </span><span class="s2">가진</span><span class="s112"> </span><span class="s2">적어도</span><span class="s112"> </span><span class="s2">하나의</span><span class="s112"> </span><span class="s2">학습</span><span class="s112"> </span><span class="s2">데이터</span><span class="s112"> </span><span class="s2">매트릭스가</span><span class="s112"> </span><span class="s2">획득되면</span><span class="s112">, </span><span class="s2">적어도</span><span class="s112"> </span><span class="s2">하나의</span><span class="s112"> </span><span class="s2">와서스타인</span><span class="s112"> </span><span class="s2">인코딩</span><span class="s112"> </span><span class="s2">네트워크로</span><span class="s112"> </span><span class="s2">하여금</span><span class="s112">, </span><span class="s2">각각의</span><span class="s112">...</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2021<span class="Apple-converted-space">  </span>8<span class="Apple-converted-space">  </span>OPEN ACCESS<span class="Apple-tab-span">	</span></span></p>
<p class="p100"><span class="s56"><a href="https://duke.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwY2AwNtIz0EUrE9JSko2AlVFimkWSpRloMi01BRj3pqapwOYEqAmBtkcsC7Y1BnxsaDn4rERgBksGZv8ScPFdgBjTcgEvtSzWT8oECuXbu4XYuqhBO8ug7oyBkZqLk61rgL-Lv7Oas7Ots5-aX5AtsJUBTNzAxoIjMwOzEejmXGZge5cHUcC6CTKwBQBNySsRYmCqyhBm4HSGXcAmzMDhC533FmZgBy_UTC4GCkIzY7EIg_eTHQ3Pl_e-bG9_PmWFTW5iUbZdeCJ49yToBksbfbDIi-1zny_b_XxWy9Pt6552tL2cNeH58sYXW1Y93d8M5D7f3fJs2s5nm6eKMii6uYY4e-gC3RcPD4R4Zz-EFwzEGFjy8vNSJRgU0iwt0kzTTJNME43STAwTzS1SjQwski0TLQ1MLVKSLQwkGaRwmyOFT1KagQsUoOAFy0YyDKxpwNyRKgu5QgEAHCSgVA">一种采用<span class="s113">Wasserstein距离的差分隐私贪心分组方法</span></a></span></p>
<p class="p14"><span class="s2">02/2021</span></p>
<p class="p14"><span class="s2">...</span></p>
<p class="p14"><span class="s2">PatentCitation Online</span></p>
<p class="p14"><span class="s2"><span class="Apple-converted-space"> </span>Preview<span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s2"><span class="Apple-converted-space"> </span>Cite this item Email this item Save this item More actions</span></p>
<p class="p14"><span class="s2">[Chinese<span class="Apple-converted-space">  </span>A Differential Privacy Greedy Grouping Method Using Wasserstein Distance'</span></p>
<p class="p42"><span class="s2"><span class="Apple-tab-span">	</span></span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2021<span class="Apple-converted-space">  </span>9<span class="Apple-converted-space">  </span>OPEN ACCESS<span class="Apple-tab-span">	</span></span></p>
<p class="p100"><span class="s56"><a href="https://duke.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwY2AwNtIz0EUrE9JSko2AlVFimkWSpRloMi01BRj3pqapwOYEqAmBtkcsC7Y1BnxsaDn4rERgBksGZv8ScPFdgBjTcgEvtSzWT8oECuXbu4XYuqhBO8ug7oyBkZqLk61rgL-Lv7Oas7Ots5-aX5At6JxNUE_GzImZgdkIdHMuM7C9C1kCCS5g3QQZ2AKApuSVCDEwVWUIM3A6wy5gE2bg8IXOewszsIMXaiYXAwWhmbFYhCHqyY6G58t7n87f9WRXn01uYlG2XXgiePck6AZLG32wyIvtc58v2_18Vsuz7Ruf7lr2dP3OZ13TX-xvfL589_O9E5_vngOSmtr6ctacF-u7nk1b-2zazmebp4oyKLm5hjh76AKdGw8Pk3hnP4SPnAzEGFjy8vNSJRgU0iwt0kzTTJNME43STAwTzS1SjQwski0TLQ1MLVKSLQwkGaTxGCSFV1aagQsUxOAlzEYyDKxpwPySKgu5VAEAFBus9Q">一种基于<span class="s113">Wasserstein距离的深度对抗迁移网络的故障诊断方法</span></a></span></p>
<p class="p14"><span class="s2">02/2021</span></p>
<p class="p14"><span class="s2">...</span></p>
<p class="p14"><span class="s2">PatentCitation Online</span></p>
<p class="p14"><span class="s2"><span class="Apple-converted-space"> </span>Preview<span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s2"><span class="Apple-converted-space"> </span>Cite this item Email this item Save this item More actions</span></p>
<p class="p14"><span class="s2">[Chinese<span class="Apple-converted-space">  </span>A Fault Diagnosis Method Based on Wasserstein Distance for Deep Confrontation Migration Network]</span><span class="s114"><br>
</span></p>
<p class="p14"><span class="s114"><br>
2021 10<span class="Apple-converted-space">  </span></span><span class="s2">OPEN ACCESS<span class="Apple-tab-span">	</span></span></p>
<p class="p6"><span class="s1"><a href="https://duke.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwfR1dT9sw0BobA95YtwkYSCdN6lshDc1IJQpK7UsTtbGjxGWCF5SmiYQqWkSR9td53DlpQeoDb9Hl_HX22Xf2fTB2bp9arY09oZzmNh1GWelOun_MY1oxpbl3nILECSNCbPiIzdauMVXY0H9VrERisJzY_6Xavp_e77REZWq5PJs8EGhx7eueaK6UZVJnSNxvin4PYyUUb3LeGyZNmfSMnkMna8fuk-a0ZZvUuVsk8NZxoqod1t9n2zFVM3_5xj7NFg22y9cZ2BpsJ1o9fDfY18pSM18ScMWNy-_sdYReIkM5gAh1oAR4UsAbTOBNyBFIy4MgHAQtEUYoDZlgLNNxjMlNmKIpoyJvdEvoGiuDEjCZOAYwNJFyR-EdoVw-Zs-zq79emmKSagzl5VkFAVrcCiVXAhPQipomDElfCiJP3gJXUTzWtaMyKB94kISpVnGAI_DHsm7N9FljqjeGsQatRlH3SQcIqRfhD_bbR82DFhHz_m3K7ofJO8H7besn-zxfzIsDBmXXLZ3SmTiZXXba2YVb2Jabd7Ou5bjT3LUO2fFHNR19_PsX2zOLwNyYtDvH7EtJHF2c1Gkf_gNiB7oz">LEARNING METHOD AND LEARNING DEVICE FOR HIGH-DIMENSION UNSUPERVISED ANOMALY DETECTION USING<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p14"><span class="s2">KERNALIZED WASSERSTEIN...</span></p>
<p class="p14"><span class="s2">by PAIK MYUNGHEE CHO; CHANG HYUN WOONG; KIM YOUNG GEUN</span></p>
<p class="p14"><span class="s2">01/2021</span></p>
<p class="p101"><span class="s2">크리스토펠</span><span class="s9"> </span><span class="s2">함수의</span><span class="s9"> </span><span class="s2">과다한</span><span class="s9"> </span><span class="s2">연산량을</span><span class="s9"> </span><span class="s2">커널화</span><span class="s9"> </span><span class="s2">와서스타인</span><span class="s9"> </span><span class="s2">오토인코더를</span><span class="s9"> </span><span class="s2">이용하여</span><span class="s9"> </span><span class="s2">개선한</span><span class="s9"> </span><span class="s2">고차원</span><span class="s9"> </span><span class="s2">비지도</span><span class="s9"> </span><span class="s2">이상</span><span class="s9"> </span><span class="s2">탐지</span><span class="s9"> </span><span class="s2">학습</span><span class="s9"> </span><span class="s2">방법이</span><span class="s9"> </span><span class="s2">개시된다</span><span class="s9">. </span><span class="s2">즉</span><span class="s9">, (a) </span><span class="s2">학습</span><span class="s9"> </span><span class="s2">장치가</span><span class="s9">, </span><span class="s2">복수</span><span class="s9"> </span><span class="s2">개의</span><span class="s9"> </span><span class="s2">성분을</span><span class="s9"> </span><span class="s2">가진</span><span class="s9"> </span><span class="s2">적어도</span><span class="s9"> </span><span class="s2">하나의</span><span class="s9"> </span><span class="s2">학습</span><span class="s9"> </span><span class="s2">데이터</span><span class="s9"> </span><span class="s2">매트릭스가</span><span class="s9"> </span><span class="s2">획득되면</span><span class="s9">, </span><span class="s2">적어도</span><span class="s9"> </span><span class="s2">하나의</span><span class="s9"> </span><span class="s2">와서스타인</span><span class="s9"> </span><span class="s2">인코딩</span><span class="s9"> </span><span class="s2">네트워크로</span><span class="s9"> </span><span class="s2">하여금</span><span class="s9">, </span><span class="s2">각각의</span><span class="s9">...</span></p>
<p class="p14"><span class="s2">PatentCitation Online</span></p>
<p class="p14"><span class="s2"><span class="Apple-converted-space"> </span>Preview<span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2021<span class="Apple-converted-space">  </span>11</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=1&amp;SID=7BYtaF4fGLO6kMKMFTY&amp;page=1&amp;doc=8">Restoring image based on wasserstein generative adversarial network network comprises constructing shallow convolutional network structure by using cavity convolution to extract spatial characteristic of collected image<span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN112488956-A</span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV NANJING INFORMATION SCI &amp; TECHNOLOG</span></p>
<p class="p5"><span class="s2">Inventor(s): FANG W; GU E; WANG W. </span></p>
<p class="p5"><span class="s2">Select record9</span></p>
<p class="p10"><span class="s2"><br>
2021<span class="Apple-converted-space">  </span>12</span></p>
<p class="p17"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=4&amp;SID=7C2Qes7hcYxovGMLeZw&amp;page=1&amp;doc=4">critical function for balancing loss function specific gravity and marking data in training set with drop label picture<span class="s95"></span></a></span></p>
<p class="p14"><span class="s2">Patent Number: CN112258425-A</span></p>
<p class="p14"><span class="s2">Patent Assignee: CHINA TELECOM WANWEI INFORMATION TECHNOL</span></p>
<p class="p14"><span class="s2">Inventor(s): ZHAO W; WANG Z; HAO D; et al.</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2021 13</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/CN112765426A/en?q=wasserstein&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=wasserstein+2021">Wasserstein space-based visual dimension reduction method<span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">CN <a href="https://patentimages.storage.googleapis.com/a1/dd/a5/ee1956866e0217/CN112765426A.pdf"><span class="s10">CN112765426A</span></a> </span><span class="s11">秦红星</span><span class="s2"> </span><span class="s11">重庆邮电大学</span></p>
<p class="p5"><span class="s2">Priority 2021-01-18 • Filed 2021-01-18 • Published 2021-05-07</span></p>
<p class="p5"><span class="s2">6. The visualization dimension reduction method based on Wasserstein space according to claim 5, wherein: the S5 specifically includes: note P i Is the ith row, Q, of the matrix P i Similarly, considered as a column vector; w represents the 1-Wasserstein distance and the dual form of the loss function …</span></p>
<p class="p5"><span class="s2"><br>
<br>
 2021 14 OPEN ACCESS</span></p>
<p class="p46"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwY2AwNtIz0EUrE5KAtVBiEjBfAevbZIvElERjU3PjRMOkNFPTZAPDZAvY7jHocqgs2NYY8LGh5eCzEoEZLBmY_UvAxXcBYkzLBbzUslg_KRMolG_vFmLrogbtLBuB7jAwUnNxsnUN8Hfxd1ZzdrZ19lPzC7IFtjKAKRfYN3BkZmAFNelBq8Fcw5xAm1QKkGsYN0EGtgCgaXklQgxMVRnCDJzOsIvYhBk4fKHz38IM7OAFm8nFQEFopiwWYbB7sqPh-fLep_N3PdnVZ5ObWJRtF-7u6GejD2Y-3zvx-e45L_bPfrGw5-nsfU-b-5_sX_d0Se_zWS3Ppu18tnmqKIOim2uIs4cu0EnxcP_HO_shXG8sxsCSl5-XKsGgYGCWkmRhlpQKGoQ1SQXWw4YpxknA_JmSBGyxJKUlSzJI4TZHCp-kNAMXKCxBK68MjWQYWEqKSlNlwYcsyoEDDQBqG5vM">一种基于WGAN网络进行图像修复的方法</a></span><span class="s115"><br>
03/2<a href="https://psu.summon.serialssolutions.com/rss?ho=f&amp;fvf=ContentType%2CPatent%2Cf&amp;rf=PublicationDate%2C2020-12-03%3A2021-12-03&amp;l=en&amp;q=(TitleCombined%3A(wasserstein%20OR%20wgan))"><span class="s13">1</span></a></span></p>
<p class="p5"><span class="s2">[Chinese<span class="Apple-converted-space">  </span>A method of image restoration based on WGAN network]</span></p>
<p class="p10"><span class="s12">Patent<span class="Apple-converted-space">  </span><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwY2AwNtIz0EUrE5KAtVBiEjBfAevbZIvElERjU3PjRMOkNFPTZAPDZAvY7jHocqgs2NYY8LGh5eCzEoEZLBmY_UvAxXcBYkzLBbzUslg_KRMolG_vFmLrogbtLBuB7jAwUnNxsnUN8Hfxd1ZzdrZ19lPzC7IFtjKAKRfYN3BkZmAFNelBq8Fcw5xAm1QKkGsYN0EGtgCgaXklQgxMVRnCDJzOsIvYhBk4fKHz38IM7OAFm8nFQEFopiwWYbB7sqPh-fLep_N3PdnVZ5ObWJRtF-7u6GejD2Y-3zvx-e45L_bPfrGw5-nsfU-b-5_sX_d0Se_zWS3Ppu18tnmqKIOim2uIs4cu0EnxcP_HO_shXG8sxsCSl5-XKsGgYGCWkmRhlpQKGoQ1SQXWw4YpxknA_JmSBGyxJKUlSzJI4TZHCp-kNAMXKCxBK68MjWQYWEqKSlNlwYcsyoEDDQBqG5vM"><span class="s13">Available Online</span></a></span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2021 15</span></p>
<p class="p5"><span class="s116"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwY2AwNtIz0EUrE5KAtVBiEjBfAevbZIvElERjU3PjRMOkNFPTZAPDZAvY7jHocqgs2NYY8LGh5eCzEoEZLBmY_UvAxXcBYkzLBbzUslg_KRMolG_vFmLrogbtLAO7MyZGBmouTrauAf4u_s5qzs62zn5qfkG2oI0zFhaWRhaOzAysoCY9aDWYa5gTaJNKQT5kKSS4hnETZGALAJqWVyLEwFSVIczA6Qy7iE2YgcMXOv8tzMAOXrCZXAwUhGbKYhGGsOe7Jz-d0PGifdXzPdOeL2h8OnPF00k9NrmJRdl24e6Ofjb6YObzWS3P9058vnvOsym7n7bvfra18WV7_7OpG571rnu6aN7TPbueTdv5bPPUp_1dzzfvfr57viiDoptriLOHLtCp8fBwiXf2Q_jKWIyBJS8_L1WCQcHALCXJwiwpFTQ4a5IKrJ8NU4yTgPk2JQnYkklKS5ZkkMJtjhQ-SWkGLlAYg-ZWjAxkGFhKikpTZcGHL8qBAxMA-Wes4Q">合自编码器和<span class="s3">WGAN</span><span class="s1">的网络攻击流量数据增强方法及系统</span></a></span><span class="s2"><br>
Chinese <span class="Apple-converted-space">  </span>Network attack flow data enhancement method and system based on self-encoder and WGAN]</span></p>
<p class="p5"><span class="s2">04/2021</span></p>
<p class="p5"><span class="s2">Patent<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwY2AwNtIz0EUrE5KAtVBiEjBfAevbZIvElERjU3PjRMOkNFPTZAPDZAvY7jHocqgs2NYY8LGh5eCzEoEZLBmY_UvAxXcBYkzLBbzUslg_KRMolG_vFmLrogbtLAO7MyZGBmouTrauAf4u_s5qzs62zn5qfkG2oI0zFhaWRhaOzAysoCY9aDWYa5gTaJNKQT5kKSS4hnETZGALAJqWVyLEwFSVIczA6Qy7iE2YgcMXOv8tzMAOXrCZXAwUhGbKYhGGsOe7Jz-d0PGifdXzPdOeL2h8OnPF00k9NrmJRdl24e6Ofjb6YObzWS3P9058vnvOsym7n7bvfra18WV7_7OpG571rnu6aN7TPbueTdv5bPPUp_1dzzfvfr57viiDoptriLOHLtCp8fBwiXf2Q_jKWIyBJS8_L1WCQcHALCXJwiwpFTQ4a5IKrJ8NU4yTgPk2JQnYkklKS5ZkkMJtjhQ-SWkGLlAYg-ZWjAxkGFhKikpTZcGHL8qBAxMA-Wes4Q"><span class="s10">Available Online</span></a><br>
<br>
<br>
2021 16  OPEN ACCESS</span></p>
<p class="p46"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwY2AwNtIz0EUrE5KAtVBiEjBfAevbZIvElERjU3PjRMOkNFPTZAPDZAvY7jHocqgs2NYY8LGh5eCzEoEZLBmY_UvAxXcBYkzLBbzUslg_KRMolG_vFmLrogbtLAO7M8DmjpqLk61rgL-Lv7Oas7Ots5-aX5AtsJVhDrqqycyRmYEV1KQHrQZzDXMCbVIpyIfc8w6uYdwEGdgCgKbllQgxMFVlCDNwOsMuYhNm4PCFzn8LM7CDF2wmFwMFoZmyWITB6cmOhufLe5_O3_VkV59NbmJRtl14IngXJegmSxt9sMjzlbteTt_yfFbL0_71L5a3Pe2Z9nJm7_PdW55N2_ls81RRBkU31xBnD12gs-LhYRDv7IfwgbEYA0tefl6qBIOCgVlKkoVZUipoINYkFVgXG6YYJwHzaEoSsNWSlJYsySCF2xwpfJLSDFyg8AQv9TOXYWApKSpNlQUftCgHDjgAtbWc3w">一种基于Wasserstein空间的可视化降维方法<span class="s57"></span></a></span></p>
<p class="p5"><span class="s2">[Chinese<span class="Apple-converted-space">  </span>A Visualized Dimensionality Reduction Method Based on Wasserstein Space]</span></p>
<p class="p6"><span class="s1"><a href="https://worldwide.espacenet.com/publicationDetails/biblio?FT=D&amp;date=20210507&amp;DB=EPODOC&amp;CC=CN&amp;NR=112765426A">Visual dimension reduction method based on Wasserstein space  </a></span><span class="s12"><br>
05/2021</span></p>
<p class="p10"><span class="s12">Patent<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwY2AwNtIz0EUrE5KAtVBiEjBfAevbZIvElERjU3PjRMOkNFPTZAPDZAvY7jHocqgs2NYY8LGh5eCzEoEZLBmY_UvAxXcBYkzLBbzUslg_KRMolG_vFmLrogbtLAO7M8DmjpqLk61rgL-Lv7Oas7Ots5-aX5AtsJVhDrqqycyRmYEV1KQHrQZzDXMCbVIpyIfc8w6uYdwEGdgCgKbllQgxMFVlCDNwOsMuYhNm4PCFzn8LM7CDF2wmFwMFoZmyWITB6cmOhufLe5_O3_VkV59NbmJRtl14IngXJegmSxt9sMjzlbteTt_yfFbL0_71L5a3Pe2Z9nJm7_PdW55N2_ls81RRBkU31xBnD12gs-LhYRDv7IfwgbEYA0tefl6qBIOCgVlKkoVZUipoINYkFVgXG6YYJwHzaEoSsNWSlJYsySCF2xwpfJLSDFyg8AQv9TOXYWApKSpNlQUftCgHDjgAtbWc3w"><span class="s13">Available Online</span></a></span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s117"><span class="Apple-converted-space"> </span></span><span class="s2">2021 patent 17</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=AdvancedSearch&amp;qid=1&amp;SID=6D6mCWjr9ONXqijKiNB&amp;page=1&amp;doc=17">process industry soft measurement data supplementing method based on self-supervised variational auto-encoder wasserstein generative adversarial network (svae-wgan) in idustrial field, involves calculating output distribution of encoder network<span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN113505477-A</span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV NORTHWEST NORMAL</span></p>
<p class="p5"><span class="s2">Inventor(s): XU J; ZHANG Q; LIU Y; et al.</span></p>
<p class="p5"><span class="s2">Inventor(s): XU J; ZHANG Q; LIU Y; et al.</span></p>
<p class="p5"><span class="s2">CN10725654 29 Jun 2021  <span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2021 patent 18</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=AdvancedSearch&amp;qid=1&amp;SID=6D6mCWjr9ONXqijKiNB&amp;page=1&amp;doc=23">Wind power output power prediction method and wasserstein generative adversarial networks (WGAN) network, has filling missing value of wind power data and abnormal value, normalizing data set as input data of prediction model, and outputting prediction result after training test of prediction mode<span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN113298297-A</span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV INNER MONGOLIA TECHNOLOGY</span></p>
<p class="p5"><span class="s2">Inventor(s): WANG Y; WU Y; XU H; et al.</span></p>
<p class="p5"><span class="s2">CN10503783 10 May 2021 </span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2021<span class="Apple-converted-space">  </span>19</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=AdvancedSearch&amp;qid=1&amp;SID=6D6mCWjr9ONXqijKiNB&amp;page=1&amp;doc=24">Robot motion planning method based on graph Walssetein auto-encoding network involves constructing graph Wasserstein auto-encoding network, performing non-uniform sampling distribution characterization learning process, and planning motion<span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN113276119-A</span></p>
<p class="p5"><span class="s2">Patent Assignee: TSINGHUA SHENZHEN INT GRADUATE SCHOOL</span></p>
<p class="p5"><span class="s2">Inventor(s): XIA C; LIANG B; WANG X; et al.</span></p>
<p class="p5"><span class="s2">CN10571993 25 May 2021 </span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">1021 20</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=AdvancedSearch&amp;qid=1&amp;SID=6D6mCWjr9ONXqijKiNB&amp;page=1&amp;doc=25">Method for training low-dose computed tomography (CT) image denoising model, involves minimizing loss of generator in wasserstein divergence generative adversarial network (WGAN)-div generation countermeasure network initial model, and maximizing loss of discriminator<span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN113205461-A</span></p>
<p class="p5"><span class="s2">Patent Assignee: SHANGHAI HUIHU INFORMATION TECHNOLOGY CO LTD</span></p>
<p class="p5"><span class="s2">Inventor(s): LI S; LI Y; PAN J.</span></p>
<p class="p5"><span class="s2">CN10360991 02 Apr 2021 </span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2021<span class="Apple-converted-space">  </span>21</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=AdvancedSearch&amp;qid=1&amp;SID=6D6mCWjr9ONXqijKiNB&amp;page=1&amp;doc=26">Group target track starting method, involves determining wave gate of sub-group according to equivalent measurement, calculating Wasserstein distance between sub-group and backup sub-group, and taking candidate sub-group as track start<span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN113126082-A</span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV SUN YAT-SEN</span></p>
<p class="p5"><span class="s2">Inventor(s): XU S; LEI X; ZHU N; et al.</span></p>
<p class="p5"><span class="s2">CN10347426 31 Mar 2021 </span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2021<span class="Apple-converted-space">  </span>22</span></p>
<p class="p10"><span class="s23"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:2021C2916J">Method for detecting industrial abnormality based on <span class="s118">wasserstein</span><span class="s13"> generative adversarial network using computer device involves using convolutional neural network module image of work-piece to perform data filter using </span><span class="s118">wasserstein</span><span class="s13"> generative adversarial network abnormal detection model</span></a></span></p>
<p class="p102"><span class="s2">CN113554645-ACN113554645-B</span></p>
<p class="p103"><span class="s30"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22HOU%20D%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s119">HOU D</span></a></span><span class="s120">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22GUO%20J%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s121">GUO J</span></a> and <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22HANG%20T%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s121">HANG T</span></a></span></p>
<p class="p5"><span class="s30"><b>Assignee(s) </b></span><span class="s18">CHANGZHOU MICRO-INTELLIGENCE TECHNOLOGY</span></p>
<p class="p14"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p104"><span class="s2">2021-C2916J</span></p>
<p class="p77"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2021<span class="Apple-converted-space">  </span>23</span></p>
<p class="p105"><span class="s23"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:202130425T">Restoring image based on <span class="s122">wasserstein</span><span class="s123"> generative adversarial network network comprises constructing shallow convolutional network structure by using cavity convolution to extract spatial characteristic of collected image</span></a></span></p>
<p class="p5"><span class="s18">CN112488956-A</span></p>
<p class="p105"><span class="s93"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22FANG%20W%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s123">FANG W</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22GU%20E%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">GU E</span></a> and <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22WANG%20W%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">WANG W</span></a></span></p>
<p class="p5"><span class="s93"><b>Assignee(s) </b></span><span class="s18">UNIV NANJING INFORMATION SCI &amp; TECHNOLOG</span></p>
<p class="p77"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2021-30425T</span></p>
<p class="p106"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">2021<span class="Apple-converted-space">  </span>24</span></p>
<p class="p105"><span class="s23"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:2021C5057X">Method for generating anti-disturbance image based on <span class="s122">Wasserstein</span><span class="s123"> generative adversarial network-gradient penalty, involves generating corresponding counter disturbance image for any input counter target</span></a></span></p>
<p class="p5"><span class="s18">CN113537467-A</span></p>
<p class="p105"><span class="s93"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22TIAN%20P%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s123">TIAN P</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22SUN%20J%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">SUN J</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22JIANG%20L%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">JIANG L</span></a></span></p>
<p class="p5"><span class="s93"><b>Assignee(s) </b></span><span class="s18">UNIV NANJING POST &amp; TELECOM</span></p>
<p class="p77"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2021-C5057X</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space"> </span>2021<span class="Apple-converted-space">  </span>25</span></p>
<p class="p8"><span class="s126"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:2021C64797">Wasserstein<span class="s17"> Generative Adversarial Network based small sample ground slow motion target data classification method, involves classifying ground slow motion target in test set by using classification model</span></a></span></p>
<p class="p5"><span class="s18">CN113569632-A</span></p>
<p class="p105"><span class="s93"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22LI%20Y%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s123">LI Y</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22BAI%20X%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">BAI X</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22ZHOU%20F%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">ZHOU F</span></a></span></p>
<p class="p5"><span class="s93"><b>Assignee(s) </b></span><span class="s18">PLA NO 32203 TROOPS and UNIV XIDIAN</span></p>
<p class="p77"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2021-C64797</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space"> </span>2021<span class="Apple-converted-space">  </span>26</span></p>
<p class="p8"><span class="s126"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:2021721792">Wasserstein<span class="s17"> generative adversarial network scene simulation and time sequence production simulation based energy capacity configuration method, involves establishing new energy planning model, obtaining new energy planning scheme</span></a></span></p>
<p class="p5"><span class="s18">CN112994115-A</span></p>
<p class="p105"><span class="s93"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22MA%20Y%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s123">MA Y</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22FU%20Y%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">FU Y</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22ZHAO%20S%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">ZHAO S</span></a></span></p>
<p class="p5"><span class="s93"><b>Assignee(s) </b></span><span class="s18">UNIV NORTH CHINA ELECTRIC POWER</span></p>
<p class="p77"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2021-721792</span></p>
<p class="p44"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">2021<span class="Apple-converted-space">  </span>27</span></p>
<p class="p105"><span class="s23"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:202168724L">Non-linear industrial process modeling method based on <span class="s122">Wasserstein</span><span class="s123"> generative adversarial network data enhancement, involves normalizing initial data set, and adding multiple groups of generated samples into mixed sample</span></a></span></p>
<p class="p5"><span class="s18">CN112966429-A</span></p>
<p class="p105"><span class="s93"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22CHU%20F%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s123">CHU F</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22DING%20P%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">DING P</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22MA%20X%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">MA X</span></a></span></p>
<p class="p5"><span class="s93"><b>Assignee(s) </b></span><span class="s18">UNIV CHINA MINING &amp; TECHNOLOGY BEIJING</span></p>
<p class="p77"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2021-68724L</span></p>
<p class="p44"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">2021<span class="Apple-converted-space">  </span>28</span></p>
<p class="p105"><span class="s23"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:2021D7113L">Representation similar countermeasure network based on <span class="s122">Wasserstein</span><span class="s123"> distance for electroencephalogram emotion classification and deep migration learning, comprises the EEG signal is sampled at a sampling rate of 200hz</span></a></span></p>
<p class="p5"><span class="s18">CN113673347-A</span></p>
<p class="p105"><span class="s93"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22YOU%20Y%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s123">YOU Y</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22HE%20G%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">HE G</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22ZHU%20L%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">ZHU L</span></a></span></p>
<p class="p5"><span class="s93"><b>Assignee(s) </b></span><span class="s18">UNIV HANGZHOU DIANZI</span></p>
<p class="p77"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2021-D7113L</span></p>
<p class="p44"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">2021<span class="Apple-converted-space">  </span>29</span></p>
<p class="p105"><span class="s23"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:2021B70701">Method for generating peptide-based vaccine, involves training <span class="s122">Wasserstein</span><span class="s123"> Generative Adversarial Network (WGAN) only on positive binding peptide sequences while updating generator to minimize kernel Maximum Mean Discrepancy (MMD) loss</span></a></span></p>
<p class="p5"><span class="s18">US2021319847-A1WO2021211233-A1</span></p>
<p class="p105"><span class="s93"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22DURDANOVIC%20I%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s123">DURDANOVIC I</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22GRAF%20H%20P%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">GRAF H P</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22MIN%20R%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">MIN R</span></a></span></p>
<p class="p5"><span class="s93"><b>Assignee(s) </b></span><span class="s18">NEC LAB AMERICA INC</span></p>
<p class="p77"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2021-B70701</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space"> </span>2021 30</span></p>
<p class="p8"><span class="s17"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:2021D7162W">Method for adapting machine learning/prediction systems from one domain to another domain, involves training classifier networks as discriminator by maximizing <span class="s122">Wasserstein</span><span class="s123"> distance-based discrepancy between class probability predictions</span></a></span></p>
<p class="p5"><span class="s18">US11188795-B1</span></p>
<p class="p105"><span class="s93"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22ULBRICHT%20D%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s123">ULBRICHT D</span></a></span><span class="s124"> and <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22LEE%20C%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">LEE C</span></a></span></p>
<p class="p77"><span class="s18"><b>Assignee(s) </b></span><span class="s124">APPLE INC</span></p>
<p class="p77"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2021-D7162W</span></p>
<p class="p77"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s93"><span class="Apple-converted-space"> </span></span><span class="s2"> 2021 31</span></p>
<p class="p8"><span class="s126"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:202170971U">Wasserstein<span class="s17"> generative adversarial network-gradient penalty based radar high-resolution range profile database constructing method, involves combining target sample group and small sample group for finishing construction of database</span></a></span></p>
<p class="p5"><span class="s18">CN112946600-A</span></p>
<p class="p105"><span class="s93"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22WANG%20P%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s123">WANG P</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22LIU%20H%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">LIU H</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22JIU%20B%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">JIU B</span></a></span></p>
<p class="p77"><span class="s18"><b>Assignee(s) </b></span><span class="s124">UNIV XIDIAN</span></p>
<p class="p77"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2021-70971U</span></p>
<p class="p77"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space"> </span>2021 32</span></p>
<p class="p105"><span class="s23"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:202141197G">Method for synthesizing high-energy image based on <span class="s122">Wasserstein</span><span class="s123"> generating countermeasure network model by using electronic device, involves utilizing arbiter network for judging high energy image synthesized by generator network</span></a></span></p>
<p class="p5"><span class="s18">CN112634390-A</span></p>
<p class="p105"><span class="s93"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22ZHENG%20H%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s123">ZHENG H</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22HU%20Z%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">HU Z</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22ZHOU%20H%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">ZHOU H</span></a></span></p>
<p class="p5"><span class="s93"><b>Assignee(s) </b></span><span class="s18">SHENZHEN INST ADVANCED TECHNOLOGY</span></p>
<p class="p77"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2021-41197G</span></p>
<p class="p77"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space"> </span>2021 33</span></p>
<p class="p107"><span class="s23"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:202160602R">Method for unsupervised multi-view three-dimensional point cloud combined registration based on <span class="s122">wasserstein</span><span class="s123"> generative adversarial network (WGAN) involves setting number of generator and discriminator training to be M times</span></a></span></p>
<p class="p5"><span class="s18">CN112837356-A</span></p>
<p class="p105"><span class="s93"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22WANG%20Y%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s123">WANG Y</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22PENG%20W%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">PENG W</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22WU%20H%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">WU H</span></a></span></p>
<p class="p77"><span class="s18"><b>Assignee(s) </b></span><span class="s124">UNIV HUNAN</span></p>
<p class="p108"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2021-60602R</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space"> </span>2021 34</span></p>
<p class="p107"><span class="s23"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:2021E61157">Method for performing seismic record inversion, involves optimizing dual <span class="s122">Wasserstein</span><span class="s123"> generative adversarial network model, and inputting large sample unlabeled seismic record into optimized inversion generator to generate corresponding large sample wave impedance</span></a></span></p>
<p class="p5"><span class="s18">CN113722893-A</span></p>
<p class="p77"><span class="s18"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22WANG%20Z%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s123">WANG Z</span></a></span></p>
<p class="p5"><span class="s93"><b>Assignee(s) </b></span><span class="s18">UNIV CHINA PETROLEUM BEIJING</span></p>
<p class="p108"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2021-E61157</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p44"><span class="s2"><span class="Apple-converted-space">  </span></span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space"> </span>2021 35</span></p>
<p class="p109"><span class="s126"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:2021525281">Wasserstein<span class="s17"> space based visual dimensionality reduction method, involves performing normalization pre-processing on high-dimensional data and updating position of projection point until reaching stop condition to obtain projection result</span></a></span></p>
<p class="p5"><span class="s18">CN112765426-A</span></p>
<p class="p77"><span class="s18"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22QIN%20H%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s123">QIN H</span></a></span><span class="s124"> and <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22CHEN%20L%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">CHEN L</span></a></span></p>
<p class="p5"><span class="s93"><b>Assignee(s) </b></span><span class="s18">UNIV CHONGQING POSTS &amp; TELECOM</span></p>
<p class="p108"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2021-525281</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space">  </span>2021 36</span></p>
<p class="p109"><span class="s17"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:2021A3597D">Method for estimating time delay distance, involves calculating time delay for each unique pair of multiple sensors by minimizing <span class="s122">Wasserstein</span><span class="s123"> distance between two cumulative distribution transforms corresponding to unique pair</span></a></span></p>
<p class="p5"><span class="s18">US2021281361-A1</span></p>
<p class="p105"><span class="s93"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22CRANCH%20G%20A%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s123">CRANCH G A</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22MENKART%20N%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">MENKART N</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22HUTCHINSON%20M%20N%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">HUTCHINSON M N</span></a></span></p>
<p class="p5"><span class="s93"><b>Assignee(s) </b></span><span class="s18">US SEC OF NAVY</span></p>
<p class="p108"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2021-A3597D</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space">  </span>2021 37</span></p>
<p class="p109"><span class="s17"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:202172556R">Computer-based method for generating tailored medical recipes for mental health disorders, involves transmitting that recipes, generative adversarial neural network (GAN) comprises <span class="s122">wasserstein</span><span class="s123"> GAN (WGAN) and self-Attention GAN (SAGAN)</span></a></span></p>
<p class="p5"><span class="s18">US11049605-B1</span></p>
<p class="p77"><span class="s18"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22PETERS%20F%20L%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s123">PETERS F L</span></a></span></p>
<p class="p77"><span class="s18"><b>Assignee(s) </b></span><span class="s124">CORTERY AB</span></p>
<p class="p108"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2021-72556R</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space">  </span>2021 38</span></p>
<p class="p107"><span class="s23"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:2021C4660T">Cross-domain recommendation method based on double-flow-based <span class="s122">wasserstein</span><span class="s123"> self-encoder, involves obtaining input data to obtain user-item-score data of A data domain and user item score data of B domain</span></a></span></p>
<p class="p5"><span class="s18">CN113536116-A</span></p>
<p class="p105"><span class="s93"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22XIE%20H%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s123">XIE H</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22ZUO%20Z%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">ZUO Z</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22NIE%20J%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">NIE J</span></a></span></p>
<p class="p5"><span class="s93"><b>Assignee(s) </b></span><span class="s18">UNIV CHINA OCEAN</span></p>
<p class="p108"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2021-C4660T</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space">  </span>2021 39</span></p>
<p class="p107"><span class="s23"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:2021B8909U">Rolling bearing enhanced diagnostic method based on personal digital assistant-<span class="s122">wasserstein</span><span class="s123"> generative adversarial networks gradient penalty, involves evaluating quality of generated sample to output fault model with high quality</span></a></span></p>
<p class="p5"><span class="s18">CN113486931-A</span></p>
<p class="p105"><span class="s93"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22GE%20H%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s123">GE H</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22ZHANG%20Q%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">ZHANG Q</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22CHEN%20J%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">CHEN J</span></a></span></p>
<p class="p5"><span class="s93"><b>Assignee(s) </b></span><span class="s18">UNIV NANJING AERONAUTICS &amp; ASTRONAUTICS</span></p>
<p class="p108"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2021-B8909U</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p44"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space"> </span>2021 40</span></p>
<p class="p107"><span class="s23"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:2021C4734E">Method for predicting bearing remaining life based on improved residual network and <span class="s122">wasserstein</span><span class="s123">-generative adversarial network used in mechanical transmission comprises sending common feature space to full-connected neural network structure bearing remaining life prediction model</span></a></span></p>
<p class="p5"><span class="s18">CN113536697-A</span></p>
<p class="p105"><span class="s93"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22ZHAO%20Z%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s123">ZHAO Z</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22XU%20J%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">XU J</span></a> and <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22SHEN%20Y%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">SHEN Y</span></a></span></p>
<p class="p5"><span class="s93"><b>Assignee(s) </b></span><span class="s18">UNIV JIANGNAN</span></p>
<p class="p108"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p104"><span class="s2">2021-C4734E</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space"> </span>2021 41</span></p>
<p class="p105"><span class="s27"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:2021C40982">Method for analyzing unbalanced data set based on <span class="s127">WGAN</span><span class="s128"> training convergence, involves changing training time of discriminator, and outputting corresponding prediction tag to finish classification of network data safety</span></a></span></p>
<p class="p5"><span class="s18">CN113537313-A</span></p>
<p class="p77"><span class="s129"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22CHEN%20Z%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s121">CHEN Z</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22ZHANG%20L%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">ZHANG L</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22XU%20Y%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">XU Y</span></a></span></p>
<p class="p5"><span class="s30"><b>Assignee(s) </b></span><span class="s18">UNIV HANGZHOU DIANZI</span></p>
<p class="p14"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2021-C40982</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space">  </span>2021 42</span></p>
<p class="p6"><span class="s17"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:2021C05218">Process industry soft measurement data supplementing method based on self-supervised variational auto-encoder wasserstein generative adversarial network (SVAE-<span class="s122">WGAN</span><span class="s123">) in idustrial field, involves calculating output distribution of encoder network</span></a></span></p>
<p class="p5"><span class="s18">CN113505477-A</span></p>
<p class="p105"><span class="s30"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22XU%20J%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s119">XU J</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22ZHANG%20Q%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">ZHANG Q</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22GAO%20S%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">GAO S</span></a></span></p>
<p class="p5"><span class="s30"><b>Assignee(s) </b></span><span class="s18">UNIV NORTHWEST NORMAL</span></p>
<p class="p14"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2021-C05218</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space"> </span>2021 43</span></p>
<p class="p105"><span class="s27"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:2021B70701">Method for generating peptide-based vaccine, involves training Wasserstein Generative Adversarial Network (<span class="s127">WGAN</span><span class="s128">) only on positive binding peptide sequences while updating generator to minimize kernel Maximum Mean Discrepancy (MMD) loss</span></a></span></p>
<p class="p5"><span class="s18">US2021319847-A1WO2021211233-A1</span></p>
<p class="p105"><span class="s30"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22DURDANOVIC%20I%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s119">DURDANOVIC I</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22GRAF%20H%20P%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">GRAF H P</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22MIN%20R%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">MIN R</span></a></span></p>
<p class="p5"><span class="s30"><b>Assignee(s) </b></span><span class="s18">NEC LAB AMERICA INC</span></p>
<p class="p14"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2021-B70701</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space"> </span>2021 44</span></p>
<p class="p105"><span class="s27"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:202151255C">Method for generating biological Raman spectrum data based on <span class="s127">WGAN</span><span class="s128"> resistance generating network comprises performing iterative training on generating network and judging network to obtain generated data of false true Raman spectrum</span></a></span></p>
<p class="p5"><span class="s18">CN112712857-A</span></p>
<p class="p105"><span class="s30"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22ZHU%20L%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s119">ZHU L</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22DING%20J%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">DING J</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22ZHUANG%20W%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">ZHUANG W</span></a></span></p>
<p class="p5"><span class="s30"><b>Assignee(s) </b></span><span class="s18">UNIV BEIJING INFORMATION SCI &amp; TECHNOLOG</span></p>
<p class="p14"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2021-51255C</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space"> </span>2021 45</span></p>
<p class="p6"><span class="s17"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:202160602R">Method for unsupervised multi-view three-dimensional point cloud combined registration based on wasserstein generative adversarial network (<span class="s122">WGAN</span><span class="s123">) involves setting number of generator and discriminator training to be M times</span></a></span></p>
<p class="p5"><span class="s18">CN112837356-A</span></p>
<p class="p77"><span class="s129"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22WANG%20Y%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s121">WANG Y</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22PENG%20W%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">PENG W</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22WU%20H%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">WU H</span></a></span></p>
<p class="p14"><span class="s18"><b>Assignee(s) </b></span><span class="s120">UNIV HUNAN</span></p>
<p class="p14"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2021-60602R</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space">  </span>2021 46</span></p>
<p class="p105"><span class="s27"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:2021C5045Q">Improved private aggregation-of-teacher series based <span class="s127">WGAN</span><span class="s128">-GP privacy protection method, involves generating synthesized data by optimizing teacher classifier cluster for training machine learning models according to original sensitive training data protection process</span></a></span></p>
<p class="p5"><span class="s18">CN113553624-A</span></p>
<p class="p77"><span class="s129"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22NIE%20P%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s121">NIE P</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22HAN%20Z%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">HAN Z</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22YANG%20Z%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">YANG Z</span></a></span></p>
<p class="p5"><span class="s30"><b>Assignee(s) </b></span><span class="s18">UNIV TIANJIN</span></p>
<p class="p14"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2021-C5045Q</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space"> </span>2021 47</span></p>
<p class="p105"><span class="s27"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:2021A0301C">Wind power output power prediction method and wasserstein generative adversarial networks (<span class="s127">WGAN</span><span class="s128">) network, has filling missing value of wind power data and abnormal value, normalizing data set as input data of prediction model, and outputting prediction result after training test of prediction mode</span></a></span></p>
<p class="p5"><span class="s18">CN113298297-A</span></p>
<p class="p77"><span class="s129"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22WANG%20Y%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s121">WANG Y</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22WU%20Y%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">WU Y</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22LIU%20G%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">LIU G</span></a></span></p>
<p class="p5"><span class="s30"><b>Assignee(s) </b></span><span class="s18">UNIV INNER MONGOLIA TECHNOLOGY</span></p>
<p class="p14"><span class="s18"><b>Derwent Primary Accession Nu</b></span><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p110"><span class="s1"><a href="https://arxiv.org/pdf/2012.09729"><b>2021 48 patent</b><span class="s130"><b></b></span></a></span></p>
<p class="p111"><span class="s23"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:2021C05218">Process industry soft measurement data supplementing method based on self-supervised variational auto-encoder <span class="s131">wasserstein</span><span class="s125"> generative adversarial network (SVAE-</span><span class="s131">WGAN</span><span class="s125">) in idustrial field, involves calculating output distribution of encoder network</span></a></span></p>
<p class="p75"><span class="s18">CN113505477-A</span></p>
<p class="p111"><span class="s93"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22XU%20J%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s132">XU J</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22ZHANG%20Q%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s132">ZHANG Q</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22GAO%20S%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s132">GAO S</span></a></span></p>
<p class="p75"><span class="s93"><b>Assignee(s) </b></span><span class="s18">UNIV NORTHWEST NORMAL</span></p>
<p class="p14"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p102"><span class="s2">2021-C05218</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2021 49</span></p>
<p class="p10"><span class="s18"><b>Wasserstein</b> space-based visual dimension reduction method</span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/a1/dd/a5/ee1956866e0217/CN112765426A.pdf"><span class="s16">CN112765426A</span></a> </span><span class="s19">秦红星</span><span class="s18"> </span><span class="s19">重庆邮电大学</span></p>
<p class="p14"><span class="s18">Priority 2021-01-18 • Filed 2021-01-18 • Published 2021-05-07</span></p>
<p class="p14"><span class="s18">6. The visualization dimension reduction method based on <b>Wasserstein</b> space according to claim 5, wherein: the S5 specifically includes: note P i Is the ith row, Q, of the matrix P i Similarly, considered as a column vector; w represents the 1-<b>Wasserstein</b> distance and the dual form of the loss function …<span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p42"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s2">2021 50</span></p>
<p class="p17"><span class="s17"><a href="https://patents.google.com/patent/US11176477B2/en?q=wasserstein">… for high-dimension unsupervised anomaly detection using kernalized <span class="s22"><b>wasserstein</b> …</span></a></span></p>
<p class="p14"><span class="s18">KR <a href="https://patentimages.storage.googleapis.com/ea/58/4a/cacf67e4c6cedc/KR102202842B1.pdf"><span class="s5">KR102202842B1</span></a> </span><span class="s78">백명희조</span><span class="s18"> </span><span class="s78">서울대학교산학협력단</span></p>
<p class="p14"><span class="s18">Priority 2019-08-13 • Filed 2019-08-13 • Granted 2021-01-14 • Published 2021-01-14</span></p>
<p class="p14"><span class="s18">The present invention relates to a learning method and a learning apparatus for high-dimension unsupervised abnormality detection using a kernalized <b>Wasserstein</b> autoencoder to decrease excessive computations of a Christoffel function, and a test method and a test apparatus using the same.</span></p>
<p class="p42"><span class="s2"><span class="Apple-converted-space"> </span><a href="https://patents.google.com/?q=allintitle:+wasserstein+OR+wgan&amp;oq=allintitle:+wasserstein+OR+wgan#"><span class="s133"><span class="Apple-converted-space"> </span></span></a></span></p>
<p class="p14"><span class="s2">2021 51</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/?q=allintitle:+wasserstein+OR+wgan&amp;oq=allintitle:+wasserstein+OR+wgan#">Industrial anomaly detection method and device based on <span class="s5"><b>WGAN</b></span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/f3/ad/eb/a426bb2b884839/CN113554645A.pdf"><span class="s5">CN113554645A</span></a> </span><span class="s19">杭天欣</span><span class="s18"> </span><span class="s19">常州微亿智造科技有限公司</span></p>
<p class="p14"><span class="s18">Priority 2021-09-17 • Filed 2021-09-17 • Published 2021-10-26</span></p>
<p class="p14"><span class="s18">constructing an original <b>WGAN</b> model, wherein the original <b>WGAN</b> model comprises a generator and a discriminator; inputting the first data set and the second data set into the original <b>WGAN</b> model to train the original <b>WGAN</b> model to obtain the <b>WGAN</b> anomaly detection model, wherein the first data set …</span></p>
<p class="p42"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p77"><span class="s134"><span class="Apple-converted-space"> </span></span><span class="s135"> </span><span class="s98">.<span class="Apple-converted-space">  </span>2021 52<br>
<a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=1&amp;SID=7D5Fv3zP6jUfjcaXwDy&amp;page=1&amp;doc=7"><span class="s136"><b>Method for synthesizing high-energy image based on </b></span><span class="s137"><b>Wasserstein</b></span><span class="s136"><b> generating countermeasure network model by using electronic device, involves utilizing arbiter network for judging high energy image synthesized by generator network</b></span></a></span></p>
<p class="p14"><span class="s2"><b>Patent Number: CN112634390-A</b></span></p>
<p class="p14"><span class="s2"><b>Patent Assignee: SHENZHEN INST ADVANCED TECHNOLOGY</b></span></p>
<p class="p14"><span class="s2"><b>Inventor(s): ZHENG H; HU Z; LIANG D; et al.</b></span></p>
<p class="p14"><span class="s2"><br>
<span class="Apple-converted-space">  </span>2021 53</span></p>
<p class="p17"><span class="s17"><a href="https://patents.google.com/patent/CN112712857A/en?q=wgan&amp;oq=wgan&amp;page=1">Method for generating biological Raman spectrum data based on <span class="s22"><b>WGAN (WGAN</b>) …</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/17/3f/40/c46af029ba6e84/CN112712857A.pdf"><span class="s5">CN112712857A</span></a> </span><span class="s19">祝连庆</span><span class="s18"> </span><span class="s19">北京信息科技大学</span></p>
<p class="p14"><span class="s18">Priority 2020-12-08 • Filed 2020-12-08 • Published 2021-04-27</span></p>
<p class="p14"><span class="s18">1. A method of generating bio-raman spectral data based on a <b>WGAN</b> antagonistic generation network, the method comprising the steps of: a, extracting part of Raman spectrum data from a Raman spectrum database to serve as a real sample, and preprocessing the Raman spectrum data; b, creating a normal …</span></p>
<p class="p9"><span class="s27"><a href="https://patents.google.com/patent/CN112712857A/en?q=Biological+Raman+Spectrum+Data+Based+on+WGAN...&amp;oq=Biological+Raman+Spectrum+Data+Based+on+WGAN...">Method for generating <span class="s35"><b>biological Raman spectrum data based on WGAN (WGAN</b>) …</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/17/3f/40/c46af029ba6e84/CN112712857A.pdf"><span class="s16">CN112712857A</span></a> </span><span class="s19">祝连庆</span><span class="s18"> </span><span class="s19">北京信息科技大学</span></p>
<p class="p14"><span class="s18">Priority 2020-12-08 • Filed 2020-12-08 • Published 2021-04-27</span></p>
<p class="p15"><span class="s2">The invention provides a method for generating <b>biological Raman spectrum data based on a WGAN</b> antagonistic generation network, which comprises the following steps: step a, extracting partial Raman spectrum data from a Raman spectrum database to<span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2021 54</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN112488956A/en?q=wgan&amp;oq=wgan&amp;page=1">Method for image restoration based on <span class="s16"><b>WGAN</b> network</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/e7/4d/d2/6cef5a556f6031/CN112488956A.pdf"><span class="s16">CN112488956A</span></a> </span><span class="s19">方巍</span><span class="s18"> </span><span class="s19">南京信息工程大学</span></p>
<p class="p14"><span class="s18">Priority 2020-12-14 • Filed 2020-12-14 • Published 2021-03-12</span></p>
<p class="p14"><span class="s18">3. The method for image inpainting based on <b>WGAN</b> network of claim 1, wherein in the step (1.3), through optimizing parameters and function algorithm: wherein, the activation function is specifically described as follows: 4. the method for image restoration based on <b>WGAN</b> network of claim 1, wherein …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2021 55</span></p>
<p class="p9"><span class="s27"><a href="https://patents.google.com/patent/CN113538266A/en?q=wgan&amp;oq=wgan&amp;page=1"><b>WGAN</b><span class="s35">-based fuzzy aerial image processing method</span></a></span></p>
<p class="p21"><span class="s79">CN <a href="https://patentimages.storage.googleapis.com/31/4c/7f/0f05823c5478ca/CN113538266A.pdf"><span class="s13">CN113538266A</span></a> </span><span class="s18">李业东</span><span class="s79"> </span><span class="s18">南京国电南自电网自动化有限公司</span></p>
<p class="p14"><span class="s18">Priority 2021-07-07 • Filed 2021-07-07 • Published 2021-10-22</span></p>
<p class="p14"><span class="s18">the fuzzy image processing model takes a <b>WGAN</b> network as a basic network and comprises a generator network and a discriminator network, wherein the generator network comprises a down-sampling network block and an up-sampling network block which are sequentially arranged, the discriminator network …</span></p>
<p class="p42"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s2">2021<span class="Apple-converted-space">  </span>56</span></p>
<p class="p17"><span class="s17"><a href="https://patents.google.com/patent/CN108549597A/en?q=wgan&amp;oq=wgan">Anti-disturbance image generation method based on <span class="s22"><b>WGAN</b>-GP</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/3b/16/83/03493dce022d77/CN113537467A.pdf"><span class="s5">CN113537467A</span></a> </span><span class="s19">蒋凌云</span><span class="s18"> </span><span class="s19">南京邮电大学</span></p>
<p class="p14"><span class="s18">Priority 2021-07-15 • Filed 2021-07-15 • Published 2021-10-22</span></p>
<p class="p14"><span class="s18">2. The <b>WGAN</b>-GP-based disturbance rejection image generation method according to claim 1, wherein: target loss function L <b>WGAN</b>-GP The expression of the calculation is</span><span class="s19">：</span><span class="s18"> In the formula (2), d (x) represents that the discriminator determines whether the x class label belongs to the class information in …</span><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2021 57</span></p>
<p class="p17"><span class="s17"><a href="https://patents.google.com/patent/CN112994115A/en?q=wgan&amp;oq=wgan&amp;page=1">New energy capacity configuration method based on <span class="s22"><b>WGAN</b> scene simulation and …</span></a></span></p>
<p class="p15"><span class="s2">CN <a href="https://patentimages.storage.googleapis.com/c0/d5/8f/b0670661fc4d5d/CN112994115A.pdf"><span class="s26">CN112994115A</span></a> </span><span class="s11">马燕峰</span><span class="s2"> </span><span class="s11">华北电力大学（保定）</span></p>
<p class="p15"><span class="s2">Priority 2019-12-18 • Filed 2019-12-18 • Published 2021-06-18</span></p>
<p class="p14"><span class="s18">A new energy capacity configuration method based on Wasserstein generation countermeasure network (<b>WGAN</b>) scene simulation and time sequence production simulation is characterized by mainly comprising the following specific steps: step 1, simulating a large number of wind and light resource …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2021 58</span></p>
<p class="p17"><span class="s17"><a href="https://patents.google.com/patent/CN113850855A/en?q=wgan&amp;oq=wgan&amp;page=1">Road texture picture enhancement method coupling traditional method and <span class="s22"><b>WGAN</b>-GP</span></a></span></p>
<p class="p17"><span class="s17"><a href="https://patentimages.storage.googleapis.com/34/da/33/acdddd068a388e/CN113850855A.pdf">CN113850855A</a></span><span class="s93"> </span><span class="s101">徐子金</span><span class="s93"> </span><span class="s101">北京工业大学</span></p>
<p class="p14"><span class="s18">Filed 2021-08-27 • Published 2021-12-28</span></p>
<p class="p14"><span class="s18">1. A road texture picture enhancement method coupling a traditional method and <b>WGAN</b>-GP is characterized in that a new high-quality texture picture is generated by utilizing a road surface macro texture picture obtained by a commercial handheld three-dimensional laser scanner through a traditional …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2021 59</span></p>
<p class="p17"><span class="s17"><a href="https://patents.google.com/patent/CN113298297A/en?q=wgan&amp;oq=wgan&amp;page=1">Wind power output power prediction method based on isolated forest and <span class="s22"><b>WGAN</b> …</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/70/be/92/d5c5c07ce6b999/CN113298297A.pdf"><span class="s5">CN113298297A</span></a> </span><span class="s19">王永生</span><span class="s18"> </span><span class="s19">内蒙古工业大学</span></p>
<p class="p14"><span class="s18">Priority 2021-05-10 • Filed 2021-05-10 • Published 2021-08-24</span></p>
<p class="p14"><span class="s18">7. The isolated forest and <b>WGAN</b> network based wind power output power prediction method of claim 6, wherein the interpolation operation comprises the following steps: step 2.1, inputting the random noise vector z into a generator G to obtain a generated time sequence G (z), wherein G (z) is a …</span><span class="s2"><br>
<br>
</span><span class="s138">2021 60</span></p>
<p class="p9"><span class="s56"><a href="https://patents.google.com/patent/WO2022165876A1/en?q=wgan&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wgan"><b>Wgan</b><span class="s16">-based unsupervised multi-view three-dimensional point cloud joint …</span></a></span></p>
<p class="p9"><span class="s15"><i>WO</i> CN <a href="https://patentimages.storage.googleapis.com/f6/5b/b7/2f66ff8c5f80c9/WO2022165876A1.pdf"><span class="s16">WO2022165876A1 </span></a></span><span class="s139">王耀南</span><span class="s15"> </span><span class="s139">湖南大学</span></p>
<p class="p14"><span class="s2">Priority 2021-02-06 • Filed 2021-02-25 • Published 2022-08-11</span></p>
<p class="p14"><span class="s2">A kind of unsupervised multi-view three-dimensional point cloud joint registration method based on <b>WGAN</b> according to claim 8, is characterized in that, described step S51 is specifically: The <b>WGAN</b> network trains the discriminator network f ω with the parameter ω and the last layer is not a …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2021 61</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/CN113536697A/en?q=wgan&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wgan">… life prediction method based on improved residual error network and <span class="s35"><b>WGAN</b></span></a></span></p>
<p class="p9"><span class="s15">CN <a href="https://patentimages.storage.googleapis.com/41/5a/36/bd77dd5a6a3644/CN113536697A.pdf"><span class="s16">CN113536697A </span></a></span><span class="s139">沈艳霞</span><span class="s15"> </span><span class="s139">江南大学</span></p>
<p class="p14"><span class="s2">Priority 2021-08-24 • Filed 2021-08-24 • Published 2021-10-22</span></p>
<p class="p14"><span class="s2">8. The improved residual network and <b>WGAN</b> based bearing remaining life prediction method of claim 1, wherein: in step S3, the <b>WGAN</b> model uses the Wasserstein distance to measure the distribution difference between two feature sets, and optimizes the generator under the domain discriminator to …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2021 62</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/?q=wgan&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wgan#">Process industry soft measurement data supplementing method based on SVAE-<span class="s35"><b>WGAN</b></span></a></span></p>
<p class="p14"><span class="s2">CN <a href="https://patentimages.storage.googleapis.com/fa/1f/cb/eb4a2bd4f28ee9/CN113505477B.pdf"><span class="s26">CN113505477B </span></a></span><span class="s11">高世伟</span><span class="s2"> </span><span class="s11">西北师范大学</span></p>
<p class="p14"><span class="s2">Priority 2021-06-29 • Filed 2021-06-29 • Granted 2022-05-20 • Published 2022-05-20</span></p>
<p class="p14"><span class="s2">1. A SVAE-<b>WGAN</b>-based process industry soft measurement data supplementing method in the industrial field is characterized by comprising the following steps: step 1: determining input and output of a model according to an industrial background, selecting a proper training data set, inputting time …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2021 63</span></p>
<p class="p77"><span class="s56"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=1&amp;SID=5ColOYdAcEC85d8WtJO&amp;page=1&amp;doc=10">Cement clinker free calcium sample data enhancement and prediction method based on R-<span class="s137">WGAN</span><span class="s136"> comprises performing convolution operation on input data and realizing regression prediction network in R-</span><span class="s137">WGAN</span><span class="s136"> of cement clinker free calcium oxide</span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN112906976-A</span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV YANSHAN</span></p>
<p class="p5"><span class="s2">Inventor(s): HAO X; LIU L; HUANG G; et al.</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2021 64</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/CN112946600A/en?q=wgan&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wgan">Method for constructing radar HRRP database based on <span class="s35"><b>WGAN</b>-GP</span></a></span></p>
<p class="p14"><span class="s2">CN <a href="https://patentimages.storage.googleapis.com/ca/f4/d4/694c9bf3fcb253/CN112946600A.pdf"><span class="s26">CN112946600A </span></a></span><span class="s11">王鹏辉</span><span class="s2"> </span><span class="s11">西安电子科技大学</span></p>
<p class="p14"><span class="s2">Priority 2021-03-17 • Filed 2021-03-17 • Published 2021-06-11</span></p>
<p class="p14"><span class="s2">The invention discloses a <b>WGAN</b>-GP-based HRRP database construction method, which comprises the following steps: (1) generating a training set; (2) constructing a <b>WGAN</b>-GP network; (3) generating a sample set; (4) training the <b>WGAN</b>-GP network; (5) and completing the construction of the HRRP database.</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2021 65</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/CN114037001A/en?q=wgan&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wgan">Mechanical pump small sample fault diagnosis method based on <span class="s35"><b>WGAN</b>-GP-C and …</span></a></span></p>
<p class="p14"><span class="s2">CN <a href="https://patentimages.storage.googleapis.com/24/ca/3e/6d998eb7545962/CN114037001A.pdf"><span class="s26">CN114037001A </span></a></span><span class="s11">王雪仁</span><span class="s2"> </span><span class="s11">中国人民解放军</span><span class="s2">92578</span><span class="s11">部队</span></p>
<p class="p14"><span class="s2">Priority 2021-10-11 • Filed 2021-10-11 • Published 2022-02-11</span></p>
<p class="p14"><span class="s2">(2.3) when the <b>WGAN</b>-GP-C which is trained is used for generating a sample, screening the generated sample data; (2.4) the quality of the generated sample data is evaluated by adopting the maximum mean difference MMD and the model is adjusted according to the maximum mean difference MMD. 5. The <b>WGAN</b> …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2021 66</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/patent/CN114372490A/en?q=wgan&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wgan">sEMG data enhancement method based on BiLSTM and <span class="s35"><b>WGAN</b>-GP networks</span></a></span></p>
<p class="p14"><span class="s2">CN <a href="https://patentimages.storage.googleapis.com/cd/3d/29/51a3b888e43977/CN114372490A.pdf"><span class="s26">CN114372490A </span></a></span><span class="s11">方银锋</span><span class="s2"> </span><span class="s11">杭州电子科技大学</span></p>
<p class="p14"><span class="s2">Priority 2021-12-29 • Filed 2021-12-29 • Published 2022-04-19</span></p>
<p class="p14"><span class="s2">A sEMG data enhancement method based on a BilSTM and <b>WGAN</b>-GP network comprises the following specific steps: s1, collecting surface electromyogram signals and preprocessing the signals; step S2, standardizing the preprocessed real electromyographic data, and dividing the standardized real …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2021 67</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/?q=wgan&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wgan#">… local surface slow-speed moving object classification method based on <span class="s35"><b>WGAN</b></span></a></span></p>
<p class="p14"><span class="s2">CN <a href="https://patentimages.storage.googleapis.com/77/12/ac/bea157091089dd/CN113569632A.pdf"><span class="s26">CN113569632A </span></a></span><span class="s11">周峰</span><span class="s2"> </span><span class="s11">西安电子科技大学</span></p>
<p class="p14"><span class="s2">Priority 2021-06-16 • Filed 2021-06-16 • Published 2021-10-29</span></p>
<p class="p14"><span class="s2">5. The method for classifying a small sample local area slow moving target according to claim 4, wherein in the substep 2.2, the <b>WGAN</b> introduces Wasserstein distance to measure the difference between the generated data distribution and the real data distribution when performing network training;</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2021 68</span></p>
<p class="p6"><span class="s1"><a href="https://patents.google.com/?q=wgan&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wgan#">Unbalanced data set analysis method based on <span class="s35"><b>WGAN</b> training convergence</span></a></span></p>
<p class="p14"><span class="s2">CN <a href="https://patentimages.storage.googleapis.com/05/38/cc/7498545b72e8e8/CN113537313A.pdf"><span class="s26">CN113537313A </span></a></span><span class="s11">许艳萍</span><span class="s2"> </span><span class="s11">杭州电子科技大学</span></p>
<p class="p14"><span class="s2">Priority 2021-06-30 • Filed 2021-06-30 • Published 2021-10-22</span></p>
<p class="p14"><span class="s2">1. An imbalance data set analysis method based on <b>WGAN</b> training convergence is characterized in that: the method specifically comprises the following steps: step one, data acquisition and pretreatment Collecting network security data, dividing the network security data into a multi-class data …</span></p>
<p class="p112"><span class="s2"><br>
</span></p>
<p class="p12"><span class="s1"><a href="https://link.springer.com/content/pdf/10.1007/s00500-021-06725-x.pdf"><span class="Apple-converted-space"> </span></a><a href="https://libproxy.mit.edu/login?&amp;url=https://link.springer.com/content/pdf/10.1007/s00158-022-03253-6"><span class="s140"><span class="Apple-converted-space"> </span></span></a></span></p>
<p class="p113"><span class="s1"><a href="https://mit.primo.exlibrisgroup.com/discovery/fulldisplay?docid=cdi_ieee_primary_9610032&amp;context=PC&amp;vid=01MIT_INST:MIT&amp;lang=en&amp;search_scope=all&amp;adaptor=Primo%20Central&amp;tab=all&amp;query=title%2Ccontains%2Cwgan%2CAND&amp;mode=advanced&amp;pfilter=dr_s%2Cexact%2C20220101%2CAND&amp;pfilter=dr_e%2Cexact%2C99991231%2CAND&amp;offset=0"><span class="Apple-converted-space"> </span><span class="s141"></span></a></span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2021 69</span></p>
<p class="p9"><span class="s27"><a href="https://patents.google.com/patent/CN114301667A/en?q=wgan&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wgan&amp;page=1"><b>WGAN</b><span class="s35"> dynamic punishment-based network security unbalance data set analysis …</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/1b/35/e5/fe1448dd633401/CN114301667A.pdf"><span class="s16">CN114301667A </span></a></span><span class="s19">许艳萍</span><span class="s18"> </span><span class="s19">杭州电子科技大学</span></p>
<p class="p14"><span class="s18">Priority 2021-12-27 • Filed 2021-12-27 • Published 2022-04-08</span></p>
<p class="p14"><span class="s18">2. The method of claim 1 wherein the method of analyzing an imbalance data set based on <b>WGAN</b> training convergence comprises: the imbalance IR and oversampling ratio R between different classes of data are defined as: wherein N is + And N - Respectively the quantity of the multi-class data and the small …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2021 70</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN114219778A/en?q=wgan&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wgan&amp;page=1">Data depth enhancement method based on <span class="s16"><b>WGAN</b>-GP data generation and Poisson …</span></a></span></p>
<p class="p9"><span class="s30">CN <a href="https://patentimages.storage.googleapis.com/f6/f9/aa/c0ab2ed1c95274/CN114219778A.pdf"><span class="s35">CN114219778A </span></a></span><span class="s36">侯越</span><span class="s30"> </span><span class="s36">北京工业大学</span></p>
<p class="p14"><span class="s18">Priority 2021-12-07 • Filed 2021-12-07 • Published 2022-03-22</span></p>
<p class="p14"><span class="s18">The invention discloses a data depth enhancement method based on <b>WGAN</b>-GP data generation and Poisson fusion, wherein <b>WGAN</b>-GP is a generation confrontation network with gradient punishment and is a generation model based on a game idea, and the generation model comprises two networks, namely a …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2021 71</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN113536697A/en?q=wgan&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wgan">Clothing attribute editing method based on improved <span class="s16"><b>WGAN</b></span></a></span></p>
<p class="p9"><span class="s30">CN <a href="https://patentimages.storage.googleapis.com/70/89/2b/d503282b2a7669/CN113793397A.pdf"><span class="s35">CN113793397A </span></a></span><span class="s36">张建明</span><span class="s30"> </span><span class="s36">浙江大学</span></p>
<p class="p14"><span class="s18">Priority 2021-07-30 • Filed 2021-07-30 • Published 2021-12-14</span></p>
<p class="p14"><span class="s18">1. A garment attribute editing method based on improved <b>WGAN</b> comprises a training stage and a testing stage, wherein the training stage is optimized in a supervised learning mode; in the testing stage, the converged network is adopted to generate clothing attributes; the method is characterized by …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2021 72</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN114218982A/en?q=wgan&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wgan&amp;page=1">Micro-seismic record denoising method based on improved <span class="s16"><b>WGAN</b> network and CBDNet</span></a></span></p>
<p class="p9"><span class="s30">CN <a href="https://patentimages.storage.googleapis.com/b6/b9/b4/3e774c5bb684a3/CN114218982A.pdf"><span class="s35">CN114218982A </span></a></span><span class="s36">盛冠群</span><span class="s30"> </span><span class="s36">三峡大学</span></p>
<p class="p14"><span class="s18">Priority 2021-11-26 • Filed 2021-11-26 • Published 2022-03-22</span></p>
<p class="p14"><span class="s18">1. The microseism record denoising method based on the improved <b>WGAN</b> network and the CBDNet is characterized by comprising the following steps of: the method comprises the following steps: collecting micro-seismic data; step two: generating forward simulation signals under different dominant …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2021 73</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN113792785A/en?q=wgan&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wgan&amp;page=1">Rapid identification method for ship attachment based on <span class="s16"><b>WGAN</b>-GP and YOLO</span></a></span></p>
<p class="p9"><span class="s142">CN</span><span class="s30"> <a href="https://patentimages.storage.googleapis.com/30/80/bb/4345e1fbc06759/CN113792785A.pdf"><span class="s35">CN113792785A </span></a></span><span class="s36">陈琦</span><span class="s30"> </span><span class="s36">上海理工大学</span></p>
<p class="p14"><span class="s18">Priority 2021-09-14 • Filed 2021-09-14 • Published 2021-12-14</span></p>
<p class="p14"><span class="s18">wherein L is the objective function of <b>WGAN</b>-GP; is the loss function of <b>WGAN</b> at Wasserstein distance; is a gradient penalty that is applied independently for each sample on a <b>WGAN</b> basis. 5. The <b>WGAN</b>-GP and YOLO based ship body attachment rapid identification method as claimed in claim 1, wherein …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2021 74</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN113627594A/en?q=wgan&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wgan&amp;page=1">One-dimensional time sequence data amplification method based on <span class="s16"><b>WGAN</b></span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/07/91/d8/78358bd5d1f748/CN113627594A.pdf"><span class="s16">CN113627594A </span></a></span><span class="s19">孙博</span><span class="s18"> </span><span class="s19">北京航空航天大学</span></p>
<p class="p14"><span class="s18">Priority 2021-08-05 • Filed 2021-08-05 • Published 2021-11-09</span></p>
<p class="p14"><span class="s18">4. The method of claim 1, wherein the <b>WGAN</b>-based one-dimensional time series data augmentation method comprises: in the "network model constructed by training" described in the third step, gaussian noise z to n (μ, σ) having a mean value of 0 and a standard deviation of 1 is used, μ is 0, and σ is …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2021 75</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN114037001A/en?q=wgan&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wgan">Power system harmonic law calculation method based on <span class="s16"><b>WGAN</b></span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/95/6b/cd/e08d02584ac62f/CN114217132A.pdf"><span class="s16">CN114217132A </span></a></span><span class="s19">梅文波</span><span class="s18"> </span><span class="s19">江苏弈赫能源科技有限公司</span></p>
<p class="p14"><span class="s18">Priority 2021-11-11 • Filed 2021-11-11 • Published 2022-03-22</span></p>
<p class="p14"><span class="s18">2. The <b>WGAN</b>-based electric power system harmonic law calculation method according to claim 1, wherein a sampling frequency of the current data in the first step is two times or more of a highest frequency in the signal. 3. The <b>WGAN</b>-based power system harmonic law calculation method according to …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2021 76</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN113850855A/en?q=wgan&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wgan&amp;page=1">Road texture picture enhancement method coupling traditional method and <span class="s16"><b>WGAN</b>-GP</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/34/da/33/acdddd068a388e/CN113850855A.pdf"><span class="s16">CN113850855A </span></a></span><span class="s19">徐子金</span><span class="s18"> </span><span class="s19">北京工业大学</span></p>
<p class="p14"><span class="s18">Priority 2021-08-27 • Filed 2021-08-27 • Published 2021-12-28</span></p>
<p class="p14"><span class="s18">1. A road texture picture enhancement method coupling a traditional method and <b>WGAN</b>-GP is characterized in that a new high-quality texture picture is generated by utilizing a road surface macro texture picture obtained by a commercial handheld three-dimensional laser scanner through a traditional …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2021 77</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN113537467A/en?q=wgan&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wgan&amp;page=1">Anti-disturbance image generation method based on <span class="s16"><b>WGAN</b>-GP</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/3b/16/83/03493dce022d77/CN113537467A.pdf"><span class="s16">CN113537467A </span></a></span><span class="s19">蒋凌云</span><span class="s18"> </span><span class="s19">南京邮电大学</span></p>
<p class="p14"><span class="s18">Priority 2021-07-15 • Filed 2021-07-15 • Published 2021-10-22</span></p>
<p class="p14"><span class="s18">2. The <b>WGAN</b>-GP-based disturbance rejection image generation method according to claim 1, wherein: target loss function L <b>WGAN</b>-GP The expression of the calculation is</span><span class="s19">：</span><span class="s18"> In the formula (2), d (x) represents that the discriminator determines whether the x class label belongs to the class information in …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2021 78</span></p>
<p class="p9"><span class="s27"><a href="https://patents.google.com/patent/CN113553624A/en?q=wgan&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wgan&amp;page=1"><b>WGAN</b><span class="s35">-GP privacy protection system and method based on improved PATE</span></a></span></p>
<p class="p9"><span class="s30">CN <a href="https://patentimages.storage.googleapis.com/7b/44/33/c8f2e33f7dd9a5/CN113553624A.pdf"><span class="s35">CN113553624A </span></a></span><span class="s36">杨张妍</span><span class="s30"> </span><span class="s36">天津大学</span></p>
<p class="p14"><span class="s18">Priority 2021-07-30 • Filed 2021-07-30 • Published 2021-10-26</span></p>
<p class="p15"><span class="s2">6. The <b>WGAN</b>-GP privacy protection system based on an improved PATE as claimed in claim 2, wherein in the student discriminator module: the student arbiter generates a sample through analysis and a prediction label output by the conditional differential privacy aggregator corresponding to the sample …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p69"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p12"><span class="s17"><a href="https://patents.google.com/xhr/query?url=q%3Dwgan%26before%3Dpriority%3A20211231%26after%3Dpriority%3A20210101%26oq%3D2021%2Bwgan%26page%3D2&amp;exp=&amp;download=true"><span class="Apple-converted-space"> </span><span class="s1"></span></a></span></p>
<p class="p14"><span class="s2">2021 79</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN113298297A/en?q=wgan&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wgan&amp;page=2">Wind power output power prediction method based on isolated forest and <span class="s16"><b>WGAN</b> …</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/70/be/92/d5c5c07ce6b999/CN113298297A.pdf"><span class="s16">CN113298297A </span></a></span><span class="s19">王永生</span><span class="s18"> </span><span class="s19">内蒙古工业大学</span></p>
<p class="p14"><span class="s18">Priority 2021-05-10 • Filed 2021-05-10 • Published 2021-08-24</span></p>
<p class="p14"><span class="s18">7. The isolated forest and <b>WGAN</b> network based wind power output power prediction method of claim 6, wherein the interpolation operation comprises the following steps: step 2.1, inputting the random noise vector z into a generator G to obtain a generated time sequence G (z), wherein G (z) is a …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p114"><span class="s1"><a href="https://patents.google.com/patent/CN113538266A/en?q=wgan&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wgan&amp;page=2"><b><span class="Apple-converted-space"> </span></b><span class="s3"><b></b></span></a></span></p>
<p class="p14"><span class="s2">2021 80</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN114218982A/en?q=Micro-seismic+record+denoising+method+based+on+improved+WGAN+network+and+CBDNet&amp;oq=Micro-seismic+record+denoising+method+based+on+improved+WGAN+network+and+CBDNet"><b>Micro-seismic record denoising method based on improved WGAN network and CBDNet</b><span class="s1"><b></b></span></a></span></p>
<p class="p9"><span class="s30">CN <a href="https://patentimages.storage.googleapis.com/b6/b9/b4/3e774c5bb684a3/CN114218982A.pdf"><span class="s35">CN114218982A </span></a></span><span class="s36">盛冠群</span><span class="s30"> </span><span class="s36">三峡大学</span></p>
<p class="p14"><span class="s18">Priority 2021-11-26 • Filed 2021-11-26 • Published 2022-03-22</span></p>
<p class="p15"><span class="s2"><b>Micro-seismic record denoising method based on improved WGAN network and CBDNet</b> Technical Field The invention relates to a microseism monitoring technology, in particular to a microseism record denoising method based on an improved WGAN network and CBDNet. Background The micro-seismic monitoring …</span></p>
<p class="p42"><span class="s18"><span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s2"><span class="Apple-converted-space"> </span>2021 81<span class="Apple-converted-space"> </span></span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN113792785A/en?q=Rapid+identification+method+for+ship+attachment+based+on+WGAN-GP+and+YOLO&amp;oq=Rapid+identification+method+for+ship+attachment+based+on+WGAN-GP+and+YOLO"><b>Rapid identification method for ship attachment based on WGAN-GP and YOLO</b><span class="s1"><b></b></span></a></span></p>
<p class="p9"><span class="s142">CN</span><span class="s30"> <a href="https://patentimages.storage.googleapis.com/30/80/bb/4345e1fbc06759/CN113792785A.pdf"><span class="s35">CN113792785A </span></a></span><span class="s36">陈琦</span><span class="s30"> </span><span class="s36">上海理工大学</span></p>
<p class="p14"><span class="s18">Priority 2021-09-14 • Filed 2021-09-14 • Published 2021-12-14</span></p>
<p class="p14"><span class="s18"><b>Rapid identification method for ship attachment based on WGAN-GP and YOLO</b> Technical Field The invention relates to the technical field of ship body attachment cleaning, in particular to a method for quickly identifying ship body attachments based on WGAN-GP and YOLO. Background The ocean occupies …</span></p>
<p class="p9"><span class="s30">CN <a href="https://patentimages.storage.googleapis.com/11/88/e5/ba0ac1eb8dd83c/CN113378959B.pdf"><span class="s35">CN113378959B </span></a></span><span class="s36">潘杰</span><span class="s30"> </span><span class="s36">中国矿业大学</span></p>
<p class="p14"><span class="s18">Priority 2021-06-24 • Filed 2021-06-24 • Granted 2022-03-15 • Published 2022-03-15</span></p>
<p class="p15"><span class="s2">wherein L is <b>WGAN</b> Representing the loss of the production countermeasure network, D (v, s) representing the result of the visual features v and the original semantic features s being fed to the discriminator network D, indicating that a visual trait is to be synthesized And the result of the original …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p10"><span class="s7"><a href="https://patents.google.com/patent/CN113554645B/en?q=wgan&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wgan"><span class="Apple-converted-space"> </span></a></span><span class="s2"> 2021 82</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN114722888A/en?q=wasserstein&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wasserstein">Early fault detection method based on <span class="s5"><b>Wasserstein</b> distance</span></a></span></p>
<p class="p10"><span class="s93">CN <a href="https://patentimages.storage.googleapis.com/b9/25/e0/c4583bd284d101/CN114722888A.pdf"><span class="s5">CN114722888A </span></a></span><span class="s101">曾九孙</span><span class="s93"> </span><span class="s101">中国计量大学</span></p>
<p class="p68"><span class="s18">Priority 2021-10-27 • Filed 2021-10-27 • Published 2022-07-08</span></p>
<p class="p68"><span class="s18">3. The early fault detection method based on <b>Wasserstein</b> distance as claimed in claim 2, characterized in that, by constructing dual form of model, the model is solved by Riemann block coordinate descent method, comprising the following steps: s2.1, adding two Lagrange multipliers to construct a …</span></p>
<p class="p68"><span class="s2"><br>
</span></p>
<p class="p68"><span class="s2">2021 83</span></p>
<p class="p10"><span class="s23"><a href="https://patents.google.com/patent/CN113010013A/en?q=wasserstein&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wasserstein"><b>Wasserstein</b><span class="s13"> distance-based motor imagery electroencephalogram migration …</span></a></span></p>
<p class="p10"><span class="s93">CN <a href="https://patentimages.storage.googleapis.com/af/cc/3a/448dd6163a590b/CN113010013A.pdf"><span class="s5">CN113010013A </span></a></span><span class="s101">罗浩远</span><span class="s93"> </span><span class="s101">华南理工大学</span></p>
<p class="p68"><span class="s18">Priority 2021-03-11 • Filed 2021-03-11 • Published 2021-06-22</span></p>
<p class="p68"><span class="s18">6. The <b>Wasserstein</b> distance-based motor imagery electroencephalogram migration learning method according to claim 1, wherein: in step 4), the <b>Wasserstein</b> distance training deep migration learning model is used, and the method comprises the following steps: 4.1) inputting the source domain data and …</span></p>
<p class="p68"><span class="s2"><br>
</span></p>
<p class="p68"><span class="s2">2021 84</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN114154405A/en?q=wasserstein&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wasserstein">… method for generating countermeasure network based on conditional <span class="s5"><b>Wasserstein</b></span></a></span></p>
<p class="p68"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/a7/15/06/6b9a64ca07c82d/CN114154405A.pdf"><span class="s13">CN114154405A </span></a></span><span class="s19">陈乾坤</span><span class="s18"> </span><span class="s19">东风汽车集团股份有限公司</span></p>
<p class="p68"><span class="s18">Priority 2021-11-19 • Filed 2021-11-19 • Published 2022-03-08</span></p>
<p class="p68"><span class="s18">3. The motor data enhancement method based on the conditional <b>Wasserstein</b> generation countermeasure network as claimed in claim 1, wherein the conditional <b>Wasserstein</b> generation countermeasure network is a combination of the conditional warerstein generation countermeasure network and the …</span></p>
<p class="p68"><span class="s2"><br>
</span></p>
<p class="p68"><span class="s2">2021 85</span></p>
<p class="p10"><span class="s23"><a href="https://patents.google.com/patent/CN113034695A/en?q=wasserstein&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wasserstein"><b>Wasserstein</b><span class="s13"> distance-based object envelope multi-view reconstruction and …</span></a></span></p>
<p class="p10"><span class="s93">CN <a href="https://patentimages.storage.googleapis.com/11/88/42/e230dd84526cfa/CN113034695A.pdf"><span class="s5">CN113034695A </span></a></span><span class="s101">何力</span><span class="s93"> </span><span class="s101">广东工业大学</span></p>
<p class="p68"><span class="s18">Priority 2021-04-16 • Filed 2021-04-16 • Published 2021-06-25</span></p>
<p class="p68"><span class="s18">7. The <b>Wasserstein</b> distance-based object envelope multi-view reconstruction and optimization method according to claim 5, wherein the specific process of step S4-3 is as follows: embedding the <b>Wasserstein</b>-based distance cost function into three-dimensional reconstruction, including: in equation (3) …</span></p>
<p class="p68"><span class="s2"><br>
</span></p>
<p class="p68"><span class="s2">2021 86</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN113673347A/en?q=wasserstein&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wasserstein">Characteristic similarity countermeasure network based on <span class="s5"><b>Wasserstein</b> distance</span></a></span></p>
<p class="p10"><span class="s93">CN <a href="https://patentimages.storage.googleapis.com/94/0b/7d/f7cd92d1afc176/CN113673347A.pdf"><span class="s5">CN113673347A </span></a></span><span class="s101">祝磊</span><span class="s93"> </span><span class="s101">杭州电子科技大学</span></p>
<p class="p68"><span class="s18">Priority 2021-07-20 • Filed 2021-07-20 • Published 2021-11-19</span></p>
<p class="p68"><span class="s18">6. The <b>Wasserstein</b> distance-based characterized similar countermeasure network of claim 1, wherein in S5: obtaining the round-trip probability of the destination domain of the source domain comprises multiplying the resulting P st </span><span class="s19">、</span><span class="s18">P ts The formula is as follows: P sts </span><span class="s19">＝</span><span class="s18">P st P ts </span><span class="s19">；</span><span class="s18"> in the formula, P sts …</span></p>
<p class="p68"><span class="s2"><br>
</span></p>
<p class="p68"><span class="s2">2021 87</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN113239610A/en?q=wasserstein&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wasserstein">Domain self-adaptive rolling bearing fault diagnosis method based on <span class="s5"><b>Wasserstein</b> …</span></a></span></p>
<p class="p10"><span class="s93">CN <a href="https://patentimages.storage.googleapis.com/fc/11/e9/d4a3ed5ce92fc6/CN113239610A.pdf"><span class="s5">CN113239610A </span></a></span><span class="s101">王晓东</span><span class="s93"> </span><span class="s101">昆明理工大学</span></p>
<p class="p68"><span class="s18">Priority 2021-01-19 • Filed 2021-01-19 • Published 2021-08-10</span></p>
<p class="p68"><span class="s18">3. The implementation principle of the <b>Wasserstein</b> distance-based domain-adaptive rolling bearing fault diagnosis method according to claim 2 is characterized in that: StepA, extracting features through convolutional neural network, convolutional layer containing a filter w and an offset b, let X n …</span></p>
<p class="p68"><span class="s2"><br>
</span></p>
<p class="p68"><span class="s2">2021 88</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN113962612A/en?q=wasserstein&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wasserstein">… robust optimization scheduling method based on improved <span class="s5"><b>Wasserstein</b> measure</span></a></span></p>
<p class="p10"><span class="s93">CN <a href="https://patentimages.storage.googleapis.com/78/87/18/f7af8ae8fdf64f/CN113962612A.pdf"><span class="s5">CN113962612A </span></a></span><span class="s101">刘鸿鹏</span><span class="s93"> </span><span class="s101">东北电力大学</span></p>
<p class="p68"><span class="s18">Priority 2021-11-25 • Filed 2021-11-25 • Published 2022-01-21</span></p>
<p class="p68"><span class="s18">2. The electric-heat combined system distribution robust optimization scheduling method based on improved <b>Wasserstein</b> measure of claim 1, characterized in that power error data set is predicted according to historical wind power Building an empirical distribution Where N is the total number of …</span></p>
<p class="p68"><span class="s2"><br>
</span></p>
<p class="p68"><span class="s2">2021 89</span></p>
<p class="p10"><span class="s18">Power system bad data identification method based on improved <b>Wasserstein</b> GA</span></p>
<p class="p10"><span class="s93">CN <a href="https://patentimages.storage.googleapis.com/90/3e/64/b538d39c33536a/CN114330486A.pdf"><span class="s5">CN114330486A </span></a></span><span class="s101">臧海祥</span><span class="s93"> </span><span class="s101">河海大学</span></p>
<p class="p68"><span class="s18">Priority 2021-11-18 • Filed 2021-11-18 • Published 2022-04-12</span></p>
<p class="p68"><span class="s18">5. The improved <b>Wasserstein</b> GAN-based power system bad data identification method as claimed in claim 1, wherein the training process of the C4.5 decision tree model in the step (5) comprises: firstly, a calculation formula for determining the sample information entropy in the C4.5 decision tree …</span></p>
<p class="p68"><span class="s2"><br>
</span></p>
<p class="p68"><span class="s2">2021 90</span></p>
<p class="p10"><span class="s18">Robot motion planning method and system based on graph <b>Wasserstein</b> self-coding …</span></p>
<p class="p68"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/ca/a1/a2/760189c625970c/CN113276119A.pdf"><span class="s13">CN113276119A </span></a></span><span class="s19">夏崇坤</span><span class="s18"> </span><span class="s19">清华大学深圳国际研究生院</span></p>
<p class="p68"><span class="s18">Priority 2021-05-25 • Filed 2021-05-25 • Published 2021-08-20</span></p>
<p class="p68"><span class="s18">8. The method for robot motion planning based on <b>Wasserstein</b> self-encoded network as claimed in claim 1, wherein step S2 comprises the following steps: s2-1, initializing encoder network parameter Q ψ And decoder network parameters Initializing a potential discriminator D τ (ii) a …</span></p>
<p class="p68"><span class="s2"><br>
</span></p>
<p class="p68"><span class="s2">2021 91</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN113536116A/en?q=wasserstein&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wasserstein">Cross-domain recommendation method based on double-current sliced <span class="s5"><b>wasserstein</b> …</span></a></span></p>
<p class="p10"><span class="s93">CN <a href="https://patentimages.storage.googleapis.com/9a/42/3a/0de0d672276739/CN113536116A.pdf"><span class="s5">CN113536116A </span></a></span><span class="s101">聂婕</span><span class="s93"> </span><span class="s101">中国海洋大学</span></p>
<p class="p68"><span class="s18">Priority 2021-06-29 • Filed 2021-06-29 • Published 2021-10-22</span></p>
<p class="p68"><span class="s18">The invention belongs to the technical field of cross-domain recommendation, and discloses a cross-domain recommendation method based on a double-current slotted <b>Wasserstein</b> self-encoder.</span><span class="s135"><br>
</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2021 92</span></p>
<p class="p10"><span class="s23"><a href="https://patents.google.com/patent/CN114417852A/en?q=wasserstein&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wasserstein&amp;page=1">Topic modeling method based on <span class="s13"><b>Wasserstein</b> self-encoder and Gaussian mixture …</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/cb/5e/f5/5f65c53c096ca2/CN114417852A.pdf"><span class="s5">CN114417852A </span></a></span><span class="s19">刘洪涛</span><span class="s18"> </span><span class="s19">重庆邮电大学</span></p>
<p class="p14"><span class="s18">Priority 2021-12-06 • Filed 2021-12-06 • Published 2022-04-29</span></p>
<p class="p14"><span class="s18">5. The method for modeling a subject based on a <b>Wasserstein</b> self-encoder and a gaussian mixture distribution as a priori as claimed in any one of claims 1 to 4, wherein the step S4 specifically comprises: s41: decoding the theme distribution theta obtained in the step S2 to obtain Representing the …</span></p>
<p class="p42"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s2">2021 93</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN114243683A/en?q=wasserstein&amp;before=priority:20211231&amp;after=priority:20210101&amp;oq=2021+wasserstein&amp;page=1">Distribution robust optimization method based on <span class="s5"><b>Wasserstein</b> measurement and …</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/11/a7/82/931fdedeb61030/CN114243683A.pdf"><span class="s5">CN114243683A </span></a></span><span class="s19">侯文庭</span><span class="s18"> </span><span class="s19">周口师范学院</span></p>
<p class="p14"><span class="s18">Priority 2021-11-23 • Filed 2021-11-23 • Published 2022-03-25</span></p>
<p class="p14"><span class="s18">6. The distributed robust optimization method based on <b>Wasserstein</b> measurement and kernel density estimation as claimed in claim 5, wherein the objective function of the distributed robust block combination model in step S4 is: in the formula: SU i </span><span class="s19">、</span><span class="s18">SD i Respectively starting and stopping expenses of …</span></p>
<p class="p42"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s2">2021 94 <span class="Apple-converted-space">  </span>see 2020</span></p>
<p class="p115"><span class="s56"><a href="https://patentimages.storage.googleapis.com/9b/ec/f1/14ebef61d30654/US11176477.pdf"><b>[PDF]</b><span class="s143"> googleapis.com</span></a></span></p>
<p class="p116"><span class="s1"><a href="https://patents.google.com/patent/US11176477B2/en">System and method for unsupervised domain adaptation via sliced-<span class="s144"><b>wasserstein </b>distance</span></a></span></p>
<p class="p14"><span class="s56"><a href="https://scholar.google.com/citations?user=V1Z-DdgAAAAJ&amp;hl=en&amp;oi=sra">AJ Gabourie</a></span><span class="s2">, <a href="https://scholar.google.com/citations?user=Uzx8nLoAAAAJ&amp;hl=en&amp;oi=sra"><span class="s26">M Rostami</span></a>, <a href="https://scholar.google.com/citations?user=yREBSy0AAAAJ&amp;hl=en&amp;oi=sra"><span class="s26">S Kolouri</span></a>, <a href="https://scholar.google.com/citations?user=P2oSOR0AAAAJ&amp;hl=en&amp;oi=sra"><span class="s26">K Kim</span></a> - US <b>Patent </b>11,176,477, 2021 - Google <b>Patents</b></span></p>
<p class="p14"><span class="s2">US11176477B2 - System and method for unsupervised domain adaptation via sliced-<b>wasserstein</b><span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s2">distance - Google <b>Patents</b> US11176477B2 - System and method for unsupervised …</span></p>
<p class="p117"><span class="s15"><span class="Apple-converted-space"> </span><a href="https://scholar.google.com/scholar?cites=8591580159841697112&amp;as_sdt=5,39&amp;sciodt=7,39&amp;hl=en"><span class="s145">Cited by 3</span></a> <a href="https://scholar.google.com/scholar?q=related:WH2onqJsO3cJ:scholar.google.com/&amp;scioq=wasserstein+patent&amp;hl=en&amp;as_sdt=7,39&amp;as_ylo=2021&amp;as_yhi=2021"><span class="s145">Related articles</span></a> <a href="https://scholar.google.com/scholar?cluster=8591580159841697112&amp;hl=en&amp;as_sdt=7,39&amp;as_ylo=2021&amp;as_yhi=2021"><span class="s145">All 4 versions</span></a></span></p>
<p class="p16"><span class="s20"><br>
2021 95<span class="Apple-converted-space">  </span>2021-2022<br>
<a href="https://patents.google.com/patent/CN113554645B/en"><span class="s21">Industrial anomaly detection method and device based on <b>WGAN</b></span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/01/1e/90/f1a33dd1d25ec4/CN113554645B.pdf"><span class="s146">CN113554645B </span></a></span><span class="s19">杭天欣</span><span class="s18"> </span><span class="s19">常州微亿智造科技有限公司</span></p>
<p class="p14"><span class="s18">Priority 2021-09-17 • Filed 2021-09-17 • Granted 2022-01-11 • Published 2022-01-11</span></p>
<p class="p14"><span class="s18">performing anomaly detection on the screened image to be detected by adopting the <b>WGAN</b> anomaly detection model, specifically, performing data preprocessing on the screened image to be detected to obtain a secondary image to be detected, inputting the secondary image to be detected into the <b>WGAN</b> …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p15"><span class="s2"><b>2021 96</b></span></p>
<p class="p92"><span class="s1"><a href="https://berkeley.primo.exlibrisgroup.com/discovery/fulldisplay?docid=cdi_epo_espacenet_CN113792785A&amp;context=PC&amp;vid=01UCS_BER:UCB&amp;lang=en&amp;search_scope=DN_and_CI&amp;adaptor=Primo%20Central&amp;tab=Default_UCLibrarySearch&amp;query=title%2Ccontains%2Cwgans%2CAND&amp;sortby=date_d&amp;mode=advanced&amp;offset=80"><b>Ship body attachment rapid identification method based on WGAN-GP and YOLO</b><span class="s3"><b></b></span></a></span></p>
<p class="p15"><span class="s2">ZHU DAQI ; CHU ZHENZHONG ; CHEN QI ; REN CHENHUI2021</span></p>
<p class="p15"><span class="s2"><b>OPEN ACCESS</b></span></p>
<p class="p15"><span class="s2">Ship body attachment rapid identification method based on WGAN-GP and YOLO</span></p>
<p class="p15"><span class="s2">No Online Access </span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p15"><span class="s2"><b>2021 97</b></span></p>
<p class="p92"><span class="s1"><a href="https://berkeley.primo.exlibrisgroup.com/discovery/fulldisplay?docid=cdi_epo_espacenet_CN113627594A&amp;context=PC&amp;vid=01UCS_BER:UCB&amp;lang=en&amp;search_scope=DN_and_CI&amp;adaptor=Primo%20Central&amp;tab=Default_UCLibrarySearch&amp;query=title%2Ccontains%2Cwgans%2CAND&amp;sortby=date_d&amp;mode=advanced&amp;offset=90"><b>WGAN-based one-dimensional time series data augmentation method</b><span class="s3"><b></b></span></a></span></p>
<p class="p15"><span class="s2">FENG QIANG ; WU ZEYU ; YANG DEZHEN ; REN YI ; SUN BO ; WANG ZILI ; QIAN CHENG2021</span></p>
<p class="p15"><span class="s2"><b>OPEN ACCESS</b></span></p>
<p class="p15"><span class="s2">WGAN-based one-dimensional time series data augmentation method</span></p>
<p class="p15"><span class="s2">No Online Access </span></p>
<p class="p69"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p15"><span class="s2"><b>2021 98</b></span></p>
<p class="p92"><span class="s1"><a href="https://berkeley.primo.exlibrisgroup.com/discovery/fulldisplay?docid=cdi_epo_espacenet_CN113536697A&amp;context=PC&amp;vid=01UCS_BER:UCB&amp;lang=en&amp;search_scope=DN_and_CI&amp;adaptor=Primo%20Central&amp;tab=Default_UCLibrarySearch&amp;query=title%2Ccontains%2Cwgans%2CAND&amp;sortby=date_d&amp;mode=advanced&amp;offset=90"><b>Bearing residual life prediction method based on improved residual network and WGAN</b><span class="s3"><b></b></span></a></span></p>
<p class="p15"><span class="s2">SHEN YANXIA ; XU JIAJIE ; ZHAO ZHIPU2021</span></p>
<p class="p15"><span class="s2"><b>OPEN ACCESS</b></span></p>
<p class="p15"><span class="s2">Bearing residual life prediction method based on improved residual network and WGAN</span></p>
<p class="p15"><span class="s2">No Online Access </span></p>
<p class="p69"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p15"><span class="s2"><b>2021 99</b></span></p>
<p class="p15"><span class="s56"><a href="https://berkeley.primo.exlibrisgroup.com/discovery/fulldisplay?docid=cdi_epo_espacenet_CN113505477A&amp;context=PC&amp;vid=01UCS_BER:UCB&amp;lang=en&amp;search_scope=DN_and_CI&amp;adaptor=Primo%20Central&amp;tab=Default_UCLibrarySearch&amp;query=title%2Ccontains%2Cwgans%2CAND&amp;sortby=date_d&amp;mode=advanced&amp;offset=90"><b>≈∂ç</b></a></span><span class="s2">TIAN RAN ; GAO SHIWEI ; QIU SULONG ; ZHANG QINGSONG ; MA ZHONGYU ; LIU YANXING ; XU JINPENG2021</span></p>
<p class="p15"><span class="s2"><b>OPEN ACCESS</b></span></p>
<p class="p15"><span class="s2">Process industrial soft measurement data supplement method based on SVAE-WGAN</span></p>
<p class="p15"><span class="s2">No Online Access </span></p>
<p class="p69"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p69"><span class="s2"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p15"><span class="s2"><b>2021 100</b></span></p>
<p class="p92"><span class="s1"><a href="https://berkeley.primo.exlibrisgroup.com/discovery/fulldisplay?docid=cdi_epo_espacenet_CN113298297A&amp;context=PC&amp;vid=01UCS_BER:UCB&amp;lang=en&amp;search_scope=DN_and_CI&amp;adaptor=Primo%20Central&amp;tab=Default_UCLibrarySearch&amp;query=title%2Ccontains%2Cwgans%2CAND&amp;sortby=date_d&amp;mode=advanced&amp;offset=100"><b>Wind power output power prediction method based on isolated forest and WGAN network</b><span class="s3"><b></b></span></a></span></p>
<p class="p15"><span class="s2">XU ZHIWEI ; LIU GUANGWEN ; WANG YONGSHENG ; XU HAO ; WU YUHAO ; SU XIAOMING2021</span></p>
<p class="p15"><span class="s2"><b>OPEN ACCESS</b></span></p>
<p class="p15"><span class="s2">Wind power output power prediction method based on isolated forest and WGAN network</span></p>
<p class="p15"><span class="s2">No Online Access </span></p>
<p class="p14"><span class="s27"><a href="https://berkeley.primo.exlibrisgroup.com/discovery/fulldisplay?docid=cdi_igi_journals_rless_Information_Hiding_10_4018_IJDCF_20210701_oa513&amp;context=PC&amp;vid=01UCS_BER:UCB&amp;lang=en&amp;search_scope=DN_and_CI&amp;adaptor=Primo%20Central&amp;tab=Default_UCLibrarySearch&amp;query=title%2Ccontains%2Cwgans%2CAND&amp;sortby=date_d&amp;mode=advanced&amp;offset=100"><span class="Apple-converted-space"> </span></a></span><span class="s2"><br>
</span></p>
<p class="p15"><span class="s2"><b>2021 101</b></span></p>
<p class="p92"><span class="s1"><a href="https://berkeley.primo.exlibrisgroup.com/discovery/fulldisplay?docid=cdi_gale_infotracmisc_A677572843&amp;context=PC&amp;vid=01UCS_BER:UCB&amp;lang=en&amp;search_scope=DN_and_CI&amp;adaptor=Primo%20Central&amp;tab=Default_UCLibrarySearch&amp;query=title%2Ccontains%2Cwgans%2CAND&amp;sortby=date_d&amp;mode=advanced&amp;offset=100"><b>Combining the WGAN and ResNeXt Networks to Achieve Data Augmentation and Classification of the FT-IR Spectra of Strawberries</b><span class="s3"><b></b></span></a></span></p>
<p class="p15"><span class="s2">Zhao, Yinan ; Tian, Shengwei ; Yu, Long ; Xing, YanSpectroscopy (Springfield, Or.), 2021, Vol.36 (4), p.28</span></p>
<p class="p15"><span class="s2">Combining the WGAN and ResNeXt Networks to Achieve Data Augmentation and Classification of the FT-IR Spectra of Strawberries</span></p>
<p class="p118"><span class="s2">Available Online</span><span class="s15"> </span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p119"><span class="s2">2021 102. patent</span></p>
<p class="p120"><span class="s17"><a href="https://patents.google.com/patent/CN115544864A/en?q=TI%3d(wgan)&amp;oq=TI%3d(wgan)&amp;sort=new">sEMG data enhancement method based on BiLSTM and <span class="s147"><b>WGAN</b>-GP networks</span></a></span></p>
<p class="p121"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/cd/3d/29/51a3b888e43977/CN114372490A.pdf"><span class="s148">CN114372490A </span></a></span><span class="s19">方银锋</span><span class="s18"> </span><span class="s19">杭州电子科技大学</span></p>
<p class="p122"><span class="s18">Priority 2021-12-29 • Filed 2021-12-29 • Published 2022-04-19</span></p>
<p class="p119"><span class="s18">A sEMG data enhancement method based on a BilSTM and <b>WGAN</b>-GP network comprises the following specific steps: s1, collecting surface electromyogram signals and preprocessing the signals; step<span class="Apple-converted-space"> </span></span></p>
<p class="p123"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p124"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p125"><span class="s2">2021 103. patent</span></p>
<p class="p126"><span class="s17"><a href="https://patents.google.com/?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new#">… robust optimization scheduling method based on improved <span class="s149"><b>Wasserstein</b> measure</span></a></span></p>
<p class="p127"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/78/87/18/f7af8ae8fdf64f/CN113962612A.pdf"><span class="s150">CN113962612A </span></a></span><span class="s151">刘鸿鹏</span><span class="s18"> </span><span class="s151">东北电力大学</span></p>
<p class="p128"><span class="s18">Priority 2021-11-25 • Filed 2021-11-25 • Published 2022-01-21</span></p>
<p class="p125"><span class="s18">An electric heating combined system distribution robust optimization scheduling method based on improved <b>Wasserstein</b> measure relates to the technical field of renewable energy scheduling in an electric heating combined system. The method aims to solve the problem that an uncertainty set …</span></p>
<p class="p125"><span class="s2"><br>
</span></p>
<p class="p125"><span class="s2">2021 104</span></p>
<p class="p126"><span class="s17"><a href="https://patents.google.com/?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new#">… method for generating countermeasure network based on conditional <span class="s149"><b>Wasserstein</b></span></a></span></p>
<p class="p127"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/a7/15/06/6b9a64ca07c82d/CN114154405A.pdf"><span class="s150">CN114154405A </span></a></span><span class="s151">陈乾坤</span><span class="s18"> </span><span class="s151">东风汽车集团股份有限公司</span></p>
<p class="p128"><span class="s18">Priority 2021-11-19 • Filed 2021-11-19 • Published 2022-03-08</span></p>
<p class="p125"><span class="s18">3. The motor data enhancement method based on the conditional <b>Wasserstein</b> generation countermeasure network as claimed in claim 1, wherein the conditional <b>Wasserstein</b> generation countermeasure network is a combination of the conditional warerstein generation countermeasure network and the …</span><span class="s152"><br>
</span></p>
<p class="p125"><span class="s2">2021105.<span class="Apple-converted-space">  </span>patent <span class="Apple-converted-space"> </span></span></p>
<p class="p126"><span class="s17"><a href="https://patents.google.com/?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new#">Early fault detection method based on <span class="s149"><b>Wasserstein</b> distance</span></a></span></p>
<p class="p127"><span class="s18">\\\CN <a href="https://patentimages.storage.googleapis.com/b9/25/e0/c4583bd284d101/CN114722888A.pdf"><span class="s150">CN114722888A </span></a></span><span class="s151">曾九孙</span><span class="s18"> </span><span class="s151">中国计量大学</span></p>
<p class="p128"><span class="s18">Priority 2021-10-27 • Filed 2021-10-27 • Published 2022-07-08</span></p>
<p class="p125"><span class="s18">s3, analyzing data statistical characteristics of <b>Wasserstein</b> distance in the principal component space and the residual error space, and establishing monitoring statistics based on hypothesis test in the principal component space and the residual error space for judging whether a fault occurs or …</span></p>
<p class="p125"><span class="s2"><br>
</span></p>
<p class="p125"><span class="s2">2021 106</span></p>
<p class="p126"><span class="s17"><a href="https://patents.google.com/?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new#">… and apparatus for conditional data genration using conditional <span class="s149"><b>wasserstein</b> …</span></a></span></p>
<p class="p127"><span class="s18"><i>KR</i> <a href="https://patentimages.storage.googleapis.com/1e/2a/a6/b1db5050e9ae08/KR20230023464A.pdf"><span class="s150">KR20230023464A </span></a></span><span class="s153">조명희</span><span class="s18"> </span><span class="s153">서울대학교산학협력단</span></p>
<p class="p128"><span class="s18">Priority 2021-08-10 • Filed 2021-08-10 • Published 2023-02-17</span></p>
<p class="p125"><span class="s18">Wherein the learned conditional <b>Wasserstein</b> generator outputs a future video frame as a response when the past video frame is input as condition data. According to claim 7, The learned conditional <b>Wasserstein</b> generator is learned by setting a past video frame and a future video frame as condition …</span></p>
<p class="p125"><span class="s2"><br>
</span></p>
<p class="p125"><span class="s2">2021 107</span></p>
<p class="p126"><span class="s17"><a href="https://patents.google.com/?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new#">Characteristic similarity countermeasure network based on <span class="s149"><b>Wasserstein</b> distance</span></a></span></p>
<p class="p127"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/94/0b/7d/f7cd92d1afc176/CN113673347A.pdf"><span class="s150">CN113673347A </span></a></span><span class="s151">祝磊</span><span class="s18"> </span><span class="s151">杭州电子科技大学</span></p>
<p class="p128"><span class="s18">Priority 2021-07-20 • Filed 2021-07-20 • Published 2021-11-19</span></p>
<p class="p125"><span class="s18">6. The <b>Wasserstein</b> distance-based characterized similar countermeasure network of claim 1, wherein in S5: obtaining the round-trip probability of the destination domain of the source domain comprises multiplying the resulting P st </span><span class="s151">、</span><span class="s18">P ts The formula is as follows: P sts </span><span class="s151">＝</span><span class="s18">P st P ts </span><span class="s151">；</span><span class="s18"> in the formula, P sts …</span></p>
<p class="p125"><span class="s2"><br>
</span></p>
<p class="p125"><span class="s2">2021 108</span></p>
<p class="p126"><span class="s17"><a href="https://patents.google.com/?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new#">Cross-domain recommendation method based on double-current sliced <span class="s149"><b>wasserstein</b> …</span></a></span></p>
<p class="p127"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/9a/42/3a/0de0d672276739/CN113536116A.pdf"><span class="s150">CN113536116A </span></a></span><span class="s151">聂婕</span><span class="s18"> </span><span class="s151">中国海洋大学</span></p>
<p class="p128"><span class="s18">Priority 2021-06-29 • Filed 2021-06-29 • Published 2021-10-22</span></p>
<p class="p125"><span class="s18">The invention belongs to the technical field of cross-domain recommendation, and discloses a cross-domain recommendation method based on a double-current slotted <b>Wasserstein</b> self-encoder.</span></p>
<p class="p125"><span class="s2"><br>
</span></p>
<p class="p125"><span class="s2">2021 109</span></p>
<p class="p126"><span class="s17"><a href="https://patents.google.com/?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new#">Robot motion planning method and system based on graph <span class="s149"><b>Wasserstein</b> self-coding …</span></a></span></p>
<p class="p127"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/ae/c3/ac/de39a8727a4492/CN113276119B.pdf"><span class="s150">CN113276119B </span></a></span><span class="s151">夏崇坤</span><span class="s18"> </span><span class="s151">清华大学深圳国际研究生院</span></p>
<p class="p128"><span class="s18">Priority 2021-05-25 • Filed 2021-05-25 • Granted 2022-06-28 • Published 2022-06-28</span></p>
<p class="p125"><span class="s18">1. A robot motion planning method based on a graph <b>Wasserstein</b> self-coding network is characterized by comprising the following steps: s1, constructing a graph <b>Wasserstein</b> self-coding network GraphWAE; the GraphWAE represents the non-obstacle area of the configuration space in a pre-training mode …</span></p>
<p class="p125"><span class="s2"><br>
</span></p>
<p class="p125"><span class="s2"><br>
2021 110</span></p>
<p class="p129"><span class="s23"><a href="https://patents.google.com/?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new#"><b>Wasserstein</b><span class="s149"> distance-based motor imagery electroencephalogram migration …</span></a></span></p>
<p class="p127"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/af/cc/3a/448dd6163a590b/CN113010013A.pdf"><span class="s150">CN113010013A </span></a></span><span class="s151">罗浩远</span><span class="s18"> </span><span class="s151">华南理工大学</span></p>
<p class="p128"><span class="s18">Priority 2021-03-11 • Filed 2021-03-11 • Published 2021-06-22</span></p>
<p class="p125"><span class="s18">7. The <b>Wasserstein</b> distance-based motor imagery electroencephalogram migration learning method according to claim 1, wherein: in step 5), calculating the classification accuracy and kappa coefficient of the deep migration learning model to the target domain data, specifically as follows: …</span></p>
<p class="p125"><span class="s2"><br>
2021 111</span></p>
<p class="p126"><span class="s17"><a href="https://patents.google.com/?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new#">Domain self-adaptive rolling bearing fault diagnosis method based on <span class="s149"><b>Wasserstein</b> …</span></a></span></p>
<p class="p127"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/fc/11/e9/d4a3ed5ce92fc6/CN113239610A.pdf"><span class="s150">CN113239610A </span></a></span><span class="s151">王晓东</span><span class="s18"> </span><span class="s151">昆明理工大学</span></p>
<p class="p128"><span class="s18">Priority 2021-01-19 • Filed 2021-01-19 • Published 2021-08-10</span></p>
<p class="p125"><span class="s18">3. The implementation principle of the <b>Wasserstein</b> distance-based domain-adaptive rolling bearing fault diagnosis method according to claim 2 is characterized in that: StepA, extracting features through convolutional neural network, convolutional layer containing a filter w and an offset b, let X n …</span></p>
<p class="p125"><span class="s2"><br>
</span></p>
<p class="p130"><span class="s17"><b>2021 112</b></span></p>
<p class="p131"><span class="s17"><a href="https://patents.google.com/?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new#">System and Method for Generaring Highly Dense 3D Point Clouds using <span class="s154"><b>Wasserstein</b> …</span></a></span></p>
<p class="p121"><span class="s18">KR <a href="https://patentimages.storage.googleapis.com/3e/29/50/4f76c7a1f58f26/KR102456682B1.pdf"><span class="s155">KR102456682B1 </span></a></span><span class="s78">권준석</span><span class="s18"> </span><span class="s78">중앙대학교</span><span class="s18"> </span><span class="s78">산학협력단</span></p>
<p class="p122"><span class="s18">Priority 2020-12-18 • Filed 2020-12-18 • Granted 2022-10-19 • Published 2022-10-19</span></p>
<p class="p119"><span class="s18">The present invention generates a high-resolution 3D point cloud using a <b>Wasserstein</b> distribution to generate a set of several 3D points by generating several input vectors from a prior distribution and expressing it as a <b>Wasserstein</b> distribution A prior distribution input unit for inputting a …</span></p>
<p class="p119"><span class="s2"><br>
</span></p>
<p class="p119"><span class="s2">2021 113</span></p>
<p class="p132"><span class="s23"><a href="https://patents.google.com/?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new#"><b>Wasserstein</b><span class="s154">-based high-energy image synthesis method and device for generating …</span></a></span></p>
<p class="p121"><span class="s23"><a href="https://patentimages.storage.googleapis.com/78/56/b2/0fdbf4cef037ff/CN112634390A.pdf">CN112634390A </a></span><span class="s19">郑海荣</span><span class="s18"> </span><span class="s19">深圳先进技术研究院</span></p>
<p class="p122"><span class="s18">Priority 2020-12-17 • Filed 2020-12-17 • Published 2021-04-09</span></p>
<p class="p119"><span class="s18">updating the preset generation countermeasure network model based on the first loss value and the first judgment result until the preset generation countermeasure network model converges, and determining the converged preset generation countermeasure network model as the <b>Wasserstein</b> generation …</span></p>
<p class="p133"><span class="s2"><br>
</span></p>
<p class="p134"><span class="s2">101` 114</span></p>
<p class="p135"><span class="s17"><a href="https://patents.google.com/?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new#">High-energy image synthesis method and device based on <span class="s156"><b>wasserstein</b> generative …</span></a></span></p>
<p class="p136"><span class="s18"><i>WO</i> <a href="https://patentimages.storage.googleapis.com/ef/a1/e1/54cadadb290582/WO2022126480A1.pdf"><span class="s157">WO2022126480A1 </span></a></span><span class="s19">郑海荣</span><span class="s18"> </span><span class="s19">深圳先进技术研究院</span></p>
<p class="p137"><span class="s18">Priority 2020-12-17 • Filed 2020-12-17 • Published 2022-06-23</span></p>
<p class="p134"><span class="s18">The preset generative adversarial network model is updated based on the first loss value and the first discrimination result until the preset generative adversarial network model converges, and the converged preset generative adversarial network model is determined as the <b>Wasserstein</b> generative …</span></p>
<p class="p133"><span class="s2"><br>
</span></p>
<p class="p138"><span class="s158"><br>
<span class="Apple-converted-space"> </span></span><span class="s2">2021 115. patent <span class="Apple-converted-space"> </span></span></p>
<p class="p139"><span class="s23"><a href="https://patents.google.com/?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new#"><b>Wasserstein</b><span class="s159"> distance-based object envelope multi-view reconstruction a</span></a></span></p>
<p class="p140"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/11/88/42/e230dd84526cfa/CN113034695A.pdf"><span class="s160">CN113034695A </span></a></span><span class="s151">何力</span><span class="s18"> </span><span class="s151">广东工业大学</span></p>
<p class="p141"><span class="s18">Priority 2021-04-16 • Filed 2021-04-16 • Published 2021-06-25</span></p>
<p class="p138"><span class="s18">7. The <b>Wasserstein</b> distance-based object envelope multi-view reconstruction and optimization method according to claim 5, wherein the specific process of step S4-3 is as follows: embedding the <b>Wasserstein</b>-based distance cost function into three-dimensional reconstruction, including: in equation (3) …</span></p>
<p class="p119"><span class="s2"><br>
</span></p>
<p class="p10"><span class="s2">&lt;—197<span class="Apple-converted-space">  </span>till 2020<span class="Apple-converted-space"> </span></span></p>
<p class="p10"><span class="s2"><span class="Apple-converted-space"> </span>+ 115<span class="Apple-converted-space">  </span>jn 2021<span class="Apple-converted-space">   </span></span></p>
<p class="p10"><span class="s2"><span class="Apple-converted-space"> </span>= 312<span class="Apple-converted-space">  </span>till </span><span class="s20">2021<span class="Apple-converted-space"> </span></span></p>
<p class="p68"><span class="s2">end 2021 e21</span></p>
<p class="p68"><span class="s2">start 2022</span></p>
<p class="p142"><span class="s2"><br>
</span></p>
<p class="p142"><span class="s2">Bbb<span class="Apple-converted-space"> </span></span></p>
<p class="p18"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p10"><span class="s2"><br>
</span></p>
<p class="p143"><span class="s2">start 2022</span></p>
<p class="p143"><span class="s2">48 patents</span></p>
<p class="p68"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s18">2022 1<span class="Apple-converted-space">   </span></span></p>
<p class="p6"><span class="s126"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:202200125T">WGAN<span class="s161"> based clothing attribute editing method, involves collecting different styles of garment construction data set in training stage, and inputting training data input with attribute label to generate countermeasure network to train</span></a></span></p>
<p class="p5"><span class="s18">CN113793397-A</span></p>
<p class="p105"><span class="s30"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22WANG%20Z%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s128">WANG Z</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22WANG%20W%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">WANG W</span></a> and <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22ZHANG%20J%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">ZHANG J</span></a></span></p>
<p class="p5"><span class="s30"><b>Assignee(s) </b></span><span class="s18">UNIV YUYAO ZHEJIANG ROBOTICS RES CENT and UNIV ZHEJIANG</span></p>
<p class="p14"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p104"><span class="s2">2022-00125T</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s18">2022 2<span class="Apple-converted-space">   </span></span></p>
<p class="p6"><span class="s126"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:202200216M">WGAN<span class="s161">-GP and YOLO based quick hull attachment identification method, involves performing density evaluation to hull attachment in identification process, and calculating attachment area ratio</span></a></span></p>
<p class="p5"><span class="s18">CN113792785-A</span></p>
<p class="p77"><span class="s129"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22CHU%20Z%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s121">CHU Z</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22REN%20C%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">REN C</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22CHEN%20Q%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">CHEN Q</span></a></span></p>
<p class="p5"><span class="s30"><b>Assignee(s) </b></span><span class="s18">UNIV SHANGHAI SCI &amp; TECHNOLOGY</span></p>
<p class="p14"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p104"><span class="s2">2022-00216M</span></p>
<p class="p5"><span class="s2"><br>
2022.3</span></p>
<p class="p144"><span class="s1"><a href="https://www.proquest.com/docview/2638207810/68626F8BF8B34328PQ/1?accountid=13158">nst Inf Eng, CAS Files Chinese Patent Application for Network Attack Traffic Data Enhancement Method and System<span class="s61"></span></a></span></p>
<p class="p145"><span class="s17"><a href="https://www.proquest.com/docview/2638207810/68626F8BF8B34328PQ/1?accountid=13158">CombiniAuto-Encoder and <span class="s162">WGAN</span></a></span></p>
<p class="p146"><span class="s18"><b>Global IP News. Broadband and Wireless Network News; New Delhi</b> [New Delhi]. 12 Mar 2022. </span></p>
<p class="p147"><span class="s7"><a href="https://www.proquest.com/docview/2638207810/citation/68626F8BF8B34328PQ/1?accountid=13158">Details</a><a href="https://www.proquest.com/docview/2638207810/fulltext/68626F8BF8B34328PQ/1?accountid=13158"><span class="s94">Full text</span></a></span></p>
<p class="p44"><span class="s18"><span class="Apple-converted-space"> </span></span><span class="s2"><span class="Apple-converted-space"> </span></span><span class="s18"> <span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s18">2022.4</span></p>
<p class="p107"><span class="s27"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:202235384T">Road texture image enhancement method coupling traditional method and <span class="s127">WGAN</span><span class="s128">-GP involves pre-processing original image, and converting three-dimensional macroscopic texture data into two-dimensional image</span></a></span></p>
<p class="p5"><span class="s18">CN113850855-A</span></p>
<p class="p77"><span class="s129">Inventor(s) <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22HOU%20Y%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s121">HOU Y</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22WANG%20Y%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">WANG Y</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22XU%20Z%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">XU Z</span></a></span></p>
<p class="p5"><span class="s30">Assignee(s) </span><span class="s18">UNIV BEIJING TECHNOLOGY</span></p>
<p class="p148"><span class="s18">Derwent Primary Accession Number </span></p>
<p class="p5"><span class="s18">2022-35384T</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s18">2022 .5</span></p>
<p class="p149"><span class="s17"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:202211243X">Method for sorting blood leukocyte based on attention residual network, involves introducing depth separable convolution to extract characteristic of white blood cell, and using <span class="s122">Wasserstein</span><span class="s123"> to generate anti-network creating synthesis</span></a></span></p>
<p class="p5"><span class="s18">CN113887672-A</span></p>
<p class="p77"><span class="s129">Inventor(s) <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22CAO%20X%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s121">CAO X</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22ZHAO%20M%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">ZHAO M</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22LI%20Z%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">LI Z</span></a></span></p>
<p class="p5"><span class="s30">Assignee(s) </span><span class="s18">UNIV MINJIANG</span></p>
<p class="p148"><span class="s18">Derwent Primary Accession Number </span></p>
<p class="p5"><span class="s18">2022-11243X</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space"> </span>2022.6</span></p>
<p class="p149"><span class="s17"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:2022170709">Method for simulating artificial seismic wave based on generative confrontation network algorithm, involves verifying judgment result, and judging network training effect of artificial seismic data by using loss function defined by <span class="s122">Wasserstein</span><span class="s123"> norm</span></a></span></p>
<p class="p5"><span class="s18">CN113935240-A</span></p>
<p class="p105"><span class="s30">Inventor(s) <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22YANG%20C%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s119">YANG C</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22XIANG%20T%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">XIANG T</span></a> and <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22YANG%20M%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">YANG M</span></a></span></p>
<p class="p14"><span class="s18">Assignee(s) </span><span class="s120">UNIV XIHUA</span></p>
<p class="p148"><span class="s18">Derwent Primary Accession Number </span></p>
<p class="p14"><span class="s12"><br>
</span><span class="s2">2022.7<span class="Apple-converted-space">  </span>see 2021</span></p>
<p class="p92"><span class="s1"><a href="https://duke.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwvV1LT8JAEN4oXDyJUeMLMgejJ6Bp6YMEJaCgF5GAiUey3Ufioy22aOJf8Zf5c9zZsqKY6M3bpk0n2e32m-nsN_MR4tg1q7qECY5CvSbjLBSNQPAw9D23wXzuhg61LUnlUo1YYkpj5q_boKSGbp4wzJrXlStXsY7dbPjt6VMVdaTwvNWIahgLugqAPSro0LwA88upLmVRO81SdmI3vVVStLGKuECK3d5gOPoBzNrb9NfJmzGrqda1nGqSJx2-cbBNM8d_nEOJlBAXp3QqUujk226DrIh4k7zrwBW-FqbAEHP96ewVrrFVhYBEglbsBhWuCux4C8gMga64u1c-VD0rQaENHAGm_I8zGCqL8Qw6i2N2UFE2XGndaz3M-2YjeRtyXU3cdTCiEY1hjGWk6XME53RGoascNgdloRXR9OH09qIzaNX18NPIiwCtUJ1R_C5hkHPkt8hhv3dzdlk1izvBBs9S-f1sslhaZ5sU4iQWOwRkwD2J8uqU8YYUvoqGfGoJ5gYWd93Q2yXlX03t_XF_n6zZWB-BhD__gBTUHEU515mokNWg36vMd1gFSabjD5SRA4w">State Intellectual Property Office of China Receives Univ Beijing Inf Sci &amp; Tech's Patent Application for Method for Generating Biological Raman Spectrum Data Based on WGAN...<span class="s3"></span></a></span></p>
<p class="p15"><span class="s2">Global IP News. Biotechnology Patent News, Mar 17, 2022</span></p>
<p class="p15"><span class="s2">Newspaper Article<span class="Apple-converted-space"> </span></span></p>
<p class="p15"><span class="s2"><span class="Apple-converted-space"> </span>Full Text Online</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2022 8</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN114662712A/en?q=wasserstein&amp;before=priority:20221231&amp;after=priority:20220101&amp;oq=2022+wasserstein">Rotating machine state monitoring method based on <span class="s16"><b>Wasserstein</b> depth digital </span></a></span><span class="s15">twin model</span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/e1/71/7b/e3eb77685910c6/CN114662712A.pdf"><span class="s16">CN114662712A</span></a> </span><span class="s19">胡文扬</span><span class="s18"> </span><span class="s19">清华大学</span></p>
<p class="p14"><span class="s18">Filed 2022-02-22 • Published 2022-06-24</span></p>
<p class="p14"><span class="s18">and if the similarity of the twin sample and the physical health sample reaches a set standard, obtaining the trained WGAN-GP network based on the <b>Wasserstein</b> deep digital twin model through consistency test. 3. The method for monitoring the condition of a rotating machine based on the <b>Wasserstein</b> …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2"><span class="Apple-converted-space"> </span>2022 9</span></p>
<p class="p9"><span class="s27"><a href="https://patents.google.com/patent/CN114839552A/en?q=wasserstein&amp;before=priority:20221231&amp;after=priority:20220101&amp;oq=2022+wasserstein"><b>Wasserstein</b><span class="s35"> distance-based battery SOH estimation method and device</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/c9/d5/c4/4032d6fa28ea41/CN114839552A.pdf"><span class="s16">CN114839552A </span></a></span><span class="s19">林名强</span><span class="s18"> </span><span class="s19">泉州装备制造研究所</span></p>
<p class="p14"><span class="s18">Priority 2022-04-08 • Filed 2022-04-08 • Published 2022-08-02</span></p>
<p class="p14"><span class="s18">3. The <b>wasserstein</b> distance-based battery SOH estimation method according to claim 1, wherein: in S1, the aging data of the pouch batteries is specifically aging data of eight nominal 740Ma · h pouch batteries recorded in advance. 4. A <b>wasserstein</b> distance-based battery SOH estimation method …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2"><span class="Apple-converted-space"> </span>2022 10</span></p>
<p class="p10"><span class="s18">Application of evidence <b>Wasserstein</b> distance algorithm in component …</span></p>
<p class="p9"><span class="s30">CN <a href="https://patentimages.storage.googleapis.com/84/f6/d9/5912d77c0a9990/CN114818957A.pdf"><span class="s35">CN114818957A </span></a></span><span class="s36">肖富元</span><span class="s30"> </span><span class="s36">肖富元</span></p>
<p class="p14"><span class="s18">Priority 2022-05-10 • Filed 2022-05-10 • Published 2022-07-29</span></p>
<p class="p15"><span class="s2">1. The application of the evidence <b>Wasserstein</b> distance algorithm in component identification is characterized in that: the <b>Wasserstein</b> distance is EWD, and the EWD is verified by the following method: 1): let m1 and m2 be the quality function of the multi-intersection element set Θ, where γ i, j …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2"><span class="Apple-converted-space"> </span>2022 11</span></p>
<p class="p150"><span class="s17"><a href="https://patents.google.com/patent/CN114936149A/en?q=wgan&amp;before=priority:20221231&amp;after=priority:20220101&amp;oq=2022+wgan">CAN bus fuzzy test case generation method based on <span class="s163"><b>WGAN</b>-GP and fuzzy test system</span></a></span></p>
<p class="p150"><span class="s17"><a href="https://patentimages.storage.googleapis.com/e0/09/cf/367b9277680cd7/CN114936149A.pdf">CN114936149A </a></span><span class="s164">黄柯霖</span><span class="s30"> </span><span class="s164">华中科技大学</span></p>
<p class="p151"><span class="s18">Filed 2022-04-27 • Published 2022-08-23</span></p>
<p class="p152"><span class="s2">the model generation module is used for building and training a <b>WGAN</b>-GP model based on a neural network through the training data set; the test case generation module is used for configuring a noise vector for the trained <b>WGAN</b>-GP model, so that the <b>WGAN</b>-GP model generates a plurality of virtual CAN …</span></p>
<p class="p151"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p15"><span class="s2">2022 12</span></p>
<p class="p153"><span class="s1"><a href="https://duke.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwvV1NT4NAEN3Y9uLJGjV-tZmDV1q6FCxJtWkbqhcbIiYem-0ChihQof0z_h3_mDMLpLEmevMGLJmE3eXNzs68fYwZvKNrO5hgLU30BBg8S5PbPjktoXNfmEveC_WB6O9wxNKKGlMOd4WSCrr9VNKueZfTFoiJ2GqNVu8a6UhRvrUS1agsKBaAfEPoUHUBVciJj_J4lOWZvOG2VWMNCnXwx25MnLn7-AOYlbeZHbCPyqwqte4UpSbFpsO3GuzqMMd__IYmaxIursQqyGBcTLtDthckR-xT5YBAKXKDo-R1IgkuybAB1X_ARKTkKQHBKo7WObi4zk3WMN7m0AGX0ID2wVGURJiiK5cYJwARE6OXTTFd4UHJXqO9PPAB74exyF5vn-_G82FXXYInEcPBi-JSnQxE4gPRXcAra8fBLc66pcbte8fsauY8Te-1qh8XdJZziC4-X2x70Thh9SRNglMGgehbfClCSRGsbwjbFLYV2pIyn9dBTz9jrV9Nnf_RfsH2OVEhdEvjxiWrr7NN0CokJdqsNpg57XIytame1PsCh8H7ww">North China Electric Power Univ Baoding Submits Patent Application for New Energy Capacity Configuration Method Based on WGAN...<span class="s165"></span></a></span></p>
<p class="p14"><span class="s18">Global IP News. Energy Patent News, Jun 23, 2022</span></p>
<p class="p154"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2022 13</span></p>
<p class="p155"><span class="s2">patent Wire Feed<span class="Apple-converted-space">  </span>Full Text</span></p>
<p class="p156"><span class="s7"><a href="https://www.proquest.com/docview/2684110589/D2946699BC554708PQ/6?accountid=13158">St<span class="s166">ate Intellectual Property Office of China Publishes Univ South China Tech's Patent Application for Motor Imagery Electroencephalogram Transfer Learning Method Based on Wasserstein Distance</span></a></span></p>
<p class="p155"><span class="s2">Global IP News. Electrical Patent News; New Delhi [New Delhi]. 04 July 2022. </span></p>
<p class="p157"><span class="s4"><span class="Apple-tab-span">	</span><span class="Apple-tab-span">	</span><a href="https://www.proquest.com/docview/2684110589/citation/D2946699BC554708PQ/6?accountid=13158"><span class="s167">Details</span></a><a href="https://www.proquest.com/docview/2684110589/fulltext/D2946699BC554708PQ/6?accountid=13158"><span class="s167">Full text</span></a></span></p>
<p class="p5"><span class="s2">2022 14</span></p>
<p class="p5"><span class="s2">Wire Feed<span class="Apple-converted-space">  </span>Full Text</span></p>
<p class="p6"><span class="s1"><a href="https://www.proquest.com/docview/2673519507/C227F09D0A6F4CB8PQ/6?accountid=13158">Univ Xidian Submits Chinese Patent Application for Radar HRRP Database Construction Method Based on WGAN-GP</a></span><span class="s12"><br>
Global IP News. Software Patent News; New Delhi [New Delhi]. 06 June 2022. </span></p>
<p class="p10"><span class="s7"><a href="https://www.proquest.com/docview/2673519507/citation/C227F09D0A6F4CB8PQ/6?accountid=13158">Details</a><a href="https://www.proquest.com/docview/2673519507/fulltext/C227F09D0A6F4CB8PQ/6?accountid=13158"><span class="s13">Full text</span></a></span></p>
<p class="p14"><span class="s12"><br>
</span><span class="s2">2022 15</span></p>
<p class="p6"><span class="s17"><a href="https://patents.google.com/patent/CN114936149A/en?q=wgan&amp;before=priority:20221231&amp;after=priority:20220101&amp;oq=2022+wgan">CAN bus fuzzy test case generation method based on <span class="s5"><b>WGAN</b>-GP and fuzzy test system</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/e0/09/cf/367b9277680cd7/CN114936149A.pdf"><span class="s5">CN114936149A </span></a></span><span class="s19">黄柯霖</span><span class="s18"> </span><span class="s19">华中科技大学</span></p>
<p class="p14"><span class="s18">Priority 2022-04-27 • Filed 2022-04-27 • Published 2022-08-23</span></p>
<p class="p14"><span class="s18">the model generation module is used for building and training a <b>WGAN</b>-GP model based on a neural network through the training data set; the test case generation module is used for configuring a noise vector for the trained <b>WGAN</b>-GP model, so that the <b>WGAN</b>-GP model generates a plurality of virtual CAN …</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p9"><span class="s20">2022 16<a href="https://www.proquest.com/docview/304888345/9BF954863EDF453EPQ/18?accountid=13158"><span class="s168"><br>
</span></a><a href="https://patents.google.com/patent/CN114662712A/en?q=wasserstein&amp;before=priority:20221231&amp;after=priority:20220101&amp;oq=2022+wasserstein"><span class="s169">Rotating machine state monitoring method based on <b>Wasserstein</b> depth digital …</span></a></span></p>
<p class="p16"><span class="s93">CN <a href="https://patentimages.storage.googleapis.com/e1/71/7b/e3eb77685910c6/CN114662712A.pdf"><span class="s22">CN114662712A </span></a></span><span class="s101">胡文扬</span><span class="s93"> </span><span class="s101">清华大学</span></p>
<p class="p14"><span class="s18">Priority 2022-02-22 • Filed 2022-02-22 • Published 2022-06-24</span></p>
<p class="p14"><span class="s18">The invention relates to the technical field of artificial intelligence, and discloses a method for monitoring the state of a rotating machine based on a <b>Wasserstein</b> depth digital twin model, which comprises the steps of acquiring operation and maintenance data of the rotating machine in a healthy …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2022 17</span></p>
<p class="p10"><span class="s23"><a href="https://patents.google.com/patent/CN114818957A/en?q=wasserstein&amp;before=priority:20221231&amp;after=priority:20220101&amp;oq=2022+wasserstein">Application of evidence <span class="s13"><b>Wasserstein</b> distance algorithm in component …</span></a></span></p>
<p class="p16"><span class="s93">CN <a href="https://patentimages.storage.googleapis.com/84/f6/d9/5912d77c0a9990/CN114818957A.pdf"><span class="s22">CN114818957A </span></a></span><span class="s101">肖富元</span><span class="s93"> </span><span class="s101">肖富元</span></p>
<p class="p14"><span class="s18">Priority 2022-05-10 • Filed 2022-05-10 • Published 2022-07-29</span></p>
<p class="p14"><span class="s18">1. The application of the evidence <b>Wasserstein</b> distance algorithm in component identification is characterized in that: the <b>Wasserstein</b> distance is EWD, and the EWD is verified by the following method: 1): let m1 and m2 be the quality function of the multi-intersection element set Θ, where γ i, j …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">022 18</span></p>
<p class="p10"><span class="s23"><a href="https://patents.google.com/patent/CN114839552A/en?q=wasserstein&amp;before=priority:20221231&amp;after=priority:20220101&amp;oq=2022+wasserstein"><b>Wasserstein</b><span class="s13"> distance-based battery SOH estimation method and device</span></a></span></p>
<p class="p14"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/c9/d5/c4/4032d6fa28ea41/CN114839552A.pdf"><span class="s5">CN114839552A </span></a></span><span class="s19">林名强</span><span class="s18"> </span><span class="s19">泉州装备制造研究所</span></p>
<p class="p14"><span class="s18">Priority 2022-04-08 • Filed 2022-04-08 • Published 2022-08-02</span></p>
<p class="p14"><span class="s18">3. The <b>wasserstein</b> distance-based battery SOH estimation method according to claim 1, wherein: in S1, the aging data of the pouch batteries is specifically aging data of eight nominal 740Ma · h pouch batteries recorded in advance. 4. A <b>wasserstein</b> distance-based battery SOH estimation method …</span></p>
<p class="p42"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s2">2022 19<span class="Apple-converted-space">  </span>patent news<span class="Apple-converted-space">  </span><br>
<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV3PT8IwFG5EL94wavyZvIteKlg7ZJCgiRqMHDAkYvRGSlcQDYUw9O5_7nvt2IYnPHhplq7t1q8va_fy3vcxFsiyKP36JkitQ3kZaDpwGG1kUKmKeqRVoCu1vlRmkT3mw6G8Ama8FCP1ryuPdbj2lEn7h9VPB8UKvEYbwBKtAMuV7IAiL7xKNm-PvBPEHTwdDwMx9LtgAMsfPWeGmvGcmkeSRuAU01zeetsJTvNb3Psi6vUyxK0OTWeueNO-kQWlkTTveVEB3uq47yk5IPLj-8fncy3I_YB_rqTbk7kfnaAId0xa2Dx15fHO17ycBiYtsVy_tsLlSs--G4pQkrxg_ZQ4z8fRSM-vjC09PxVYQdZryY7pibzc3t8tsiK93lRNzQxuPL5bbM3YbfZN2ILDFjy2kGALiC34ycHEQootZHOHBFtYYAseW3DYUq_GWM0-rh3CjXN3DQQ05IDeYWf3ze7dQ4neupcIimIRk8slHqrPOO5lcxa7bN1OrNljYLRQ1Ys-0aSFlYHQ_VAORKCjGt6IqiLYZycrDXmwYrtDtpkt6xHbGKDdm2NHofkDUTM95w"><span class="s170">Univ China Mining Applies for Patent on Nonlinear Industrial Process Modeling Method Based on <b>Wgans</b>...</span></a><br>
</span><span class="s18">Global IP News: Industrial Patent News, Jun 14, 2022</span><span class="s2"><br>
</span><span class="s18"><b>Newspaper Article</b><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV3PT8IwFG5EL94wavyZvIteKlg7ZJCgiRqMHDAkYvRGSlcQDYUw9O5_7nvt2IYnPHhplq7t1q8va_fy3vcxFsiyKP36JkitQ3kZaDpwGG1kUKmKeqRVoCu1vlRmkT3mw6G8Ama8FCP1ryuPdbj2lEn7h9VPB8UKvEYbwBKtAMuV7IAiL7xKNm-PvBPEHTwdDwMx9LtgAMsfPWeGmvGcmkeSRuAU01zeetsJTvNb3Psi6vUyxK0OTWeueNO-kQWlkTTveVEB3uq47yk5IPLj-8fncy3I_YB_rqTbk7kfnaAId0xa2Dx15fHO17ycBiYtsVy_tsLlSs--G4pQkrxg_ZQ4z8fRSM-vjC09PxVYQdZryY7pibzc3t8tsiK93lRNzQxuPL5bbM3YbfZN2ILDFjy2kGALiC34ycHEQootZHOHBFtYYAseW3DYUq_GWM0-rh3CjXN3DQQ05IDeYWf3ze7dQ4neupcIimIRk8slHqrPOO5lcxa7bN1OrNljYLRQ1Ys-0aSFlYHQ_VAORKCjGt6IqiLYZycrDXmwYrtDtpkt6xHbGKDdm2NHofkDUTM95w"><span class="s145">Citation Online</span></a></span></p>
<p class="p14"><span class="s100"><br>
<span class="Apple-converted-space">  </span></span><span class="s2"><br>
<br>
<span class="Apple-converted-space"> </span></span><span class="s171"><span class="Apple-converted-space"> </span></span><span class="s100"> 2</span><span class="s2">022 20<span class="Apple-converted-space">  </span>patent news<span class="Apple-converted-space">  </span><br>
<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtZ3PT8IwFMcbf1y8YdT4M3kXT3VYt8kgQRNEEUxMiIB6I6MrBJVBLOj_4l_re93Yhl7w4KXpuq3ZPu3aUt77PsYcOy-sH2OCLaVnnzuSFhxKKttxC6IUSN-RbrFn-2ruPRaZQ0VB2PSCjdS_tjyWYduTJ-0fWj-pFAswj30AU-wFmC7VD8jygtdnIX7HNRwBtImYrbQicX6yA6ik_2Abk8NOqGcTGkA0LkWNe671SM4tbWx0ZV1TMIBIyIM3x0O8v_o2ngX8zuQf1CDR4eX3JjY1v_KpIjx-uo2FY1-y0QZ4o2kGWtqZaOGU8EmWaPGjZV0waFcCf9AKd-7lTf3IxBnhRmALL092-HjzY5pP7JUWxK-fG95iYSTK61HQQI_cE0gKfRQM5fRChVantcpW7VIxnkhx9vTiJUE7x3L0eBMfWUElwr7JVlS4xb4IORjkYJBDjByi94IMckDkkEUOKXL4hRwMcjDIwSCHLHKIkINBDnhcHvnvr5cEvnxqstvspHbTrtYtep1uHIAUE01bNHrgz7TupjDEDlsLx6HaZaCk8AtnPZJV89y-kD3P7gtHBkU8ERSEs8eOl6pyf8nrDthG2t6HbL2P34k6MpKb31TFT-w"><span class="s170">Univ Hunan Files Chinese Patent Application for Unsupervised Multi-View Three-Dimensional Point Cloud Joint Registration Method Based on <b>WGAN</b></span></a><br>
</span><span class="s18">Global IP News: Software Patent News, Apr 28, 2022</span><span class="s2"><br>
</span><span class="s18"><b>Newspaper Article</b><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtZ3PT8IwFMcbf1y8YdT4M3kXT3VYt8kgQRNEEUxMiIB6I6MrBJVBLOj_4l_re93Yhl7w4KXpuq3ZPu3aUt77PsYcOy-sH2OCLaVnnzuSFhxKKttxC6IUSN-RbrFn-2ruPRaZQ0VB2PSCjdS_tjyWYduTJ-0fWj-pFAswj30AU-wFmC7VD8jygtdnIX7HNRwBtImYrbQicX6yA6ik_2Abk8NOqGcTGkA0LkWNe671SM4tbWx0ZV1TMIBIyIM3x0O8v_o2ngX8zuQf1CDR4eX3JjY1v_KpIjx-uo2FY1-y0QZ4o2kGWtqZaOGU8EmWaPGjZV0waFcCf9AKd-7lTf3IxBnhRmALL092-HjzY5pP7JUWxK-fG95iYSTK61HQQI_cE0gKfRQM5fRChVantcpW7VIxnkhx9vTiJUE7x3L0eBMfWUElwr7JVlS4xb4IORjkYJBDjByi94IMckDkkEUOKXL4hRwMcjDIwSCHLHKIkINBDnhcHvnvr5cEvnxqstvspHbTrtYtep1uHIAUE01bNHrgz7TupjDEDlsLx6HaZaCk8AtnPZJV89y-kD3P7gtHBkU8ERSEs8eOl6pyf8nrDthG2t6HbL2P34k6MpKb31TFT-w"><span class="s145">Citation Online</span></a></span><span class="s100"><br>
</span><span class="s2"><br>
<br>
</span><span class="s100"><span class="Apple-converted-space"> </span>2</span><span class="s2">022 21<span class="Apple-converted-space">  </span>patent news<span class="Apple-converted-space">  </span><br>
<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV1NT8JAEN0oXjyJUeMXZg5eC2UX2pKgBlHwIqmBxMQLWXYXY6SlUjjowf_kP3RmaWMwRi_emuz0I7vTN9PuzHuMCV52nW-YwJXyeV0oSjiMMlzUPLehlRSqFoy4NHn3WFYOdZe3xmTLnaOkhW49VfTXvMJ9DG0Yf4LgInlxSEeK9ltzUQ2ZiS3os6pAm3W2ga7nkcZBWH9YAV4E3SycdLbYe35n8yatYuEPn62rfI3_-phFViRwS2RiZtBa-s42WzPxDvtAvwES1TapgdCWl6dgy0rsEqJ19Aq9ablBLyEMMO9OUlimsilgAgwhJq_xHND01lBXMTkBhOg00I_kZAJ9SXzE0JGLyRyuloV-Tykak5I1XGJQ1XRyM5Kz5_P7bqvXrNhDpxs6bZCxJlMEb8iYYR932WnnetC-cfJ5GRL98hijcjr8mhWxxwrxNDb7DIxypVcdEUWYXxu7auTzsSuUDnBAe644YKVfL3X4x_gR2-TUvUD7__4xK8xnC1OybJEn1i0-AZEG2cw"><span class="s170">The Chinese Peoples Liberation Army No.92578 Troops Applies for Patent on Mechanical Pump Small Sample Fault Diagnosis Method Based on <b>WGAN</b>...</span></a><br>
</span><span class="s18">Global IP News. Information Technology Patent News, Oct 7, 2022</span><span class="s2"><br>
</span><span class="s18"><b>Newspaper Article</b> <a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV1NT8JAEN0oXjyJUeMXZg5eC2UX2pKgBlHwIqmBxMQLWXYXY6SlUjjowf_kP3RmaWMwRi_emuz0I7vTN9PuzHuMCV52nW-YwJXyeV0oSjiMMlzUPLehlRSqFoy4NHn3WFYOdZe3xmTLnaOkhW49VfTXvMJ9DG0Yf4LgInlxSEeK9ltzUQ2ZiS3os6pAm3W2ga7nkcZBWH9YAV4E3SycdLbYe35n8yatYuEPn62rfI3_-phFViRwS2RiZtBa-s42WzPxDvtAvwES1TapgdCWl6dgy0rsEqJ19Aq9ablBLyEMMO9OUlimsilgAgwhJq_xHND01lBXMTkBhOg00I_kZAJ9SXzE0JGLyRyuloV-Tykak5I1XGJQ1XRyM5Kz5_P7bqvXrNhDpxs6bZCxJlMEb8iYYR932WnnetC-cfJ5GRL98hijcjr8mhWxxwrxNDb7DIxypVcdEUWYXxu7auTzsSuUDnBAe644YKVfL3X4x_gR2-TUvUD7__4xK8xnC1OybJEn1i0-AZEG2cw"><span class="s145"> Full Text Online</span></a></span><span class="s2"><br>
<br>
</span><span class="s100">2</span><span class="s2">022 22<span class="Apple-converted-space">  </span>patent news TO PATENT<br>
<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtZ3PT8IwFMcb0Ys3jBp_Ju-ilzkc3XBbgiZI8MfBhABGPZFSiqhhkg38Y_xrfa8d2_CEBy_L1izN-mm3t76-fh9jLq849q9vApfS5zVX0g-Hkoq73oUTDqVwpRcMuFCL3WMmHMqkLk-WYqT-teexDPuedtL-ofezSrEAz3EM4BFHAR5XGgcUeWG9oEEa05uM1o9WCihrtkoUCfRTLEAjX8XWYYdN7TO09OquivHnVinaxCXf5hOrK0hPGEfLTFitaEyDJotTb8e07KOredCZqa1rNJJDWpDo2E-3qXDsezHbgHXf1h9a8kxQ8tCFnO3i0YrbMMgzgZNap2bz3DOpc41YWmQLb8-8fFb7a1bJYpaWBLCf7_3lQiPM6zukahh4wSnJoU-oIZcqsh-7JVbiYZAaU6Pxpa1cr8zK9HhTMVUxNAz6Lbamom32TdghxQ4pdkixg2kbFLADYgeDHVLsQNghxQ4GOxB2KGAHxA45djDYQWMHvO7Y9YmIP64Ifv1cn-6ws5tWr3lnU3P6aRJSPCTkpklexTxJ-jkMZ5etR5-R2mOAk1zf86Qccc-lGa3wg0E19IQXqqqP9mufnaxU5cGK9x2yzby_j9jGCN8VdaxlN38ALb1PSg"><span class="s170">Univ Yanshan Submits Chinese Patent Application for Cement Clinker Free Calcium Sample Data Enhancement and Prediction Method Based on R-<b>WGAN</b></span></a><br>
</span><span class="s18">Global IP News: Construction Patent News, May 24, 2022</span><span class="s2"><br>
</span><span class="s18"><b>Newspaper Article</b><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtZ3PT8IwFMcb0Ys3jBp_Ju-ilzkc3XBbgiZI8MfBhABGPZFSiqhhkg38Y_xrfa8d2_CEBy_L1izN-mm3t76-fh9jLq849q9vApfS5zVX0g-Hkoq73oUTDqVwpRcMuFCL3WMmHMqkLk-WYqT-teexDPuedtL-ofezSrEAz3EM4BFHAR5XGgcUeWG9oEEa05uM1o9WCihrtkoUCfRTLEAjX8XWYYdN7TO09OquivHnVinaxCXf5hOrK0hPGEfLTFitaEyDJotTb8e07KOredCZqa1rNJJDWpDo2E-3qXDsezHbgHXf1h9a8kxQ8tCFnO3i0YrbMMgzgZNap2bz3DOpc41YWmQLb8-8fFb7a1bJYpaWBLCf7_3lQiPM6zukahh4wSnJoU-oIZcqsh-7JVbiYZAaU6Pxpa1cr8zK9HhTMVUxNAz6Lbamom32TdghxQ4pdkixg2kbFLADYgeDHVLsQNghxQ4GOxB2KGAHxA45djDYQWMHvO7Y9YmIP64Ifv1cn-6ws5tWr3lnU3P6aRJSPCTkpklexTxJ-jkMZ5etR5-R2mOAk1zf86Qccc-lGa3wg0E19IQXqqqP9mufnaxU5cGK9x2yzby_j9jGCN8VdaxlN38ALb1PSg"><span class="s145">Citation Online</span></a></span><span class="s100"><br>
</span><span class="s2"><br>
<br>
</span><span class="s100">2</span><span class="s2">022 23<span class="Apple-converted-space">  </span>patent news<span class="Apple-converted-space">  </span>see 2021<br>
<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtZ1LTwIxEIAbHxdvGDW-SObgrVlcusVlEzRBgo-DCQGM8URKKUENK1nQH-OvdabbZRcPPg5eNksh3e7XodN2pjOMBaLie1_GBKF1KGqBpgmH0UYE8syPRloFWtaHQpns9FjqDpWmLJqv-Ej9a89jGfY9naT9Q-8vK8UCvEcZwCtKAV5_JQfkecEfUSFN6J-M2o8sBZQ128wNBegnX4BmbsW2boctu2fIrXXXJDi5NYYOcemntynvKYonjNKyULwdT0holn7qnYTMPraaO5uZml-ikhyRQaLrPVy7wLHPxWwD_LZjB9qKTR2aBbPNGlY8hEH7Erik9WueyPclbaYRbkNs4c-Xe3y8876oWI8lCm0-pUadm9i7762zdRHVVzWidFqrX2IleuBMzUwCzRTlNlsz8Q77IIzgMILDCA4jpK2FAkZAjJBiBIcRCCM4jJBiBMIIBYyAGCHHCClGsBgBP3e9xlQlLxcEs3Fqb3fZyVW737rxslcaUPjpMc5K5gOcF-FI6Qci8vfYRvwam30GuFgNpdR6LGRAK1MV1ofVSCoZmWqIeuiAlb-t6vCH74_YVt5Tx2xzjDJuyjZc5icLKjcg"><span class="s170">Univ Yanshan Submits Chinese Patent Application for Cement Clinker Free Calcium Sample Data Enhancement and Prediction Method Based on R-<b>WGAN</b></span></a><br>
</span><span class="s18">Global IP News. Construction Patent News, May 24, 2022</span><span class="s2"><br>
</span><span class="s18"><b>Newspaper Article</b><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtZ1LTwIxEIAbHxdvGDW-SObgrVlcusVlEzRBgo-DCQGM8URKKUENK1nQH-OvdabbZRcPPg5eNksh3e7XodN2pjOMBaLie1_GBKF1KGqBpgmH0UYE8syPRloFWtaHQpns9FjqDpWmLJqv-Ej9a89jGfY9naT9Q-8vK8UCvEcZwCtKAV5_JQfkecEfUSFN6J-M2o8sBZQ128wNBegnX4BmbsW2boctu2fIrXXXJDi5NYYOcemntynvKYonjNKyULwdT0holn7qnYTMPraaO5uZml-ikhyRQaLrPVy7wLHPxWwD_LZjB9qKTR2aBbPNGlY8hEH7Erik9WueyPclbaYRbkNs4c-Xe3y8876oWI8lCm0-pUadm9i7762zdRHVVzWidFqrX2IleuBMzUwCzRTlNlsz8Q77IIzgMILDCA4jpK2FAkZAjJBiBIcRCCM4jJBiBMIIBYyAGCHHCClGsBgBP3e9xlQlLxcEs3Fqb3fZyVW737rxslcaUPjpMc5K5gOcF-FI6Qci8vfYRvwam30GuFgNpdR6LGRAK1MV1ofVSCoZmWqIeuiAlb-t6vCH74_YVt5Tx2xzjDJuyjZc5icLKjcg"><span class="s145">Citation Online</span></a></span><span class="s100"><br>
</span><span class="s2"><br>
<span class="Apple-converted-space"> </span><br>
</span><span class="s100">2</span><span class="s2">022 24<span class="Apple-converted-space">  </span>patent news<span class="Apple-converted-space">  </span><br>
<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtZ3PT8IwFMcbf1y8YdT4M3kXvYwhbIOxBE2mAeWgIQGjN1JKUUQGYcP_xv_V99q6DU948NIsTdO0-5RX-vb6fYy5Tqls_7IJjhC-U3UF_eGQQjquVysHQ8Fd4dUHDpc_t8d0OJRO3R6vxEj9K3msQ_Z0k_YP9NNOsQKfcQ1giasAy7XWAUUDoBUYkfKg8oqGXauFpiBWqbNlLEmlnwICwuxTtoo9fNQB4laYJFxMSAWd1CZwmSQc-3qj1aICCR5UDmodAqpkocnGDMba37JMZnYzonvzOlbz-c6ox77nUw5Y7Y6ytuSeuFnM-HBgJGRVcO6HNsZ6NGaw-dsZ5LDAsy5Fv2XHW5WCxFLaW9g8df5Znc-klIYyrehiv7T91Uqt11sLaiT-5vkXpJI-HY5FciUj-6m7yTadoG72WNxYq2bz6xVYgYY353O5gFAT2WUbMtpjX0QDkAYgjSIgC1AswLAAPT3IsQBkAWb2oFmAYQHEAnIsQLMAfHOgWUDKAvIsVIvGlC8m10Skcake91mx1ezd3ts0o75JT4pFTA6c-JUv47ifvY_yAduKZpE8ZIDHX9_zhBg5nktnXe7XB5XA414gKz7ubEfsfK0uj9dsd8J2MuSnbHuEvyJ5pgQ5vwG5Mlbp"><span class="s170">Inst Inf Eng, CAS Files Chinese Patent Application for Network Attack Traffic Data Enhancement Method and System Combining Auto-Encoder and <b>WGA</b></span></a><br>
</span><span class="s18">Global IP News: Broadband and Wireless Network Patent News, Mar 12, 2022</span><span class="s2"><br>
</span><span class="s18"><b>Newspaper Article</b><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtZ3PT8IwFMcbf1y8YdT4M3kXvYwhbIOxBE2mAeWgIQGjN1JKUUQGYcP_xv_V99q6DU948NIsTdO0-5RX-vb6fYy5Tqls_7IJjhC-U3UF_eGQQjquVysHQ8Fd4dUHDpc_t8d0OJRO3R6vxEj9K3msQ_Z0k_YP9NNOsQKfcQ1giasAy7XWAUUDoBUYkfKg8oqGXauFpiBWqbNlLEmlnwICwuxTtoo9fNQB4laYJFxMSAWd1CZwmSQc-3qj1aICCR5UDmodAqpkocnGDMba37JMZnYzonvzOlbz-c6ox77nUw5Y7Y6ytuSeuFnM-HBgJGRVcO6HNsZ6NGaw-dsZ5LDAsy5Fv2XHW5WCxFLaW9g8df5Znc-klIYyrehiv7T91Uqt11sLaiT-5vkXpJI-HY5FciUj-6m7yTadoG72WNxYq2bz6xVYgYY353O5gFAT2WUbMtpjX0QDkAYgjSIgC1AswLAAPT3IsQBkAWb2oFmAYQHEAnIsQLMAfHOgWUDKAvIsVIvGlC8m10Skcake91mx1ezd3ts0o75JT4pFTA6c-JUv47ifvY_yAduKZpE8ZIDHX9_zhBg5nktnXe7XB5XA414gKz7ubEfsfK0uj9dsd8J2MuSnbHuEvyJ5pgQ5vwG5Mlbp"><span class="s145">Citation Online</span></a></span><span class="s100"><br>
</span></p>
<p class="p117"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s100">2</span><span class="s2">022 25<span class="Apple-converted-space">  </span>patent news <span class="Apple-converted-space"> </span></span></p>
<p class="p6"><span class="s17"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtZ1LS8NAEIAXqxdvFRVfhTkIHkJq3aRpClVQqehBGrDqsWw2G5HSrbTB_-k_cma3eXnwcfASyqbdPL7p7uzsPBjzeLvjfhkTuJQ93vUkKRxKKu75QaefSOFJP4y5UHn0mHWHsiXdlzUfqX8lj23IniJp_0C_6BQb8DPKAB5RCvD4Kzkw2mQ9WiQiA_wCte8R5Y9QK48MLcgzjnZrrM8MSY9-SagWUWl_N-b9CHvUmVVgZems-CxM6CaVz6SknhnJk3uF_SXOKCZzjzPUxkMJRxJyY3SfKGiG1r9lFluzlzHCYWy2ig917k2J66oObcsUOHeRGaHbeDtyamstkRhTui1BEY3FfVYjOci4wY0j7Fm5FDblSswP6euFodCJ3rO2cXui_Oiz5FVm50q7jw8N1uD9sD6t8tWUOG6yJl3wTeArhkvLY4utKb3NPgwLqLKAnAVYFjBPwbCAnAUQCyhYQMniZAn2CaFCApAEDGZiMb2o8BicmhaoYwGLBXIsUGKBOhZALFDFAhbLDju-GY6vb938TUwo9XWKGtFywoMw9HycBbudXbau51rtMYh7ceolvghlEPipCAUq0lL0YtUze3PhPmt929XBD-cP2WYJ-IhtpPj_Ui2TqvMTbVtobQ">State Intellectual Property Office of China Releases Univ Guangdong Technology's Patent Application for <span class="s136"><b>Wasserstein</b>...</span></a></span><span class="s15"><br>
</span><span class="s30">Global IP News. Packaging &amp; Containers Patent News, Jul 12, 2022</span><span class="s15"><br>
</span><span class="s30"><b>Newspaper Article</b><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtZ1LS8NAEIAXqxdvFRVfhTkIHkJq3aRpClVQqehBGrDqsWw2G5HSrbTB_-k_cma3eXnwcfASyqbdPL7p7uzsPBjzeLvjfhkTuJQ93vUkKRxKKu75QaefSOFJP4y5UHn0mHWHsiXdlzUfqX8lj23IniJp_0C_6BQb8DPKAB5RCvD4Kzkw2mQ9WiQiA_wCte8R5Y9QK48MLcgzjnZrrM8MSY9-SagWUWl_N-b9CHvUmVVgZems-CxM6CaVz6SknhnJk3uF_SXOKCZzjzPUxkMJRxJyY3SfKGiG1r9lFluzlzHCYWy2ig917k2J66oObcsUOHeRGaHbeDtyamstkRhTui1BEY3FfVYjOci4wY0j7Fm5FDblSswP6euFodCJ3rO2cXui_Oiz5FVm50q7jw8N1uD9sD6t8tWUOG6yJl3wTeArhkvLY4utKb3NPgwLqLKAnAVYFjBPwbCAnAUQCyhYQMniZAn2CaFCApAEDGZiMb2o8BicmhaoYwGLBXIsUGKBOhZALFDFAhbLDju-GY6vb938TUwo9XWKGtFywoMw9HycBbudXbau51rtMYh7ceolvghlEPipCAUq0lL0YtUze3PhPmt929XBD-cP2WYJ-IhtpPj_Ui2TqvMTbVtobQ"><span class="s172">Citation Online</span></a></span><span class="s15"><br>
</span></p>
<p class="p158"><span class="s9"><span class="Apple-converted-space"> </span></span><span class="s37"><br>
</span><span class="s18"><b>2022 26<span class="Apple-tab-span">	</span><span class="Apple-tab-span">	</span></b><a href="https://epubs.siam.org/doi/10.1137/19M1296574"><span class="s173"><b><span class="Apple-converted-space"> </span></b></span></a></span></p>
<p class="p159"><span class="s12"><span class="Apple-converted-space"> </span></span><span class="s20"> <a href="https://patents.google.com/patent/CN114662712A/en?q=wasserstein+wgan&amp;after=priority:20220101"><span class="s5">Rotating machine state monitoring method based on Wasserstein depth digital …</span></a></span></p>
<p class="p160"><span class="s20">CN <a href="https://patentimages.storage.googleapis.com/e1/71/7b/e3eb77685910c6/CN114662712A.pdf"><span class="s174">CN114662712A </span></a></span><span class="s175">胡文扬</span><span class="s20"> </span><span class="s175">清华大学</span></p>
<p class="p15"><span class="s2">Priority 2022-02-22 • Filed 2022-02-22 • Published 2022-06-24</span></p>
<p class="p14"><span class="s18">The invention relates to the technical field of artificial intelligence, and discloses a method for monitoring the state of a rotating machine based on a Wasserstein depth digital twin model, which comprises the steps of acquiring operation and maintenance data of the rotating machine in a healthy …</span><span class="s2"><br>
<br>
</span><span class="s120">2022 27</span></p>
<p class="p161"><span class="s1"><a href="https://search.library.ucla.edu/discovery/fulldisplay?docid=cdi_epo_espacenet_CN114936149A&amp;context=PC&amp;vid=01UCS_LAL:UCLA&amp;lang=en&amp;search_scope=ArticlesBooksMore&amp;adaptor=Primo%20Central&amp;tab=Articles_books_more_slot&amp;query=title%2Ccontains%2Cwgan%2CAND&amp;sortby=date_d&amp;mode=advanced&amp;pfilter=dr_s%2Cexact%2C20220901%2CAND&amp;pfilter=dr_e%2Cexact%2C99991231%2CAND&amp;offset=0"><b>基于</b><span class="s3"><b>WGAN-GP</b></span><span class="s57"><b>的</b></span><span class="s3"><b>CAN</b></span><span class="s57"><b>总线模糊测试用例生成方法及模糊测试系统</b></span></a></span></p>
<p class="p15"><span class="s2"><b>OPEN ACCESS</b></span></p>
<p class="p20"><span class="s2">基于</span><span class="s9">WGAN-GP</span><span class="s2">的</span><span class="s9">CAN</span><span class="s2">总线模糊测试用例生成方法及模糊测试系统</span></p>
<p class="p15"><span class="s2">No Online Access </span></p>
<p class="p15"><span class="s138">[Chinese<span class="Apple-converted-space">  </span></span><span class="s2">CAN bus fuzz test case generation method and fuzz test system based on WGAN-GP]</span></p>
<p class="p14"><span class="s2"><br>
<br>
</span></p>
<p class="p15"><span class="s2"><b>2022<span class="Apple-converted-space">  </span>28</b></span></p>
<p class="p92"><span class="s1"><a href="https://berkeley.primo.exlibrisgroup.com/discovery/fulldisplay?docid=cdi_epo_espacenet_CN114764766A&amp;context=PC&amp;vid=01UCS_BER:UCB&amp;lang=en&amp;search_scope=DN_and_CI&amp;adaptor=Primo%20Central&amp;tab=Default_UCLibrarySearch&amp;query=title%2Ccontains%2Cwgans%2CAND&amp;sortby=date_d&amp;mode=advanced&amp;offset=10"><b>FC-VoVNet and WGAN-based B ultrasonic image denoising method</b><span class="s3"><b></b></span></a></span></p>
<p class="p15"><span class="s2">WEI JIANHUA ; CHEN DEHAI2022</span></p>
<p class="p15"><span class="s2"><b>OPEN ACCESS</b></span></p>
<p class="p15"><span class="s2">FC-VoVNet and WGAN-based B ultrasonic image denoising method</span></p>
<p class="p15"><span class="s2">No Online Access </span></p>
<p class="p69"><span class="s2"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p15"><span class="s2"><b>2022 29</b></span></p>
<p class="p20"><span class="s56"><a href="https://berkeley.primo.exlibrisgroup.com/discovery/fulldisplay?docid=cdi_epo_espacenet_CN113505477BB&amp;context=PC&amp;vid=01UCS_BER:UCB&amp;lang=en&amp;search_scope=DN_and_CI&amp;adaptor=Primo%20Central&amp;tab=Default_UCLibrarySearch&amp;query=title%2Ccontains%2Cwgans%2CAND&amp;sortby=date_d&amp;mode=advanced&amp;offset=20"><b>基于</b><span class="s176"><b>SVAE-WGAN的过程工业软测量数据补充方法</b></span></a></span></p>
<p class="p15"><span class="s2">2022</span></p>
<p class="p15"><span class="s2"><b>OPEN ACCESS</b></span></p>
<p class="p20"><span class="s2">基于</span><span class="s9">SVAE-WGAN</span><span class="s2">的过程工业软测量数据补充方法</span></p>
<p class="p15"><span class="s2">No Online Access </span></p>
<p class="p15"><span class="s138">[Chines<span class="Apple-converted-space">  </span></span><span class="s2">VAE-WGAN-based data supplementation method for soft sensing in process industry</span></p>
<p class="p15"><span class="s2">]</span></p>
<p class="p69"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p15"><span class="s2"><b>2022 30 see 2020</b></span></p>
<p class="p20"><span class="s56"><a href="https://berkeley.primo.exlibrisgroup.com/discovery/fulldisplay?docid=cdi_epo_espacenet_CN111696066BB&amp;context=PC&amp;vid=01UCS_BER:UCB&amp;lang=en&amp;search_scope=DN_and_CI&amp;adaptor=Primo%20Central&amp;tab=Default_UCLibrarySearch&amp;query=title%2Ccontains%2Cwgans%2CAND&amp;sortby=date_d&amp;mode=advanced&amp;offset=30"><b>基于改进</b><span class="s176"><b>WGAN-GP的多波段图像同步融合与增强方法</b></span></a></span></p>
<p class="p15"><span class="s2"><b>OPEN ACCESS</b></span></p>
<p class="p20"><span class="s2">基于改进</span><span class="s9">WGAN-GP</span><span class="s2">的多波段图像同步融合与增强方法</span></p>
<p class="p15"><span class="s2">No Online Access </span></p>
<p class="p15"><span class="s138">[Chinese<span class="Apple-converted-space">  </span></span><span class="s2">Synchronous fusion and enhancement method of multi-band image based on improved WGAN-GP</span></p>
<p class="p15"><span class="s2">]<span class="Apple-converted-space"> </span></span></p>
<p class="p15"><span class="s2"><b>P2022 31</b></span></p>
<p class="p70"><span class="s57"><a href="https://berkeley.primo.exlibrisgroup.com/discovery/fulldisplay?docid=cdi_epo_espacenet_CN114372490A&amp;context=PC&amp;vid=01UCS_BER:UCB&amp;lang=en&amp;search_scope=DN_and_CI&amp;adaptor=Primo%20Central&amp;tab=Default_UCLibrarySearch&amp;query=title%2Ccontains%2Cwgans%2CAND&amp;sortby=date_d&amp;mode=advanced&amp;offset=30"><b>一种基于</b><span class="s95"><b>BiLSTM</b></span><span class="s25"><b>和</b></span><span class="s95"><b>WGAN-GP</b></span><span class="s25"><b>网络的</b></span><span class="s95"><b>sEMG</b></span><span class="s25"><b>数据增强方法</b></span></a></span></p>
<p class="p15"><span class="s2"><b>OPEN ACCESS</b></span></p>
<p class="p15"><span class="s11">一种基于</span><span class="s2">BiLSTM</span><span class="s11">和</span><span class="s2">WGAN-GP</span><span class="s11">网络的</span><span class="s2">sEMG</span><span class="s11">数据增强方法</span></p>
<p class="p15"><span class="s2">No Online Access </span></p>
<p class="p15"><span class="s2">[Chinese<span class="Apple-converted-space">  </span>A sEMG data augmentation method based on BiLSTM and WGAN-GP network]</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p15"><span class="s2"><b>2022<span class="Apple-converted-space">  </span>32</b></span></p>
<p class="p20"><span class="s7"><a href="https://berkeley.primo.exlibrisgroup.com/discovery/fulldisplay?docid=cdi_epo_espacenet_CN114301667A&amp;context=PC&amp;vid=01UCS_BER:UCB&amp;lang=en&amp;search_scope=DN_and_CI&amp;adaptor=Primo%20Central&amp;tab=Default_UCLibrarySearch&amp;query=title%2Ccontains%2Cwgans%2CAND&amp;sortby=date_d&amp;mode=advanced&amp;offset=30"><b>基于</b><span class="s176"><b>WGAN动态惩罚的网络安全不平衡数据集分析方法</b></span></a></span></p>
<p class="p15"><span class="s2"><b>OPEN ACCESS</b></span></p>
<p class="p20"><span class="s2">基于</span><span class="s9">WGAN</span><span class="s2">动态惩罚的网络安全不平衡数据集分析方法</span></p>
<p class="p15"><span class="s2">No Online Access </span></p>
<p class="p15"><span class="s2">[Chinese<span class="Apple-converted-space">  </span>Hyperspectral image classification method based on semi-supervised WGAN-GP</span></p>
<p class="p15"><span class="s2">]</span></p>
<p class="p15"><span class="s2"><b>2022<span class="Apple-converted-space">  </span>33</b></span></p>
<p class="p20"><span class="s7"><a href="https://berkeley.primo.exlibrisgroup.com/discovery/fulldisplay?docid=cdi_epo_espacenet_CN113298297BB&amp;context=PC&amp;vid=01UCS_BER:UCB&amp;lang=en&amp;search_scope=DN_and_CI&amp;adaptor=Primo%20Central&amp;tab=Default_UCLibrarySearch&amp;query=title%2Ccontains%2Cwgans%2CAND&amp;sortby=date_d&amp;mode=advanced&amp;offset=30"><b>一种基于孤立森林与</b><span class="s176"><b>WGAN网络的风电输出功率预测方法</b></span></a></span></p>
<p class="p15"><span class="s2"><b>OPEN ACCESS</b></span></p>
<p class="p20"><span class="s2">一种基于孤立森林与</span><span class="s9">WGAN</span><span class="s2">网络的风电输出功率预测方法</span></p>
<p class="p15"><span class="s2">No Online Access </span></p>
<p class="p15"><span class="s2">[Chinese<span class="Apple-converted-space">  </span>A wind power output power prediction method based on isolated forest and WGAN network]</span></p>
<p class="p162"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p15"><span class="s2"><b>2022 34</b></span></p>
<p class="p70"><span class="s1"><a href="https://berkeley.primo.exlibrisgroup.com/discovery/fulldisplay?docid=cdi_epo_espacenet_CN114219778A&amp;context=PC&amp;vid=01UCS_BER:UCB&amp;lang=en&amp;search_scope=DN_and_CI&amp;adaptor=Primo%20Central&amp;tab=Default_UCLibrarySearch&amp;query=title%2Ccontains%2Cwgans%2CAND&amp;sortby=date_d&amp;mode=advanced&amp;offset=30"><b>Data depth enhancement method based on WGAN-GP data generation and Poisson fusion</b><span class="s95"><b></b></span></a></span></p>
<p class="p15"><span class="s2">ZHANG HUITING ; LIU ZHUO ; HOU YUE ; CHEN NING ; CHEN YANYAN2022</span></p>
<p class="p15"><span class="s2"><b>OPEN ACCESS</b></span></p>
<p class="p15"><span class="s2">Data depth enhancement method based on WGAN-GP data generation and Poisson fusion</span></p>
<p class="p15"><span class="s2">No Online Access <span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p15"><span class="s2"><b>2022 35</b></span></p>
<p class="p70"><span class="s1"><a href="https://berkeley.primo.exlibrisgroup.com/discovery/fulldisplay?docid=cdi_epo_espacenet_CN114218982A&amp;context=PC&amp;vid=01UCS_BER:UCB&amp;lang=en&amp;search_scope=DN_and_CI&amp;adaptor=Primo%20Central&amp;tab=Default_UCLibrarySearch&amp;query=title%2Ccontains%2Cwgans%2CAND&amp;sortby=date_d&amp;mode=advanced&amp;offset=30"><b>Microseism record denoising method based on improved WGAN network and CBDNet</b><span class="s95"><b></b></span></a></span></p>
<p class="p15"><span class="s2">SHENG GUANQUN ; MA KAI ; JING TANG ; ZHENG YUELIN ; YU MEI ; ZHANG JINGLAN2022</span></p>
<p class="p15"><span class="s2"><b>OPEN ACCESS</b></span></p>
<p class="p15"><span class="s2">Microseism record denoising method based on improved WGAN network and CBDNet</span></p>
<p class="p15"><span class="s2">No Online Access </span></p>
<p class="p162"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p15"><span class="s2"><b>2022 36 see 2021</b></span></p>
<p class="p70"><span class="s1"><a href="https://berkeley.primo.exlibrisgroup.com/discovery/fulldisplay?docid=cdi_epo_espacenet_CN114217132A&amp;context=PC&amp;vid=01UCS_BER:UCB&amp;lang=en&amp;search_scope=DN_and_CI&amp;adaptor=Primo%20Central&amp;tab=Default_UCLibrarySearch&amp;query=title%2Ccontains%2Cwgans%2CAND&amp;sortby=date_d&amp;mode=advanced&amp;offset=30"><b>Power system harmonic law calculation method based on WGAN</b><span class="s95"><b></b></span></a></span></p>
<p class="p15"><span class="s2">WU OU ; PAN YANYI ; YAO CHANGQING ; MEI WENBO ; MEI ZHICHAO ; ZHU SHUAI2022</span></p>
<p class="p15"><span class="s2"><b>OPEN ACCESS</b></span></p>
<p class="p15"><span class="s2">Power system harmonic law calculation method based on WGAN</span></p>
<p class="p15"><span class="s2">No Online Access </span></p>
<p class="p69"><span class="s2"><span class="Apple-converted-space">  </span></span></p>
<p class="p15"><span class="s2"><b>2022<span class="Apple-converted-space">  </span>37</b></span></p>
<p class="p20"><span class="s7"><a href="https://berkeley.primo.exlibrisgroup.com/discovery/fulldisplay?docid=cdi_epo_espacenet_CN112946600BB&amp;context=PC&amp;vid=01UCS_BER:UCB&amp;lang=en&amp;search_scope=DN_and_CI&amp;adaptor=Primo%20Central&amp;tab=Default_UCLibrarySearch&amp;query=title%2Ccontains%2Cwgans%2CAND&amp;sortby=date_d&amp;mode=advanced&amp;offset=40"><b>基于</b><span class="s176"><b>WGAN-GP的雷达HRRP数据库构建方法</b></span></a></span></p>
<p class="p15"><span class="s2"><b>OPEN ACCESS</b></span></p>
<p class="p20"><span class="s2">基于</span><span class="s9">WGAN-GP</span><span class="s2">的雷达</span><span class="s9">HRRP</span><span class="s2">数据库构建方法</span></p>
<p class="p15"><span class="s2">No Online Access </span></p>
<p class="p15"><span class="s2">[Chinese<span class="Apple-converted-space">  </span>Construction method of radar HRRP database based on WGAN-GP]</span></p>
<p class="p162"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p15"><span class="s2"><b>2022 38</b></span></p>
<p class="p20"><span class="s7"><a href="https://berkeley.primo.exlibrisgroup.com/discovery/fulldisplay?docid=cdi_epo_espacenet_CN110493242BB&amp;context=PC&amp;vid=01UCS_BER:UCB&amp;lang=en&amp;search_scope=DN_and_CI&amp;adaptor=Primo%20Central&amp;tab=Default_UCLibrarySearch&amp;query=title%2Ccontains%2Cwgans%2CAND&amp;sortby=date_d&amp;mode=advanced&amp;offset=40"><b>基于</b><span class="s176"><b>WGAN-GP和U-net改进的图像增强的方法、装置及存储介质</b></span></a></span></p>
<p class="p15"><span class="s2"><b>OPEN ACCESS</b></span></p>
<p class="p20"><span class="s2">基于</span><span class="s9">WGAN-GP</span><span class="s2">和</span><span class="s9">U-net</span><span class="s2">改进的图像增强的方法、装置及存储介质</span></p>
<p class="p15"><span class="s2">No Online Access </span></p>
<p class="p15"><span class="s2">[Chinese<span class="Apple-converted-space">  </span>mproved image enhancement method, device and storage medium based on WGAN-GP and U-net]</span></p>
<p class="p163"><span class="s4"><br>
</span><span class="s2"><br>
</span></p>
<p class="p14"><span class="s18">2022 39</span><span class="s2"><br>
<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwY2AwNtIz0EUrE5ISDRINDNJMLNOS0tJSk8ws0hITgX2jRFOjJGCVY5IC2z0GXQ6VBdsaAz42tBx8ViIwgyUDs38JuPguQIxpuYCXWhbrJ2UChfLt3UJsXdSgnWUjUO_GQs3FydY1wN_F31nN2dnW2U_NL8gW2A4yNgQmVxNHZgZW0BntoMzhGuYE2qRSkA-5oQVcw7gJMrAFAE3LKxFiYKrKEGbgdIZdxCbMwOELnf8WZmAHL9hMLgYKQjNlsQiDy9P5u57s6ns2ZeeL_bNtchOLsu3C3R39bPTBTF33gOezWp72dj2fPfH53MXPGrc9a-l_trXxZXv_s8UNz7Z2P5u289nmqaIMim6uIc4eukCHxcNDId7ZD-EHYzEGlrz8vFQJBoU0s7SURDNz4ySzVAOTpKS0JBMjQ7NEC0sjiyRjc2BjR5JBCrc5UvgkpRm4QCEK3odnIcPAUlJUmioLPmpRDhx0AIQ-nig"><span class="s177">基于改进</span><span class="s170"><b>WGAN</b>-GP</span><span class="s177">的半监督恶意流量检测方法</span></a><br>
</span><span class="s18">11/2022</span><span class="s2"><br>
</span><span class="s18"><b>Patent</b> <a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwY2AwNtIz0EUrE5ISDRINDNJMLNOS0tJSk8ws0hITgX2jRFOjJGCVY5IC2z0GXQ6VBdsaAz42tBx8ViIwgyUDs38JuPguQIxpuYCXWhbrJ2UChfLt3UJsXdSgnWUjUO_GQs3FydY1wN_F31nN2dnW2U_NL8gW2A4yNgQmVxNHZgZW0BntoMzhGuYE2qRSkA-5oQVcw7gJMrAFAE3LKxFiYKrKEGbgdIZdxCbMwOELnf8WZmAHL9hMLgYKQjNlsQiDy9P5u57s6ns2ZeeL_bNtchOLsu3C3R39bPTBTF33gOezWp72dj2fPfH53MXPGrc9a-l_trXxZXv_s8UNz7Z2P5u289nmqaIMim6uIc4eukCHxcNDId7ZD-EHYzEGlrz8vFQJBoU0s7SURDNz4ySzVAOTpKS0JBMjQ7NEC0sjiyRjc2BjR5JBCrc5UvgkpRm4QCEK3odnIcPAUlJUmioLPmpRDhx0AIQ-nig"><span class="s94"> Available Online</span></a></span><span class="s2"><br>
</span><span class="s18">Open Access</span><span class="s2"><br>
</span><span class="s18"><span class="Apple-converted-space"> </span>[Chinese<span class="Apple-converted-space">  </span>Semi-supervised malicious traffic detection method based on improved WGAN-GP]</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s18">2022 40</span><span class="s2"><br>
<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwY2AwNtIz0EUrE5ISDRINDNJMLNOS0tJSk8ws0hITgX2jRFOjJGCVY5IC2z0GXQ6VBdsaAz42tBx8ViIwgyUDs38JuPguQIxpuYCXWhbrJ2UChfLt3UJsXdSgnWUjUO_GQs3FydY1wN_F31nN2dnW2U_NL8gW2A4CXbBlZujIzMAKOqMdlDlcw5xAm1QK8iH3vINrGDdBBrYAoGl5JUIMTFUZwgyczrCL2IQZOHyh89_CDOzgBZvJxUBBaKYsFmHweDp_15NdfTa5iUXZduHujn42-mCmrrOf3_PWJc_n73-ya-qTHd3PN3U-3TDj2dbJT3cte7mo5dnW7mfTdj7bPPXppJ7nm3c_3z1flEHRzTXE2UMX6Lh4eEjEO_sh_GEsxsCSl5-XKsGgkGaWlpJoZm6cZJZqYJKUlJZkYmRolmhhaWSRZGwObPBIMkjhNkcKn6Q0AxcoVMF78SxkGFhKikpTZcHHLcqBgw8AYcShkA"><span class="s177">基于</span><span class="s170"><b>WGAN</b>-CNN</span><span class="s177">煤矿井下粉尘浓度预测方法和系统</span></a><br>
</span><span class="s18">11/2022</span><span class="s2"><br>
</span><span class="s18"><b>Patent</b> <a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwY2AwNtIz0EUrE5ISDRINDNJMLNOS0tJSk8ws0hITgX2jRFOjJGCVY5IC2z0GXQ6VBdsaAz42tBx8ViIwgyUDs38JuPguQIxpuYCXWhbrJ2UChfLt3UJsXdSgnWUjUO_GQs3FydY1wN_F31nN2dnW2U_NL8gW2A4CXbBlZujIzMAKOqMdlDlcw5xAm1QK8iH3vINrGDdBBrYAoGl5JUIMTFUZwgyczrCL2IQZOHyh89_CDOzgBZvJxUBBaKYsFmHweDp_15NdfTa5iUXZduHujn42-mCmrrOf3_PWJc_n73-ya-qTHd3PN3U-3TDj2dbJT3cte7mo5dnW7mfTdj7bPPXppJ7nm3c_3z1flEHRzTXE2UMX6Lh4eEjEO_sh_GEsxsCSl5-XKsGgkGaWlpJoZm6cZJZqYJKUlJZkYmRolmhhaWSRZGwObPBIMkjhNkcKn6Q0AxcoVMF78SxkGFhKikpTZcHHLcqBgw8AYcShkA"><span class="s94"> Available Online</span></a></span><span class="s2"><br>
</span><span class="s18"><span class="Apple-converted-space"> </span>[Chinese<span class="Apple-converted-space">  </span>Prediction method and system of underground dust concentration in coal mine based on WGAN-CNN]</span><span class="s2"><br>
</span><span class="s18"><span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s2">2022 41<span class="Apple-converted-space">  </span>patent news<br>
<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV1LS8NAEF60XjxZUfFVmYPX2LybQlVa-_CiRBQEL2XW7FJb3MQ0vXjw6t92Ng9KRfTibWFJsssO3zc7mZmPMcc-M41vmMDRRNOUbltyKQX3A4lIdyP0bE6U40ZV9ViZDnVXlcaUx12hZA7dUfyso-ZNXVRC6Er-yGXyZmgdKf2_tRLVwFJsITq3HMsL1tkGmZ6nk75C72kVeP2STYZb7KP6sHjHXLDwh1vrarvGf11lndU1tiWYiBS6helsszWhdthnT7xMic1gKekBOncD7oWYzSEkz1RlQI4u9DFD6Iskm8BATbTt6Dgj3OSK1NAjcowgVtB5xXR28Tjq3naa-dAYhcWzRcNrbReAKoIwJhOg8XCh43e77HQ4eLi6NqrdjnVPZUlUOx8v9-rssZqKldhnIH0Zod9yuC9Ml3PJXdvyMWjbAXda5H4dsMavrzr8Y_6Ibdq6JMGyDNs6ZrUsXYhG3gLyJD_rL7wzzGg"><span class="s170">Beijing Industrial Univ Seeks Patent for Data Depth Enhancement Method Based on </span></a></span></p>
<p class="p14"><span class="s18"><span class="Apple-converted-space"> </span>WGAN-GP Data Generation and Poisson Fusion</span><span class="s2"><br>
</span><span class="s18">Global IP News. Information Technology Patent News, Nov 21, 2022</span><span class="s2"><br>
</span><span class="s18"><b>Newspaper Article</b> <a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV1LS8NAEF60XjxZUfFVmYPX2LybQlVa-_CiRBQEL2XW7FJb3MQ0vXjw6t92Ng9KRfTibWFJsssO3zc7mZmPMcc-M41vmMDRRNOUbltyKQX3A4lIdyP0bE6U40ZV9ViZDnVXlcaUx12hZA7dUfyso-ZNXVRC6Er-yGXyZmgdKf2_tRLVwFJsITq3HMsL1tkGmZ6nk75C72kVeP2STYZb7KP6sHjHXLDwh1vrarvGf11lndU1tiWYiBS6helsszWhdthnT7xMic1gKekBOncD7oWYzSEkz1RlQI4u9DFD6Iskm8BATbTt6Dgj3OSK1NAjcowgVtB5xXR28Tjq3naa-dAYhcWzRcNrbReAKoIwJhOg8XCh43e77HQ4eLi6NqrdjnVPZUlUOx8v9-rssZqKldhnIH0Zod9yuC9Ml3PJXdvyMWjbAXda5H4dsMavrzr8Y_6Ibdq6JMGyDNs6ZrUsXYhG3gLyJD_rL7wzzGg"><span class="s94"> Full Text Online</span></a></span><span class="s2"><br>
<span class="Apple-converted-space"> </span><br>
<br>
<span class="Apple-converted-space"> </span>2022 42<span class="Apple-converted-space">  </span>patent news<br>
<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV1NS8NAEF20XjxZUfGrMgevtflOClWJobWISgVB8FJmm91WtGlNUgQP3v3X7mwTSkX04i1LINllhzezO_PmMWZbJ0b9GyZwNNAwpNOUXErBvUAiqrMRuhZXLseJS_ZYUQ51V1Jjiu0uUVJDdzwZ0K15g0gllEgy_fPpa510pCjfWopqYCG2EJ-atukGq2xNmZ5LRV8993EZeP3Cm3Q22Ef5Y_GOWrDwh1PrcrvGf51llVUJ26Y4FSmEc9PZZCsi2WKfV8pchtkMopEY4gjamhoIdAEPCmPGT3kGJLktMgE9FaYmOYSLFDioCBh6pLsG807o0MV0TM134RrfIMKXQaEWBjdauRoulBONQY1bY0yfzx4uw9tWQz9us-NO-z7q1sv19qmrslTONusvVmvvsEoyScQuA-nJGD3f5p4wHM4ldyzTw6BpBdz2VQC2x2q_fmr_j_cHbN0iUgIV5zUPWSVPZ6Kmm0Ae6d3-Av2NzZk"><span class="s170">Jiangsu Chegah Energy Tech Submits Chinese Patent Application for Power System Harmonic Law Calculation Method Based on <b>WGAN</b></span></a><br>
</span><span class="s18">Global IP News. Electrical Patent News, Nov 19, 2022</span><span class="s2"><br>
</span><span class="s18"><b>Newspaper Article</b> <a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV1NS8NAEF20XjxZUfGrMgevtflOClWJobWISgVB8FJmm91WtGlNUgQP3v3X7mwTSkX04i1LINllhzezO_PmMWZbJ0b9GyZwNNAwpNOUXErBvUAiqrMRuhZXLseJS_ZYUQ51V1Jjiu0uUVJDdzwZ0K15g0gllEgy_fPpa510pCjfWopqYCG2EJ-atukGq2xNmZ5LRV8993EZeP3Cm3Q22Ef5Y_GOWrDwh1PrcrvGf51llVUJ26Y4FSmEc9PZZCsi2WKfV8pchtkMopEY4gjamhoIdAEPCmPGT3kGJLktMgE9FaYmOYSLFDioCBh6pLsG807o0MV0TM134RrfIMKXQaEWBjdauRoulBONQY1bY0yfzx4uw9tWQz9us-NO-z7q1sv19qmrslTONusvVmvvsEoyScQuA-nJGD3f5p4wHM4ldyzTw6BpBdz2VQC2x2q_fmr_j_cHbN0iUgIV5zUPWSVPZ6Kmm0Ae6d3-Av2NzZk"><span class="s94"> Full Text Online</span></a></span><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2"><br>
2022 43<span class="Apple-converted-space">  </span>patent news<br>
<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV1LS8NAEF60XjxZUfFVmYPgKTbvJlCVPmy9tFYoCF7KrtmFIk1qUg968H_575zZJNSK6MXbLgm7YTPMa7-ZjzHHPjeNbzpBcJObpnJDJZSSwg8U5xgbcc8WaHLcqKweK-BQd2VpTPG7Sy2pVXeUPFLWvE5FJWiObCe8mj8bxCNF960lqQYvyBaiC8uxvGCdbaDoeQT6GnkPq4o3KKxJb4u9lxvLN64JC3-IWlfbNf7rV1ZZlXTbnM9lCq1cdLbZmox32Id2PuFrcQmMKF-fLl7hltpNSEgUaNZtQJdTUtdaGKNASOhTdj0DgnqcZTDCdeIFtJYX5ID-MQwIAJjJaTaDPPKFroyTKWUsYKDZrKGNhjUCfD9PeOC4OePp0-V9vzVs1vUQhjl6HXgcQafdxekuO-1djzs3Rnk-E-rCrNA4Z5Pl6Th7rBInsdxnoHwVcb_hCF-arhBKuLbl8yC0A-E00GE7YLVflzr84_kR27SpiMGyDNs6ZpVF-iJrumnkiZaOT3Q23yU"><span class="s170">State Intellectual Property Office of China Receives Three Gorges Univ's Patent Application for Microseism Record Denoising Method Based on Improved <b>WGAN</b>...</span></a><br>
</span><span class="s18">Global IP News. Broadband and Wireless Network News, Nov 21, 2022</span><span class="s2"><br>
</span><span class="s18"><b>Newspaper Article</b> <a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV1LS8NAEF60XjxZUfFVmYPgKTbvJlCVPmy9tFYoCF7KrtmFIk1qUg968H_575zZJNSK6MXbLgm7YTPMa7-ZjzHHPjeNbzpBcJObpnJDJZSSwg8U5xgbcc8WaHLcqKweK-BQd2VpTPG7Sy2pVXeUPFLWvE5FJWiObCe8mj8bxCNF960lqQYvyBaiC8uxvGCdbaDoeQT6GnkPq4o3KKxJb4u9lxvLN64JC3-IWlfbNf7rV1ZZlXTbnM9lCq1cdLbZmox32Id2PuFrcQmMKF-fLl7hltpNSEgUaNZtQJdTUtdaGKNASOhTdj0DgnqcZTDCdeIFtJYX5ID-MQwIAJjJaTaDPPKFroyTKWUsYKDZrKGNhjUCfD9PeOC4OePp0-V9vzVs1vUQhjl6HXgcQafdxekuO-1djzs3Rnk-E-rCrNA4Z5Pl6Th7rBInsdxnoHwVcb_hCF-arhBKuLbl8yC0A-E00GE7YLVflzr84_kR27SpiMGyDNs6ZpVF-iJrumnkiZaOT3Q23yU"><span class="s94"> Full Text Online</span></a></span><span class="s2"> </span><span class="s89"><br>
<br>
</span><span class="s2"><span class="Apple-converted-space"> </span>2022 44<span class="Apple-converted-space">  </span>patent news<br>
<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtZ07T8MwEIDNa2EDAeIp3YIYQiHQNA8JkACB6ABEAgQbchsHEG2CSMrP4bdyd3bilKkMLEnluJGTzzpfzvcQon2457Z-yYRQ-jjkJHC9XuhHnu-qXq9PRcsjPHf6fhU9pt2hpr-r0Bjb-K_ksQ3ZUyTtH-jXN8UG_I1zAI84C_A40TxgbXI8WiQmA_wnat-3lD9CGY-MTNY-8gXq1dlLqshiMirzYd5D2WHsVnclSlByBtJOzFW_eKCNjbWwoKtkt69CqHhjIMaxZKVWffvWzfE6xy9_51KOBiVOw1I6F9krzUZ2VLjmGtfOGS63CW1tnOe0y64tmI-So0WpYqdJoM2eUFxlupBckORG-7k3lXBd58Dpxizi2TRqn9IMsRn-QRYR_JgmK6-1iHKNE4eTe2H32rroxF_lXu0rNZZ4-6kbjDfqhMABqodBGKIApjTsw-StXx6rrPVwNyNmDqPQLOK4cgdmdb1fEAs0vA-JFOFUI18U0ypbmlpk3NDEDRVu0LghT4FxQ40bKoxgXwQwbmDcgM8DCNT2q3CDwc1XCTcY3DsF6DcJDdiAsIFhA8MGgg0N2KBhA8MG_EMDNhwN5ef7SQP50T63gCUPDfJgyC-L3cuL-_OrFr3GZ1N0FQ8FmaWKFzkqimcLwV0Rs1meqVUBnTBJQt9zk-jA87wglaGi7ed2grqySiN_TWxPdMv1CfttiHk7zzbFXIqyQW1xmtEftcWp3g"><span class="s26">State Intellectual Property Office of China Publishes Dongfeng Automobile Group Stock Ltd and Dongfeng Pleasure Science and Tech Limited's Patent Application for Motor Fault Data Enhancement Method Based on Conditional <b>Wasserstein</b>...</span></a><br>
</span><span class="s18">Global IP News: Automobile Patent News, Nov 4, 2022</span><span class="s2"><br>
</span><span class="s18"><b>Newspaper Article</b><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtZ07T8MwEIDNa2EDAeIp3YIYQiHQNA8JkACB6ABEAgQbchsHEG2CSMrP4bdyd3bilKkMLEnluJGTzzpfzvcQon2457Z-yYRQ-jjkJHC9XuhHnu-qXq9PRcsjPHf6fhU9pt2hpr-r0Bjb-K_ksQ3ZUyTtH-jXN8UG_I1zAI84C_A40TxgbXI8WiQmA_wnat-3lD9CGY-MTNY-8gXq1dlLqshiMirzYd5D2WHsVnclSlByBtJOzFW_eKCNjbWwoKtkt69CqHhjIMaxZKVWffvWzfE6xy9_51KOBiVOw1I6F9krzUZ2VLjmGtfOGS63CW1tnOe0y64tmI-So0WpYqdJoM2eUFxlupBckORG-7k3lXBd58Dpxizi2TRqn9IMsRn-QRYR_JgmK6-1iHKNE4eTe2H32rroxF_lXu0rNZZ4-6kbjDfqhMABqodBGKIApjTsw-StXx6rrPVwNyNmDqPQLOK4cgdmdb1fEAs0vA-JFOFUI18U0ypbmlpk3NDEDRVu0LghT4FxQ40bKoxgXwQwbmDcgM8DCNT2q3CDwc1XCTcY3DsF6DcJDdiAsIFhA8MGgg0N2KBhA8MG_EMDNhwN5ef7SQP50T63gCUPDfJgyC-L3cuL-_OrFr3GZ1N0FQ8FmaWKFzkqimcLwV0Rs1meqVUBnTBJQt9zk-jA87wglaGi7ed2grqySiN_TWxPdMv1CfttiHk7zzbFXIqyQW1xmtEftcWp3g"><span class="s94">Citation Online</span></a></span></p>
<p class="p14"><span class="s2"><br>
<span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s18">2022 45 piatent<span class="Apple-converted-space"> </span></span></p>
<p class="p105"><span class="s27"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:2022D93909">Method for determining relevance of object, involves calculating <span class="s127">Wasserstein</span><span class="s128"> distance between detection object and tracking object according to Gaussian distribution of detection object and Gaussian distribution of tracking object</span></a></span></p>
<p class="p5"><span class="s18">CN115273019-A</span></p>
<p class="p14"><span class="s18"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22LIN%20J%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s123">LIN J</span></a></span></p>
<p class="p5"><span class="s30"><b>Assignee(s) </b></span><span class="s18">JIUSHI ZHIXING BEIJING TECHNOLOGY CO LTD</span></p>
<p class="p14"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2022-D93909</span></p>
<p class="p164"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p165"><span class="s18"><span class="Apple-converted-space"> </span></span><span class="s2"><b><span class="Apple-converted-space"> </span></b></span></p>
<p class="p14"><span class="s18">2022 46<span class="Apple-converted-space">  </span>patent</span></p>
<p class="p105"><span class="s27"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:2022D9871X">Method for upsampling network on point cloud, involves constructing loss function of point cloud upsampling network based on <span class="s127">Wasserstein</span><span class="s128"> distance, and obtaining point cloud upsampling network by training sparse point cloud training data and dense point cloud training data</span></a></span></p>
<p class="p5"><span class="s18">CN115294179-A</span></p>
<p class="p77"><span class="s129"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22LUO%20Z%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s121">LUO Z</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22LI%20Z%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">LI Z</span></a> and <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22LEI%20N%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">LEI N</span></a></span></p>
<p class="p5"><span class="s30"><b>Assignee(s) </b></span><span class="s18">UNIV DALIAN TECHNOLOGY</span></p>
<p class="p14"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2022-D9871X</span></p>
<p class="p166"><span class="s2">more_horiz</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2922<span class="Apple-converted-space">  </span>47<span class="Apple-converted-space">  </span>patent</span></p>
<p class="p6"><span class="s17"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:2022D5413F">Method for removing artifacts from extremely sparse angular computed tomography reconstruction, involves sending image set as input to UNet generator network trained based on <span class="s122">WGAN</span><span class="s123">-GP generative adversarial network combined with transformers block</span></a></span></p>
<p class="p5"><span class="s18">CN115239588-A</span></p>
<p class="p77"><span class="s129"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22QIN%20Y%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s121">QIN Y</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22JIANG%20W%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">JIANG W</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22DI%20J%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s125">DI J</span></a></span></p>
<p class="p5"><span class="s30"><b>Assignee(s) </b></span><span class="s18">UNIV GUANGDONG TECHNOLOGY</span></p>
<p class="p14"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p104"><span class="s2">2022-D5413F</span></p>
<p class="p14"><span class="s2"><br>
2022 48<br>
<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV3JTsMwELUoXLgVAWKrNAduUQpJmi5SQWIpAiFEJYKQuFQmccSipFUX_om_5I2dNCkHlgOHWKlTOe7zdDy2Z94I4bn1Q_uLTvBc6cuIubh8Gcew2pseFkfNjsLi7MkJ23n0mHGHMpkZJws-Uv868qjD2HMk7R9Gf94oKnAPGUAJKUD5Kzl4fB7OrGtcQe43yb4YrDASPjPow9ZMp8YYDQvHw3Pm081SYbH39WwytW6hXZIsbNO60ZmnrVNMghEfODxIHbfJuTPxbL7vqM8mrtU4VdCu7CsPm78HrZIUAvFaTj5gXfW13q0vNMLiGTAdCHqfdbgcnsE7FljsOo5twuK1jOkcJJYm38LX57t_Vv99Wte-TEx6nkQv4fRIpfb9XUVU3E57ca70s_ksqIoqv3AkR2pMJwbkNbGk0nXxwQATAKYcYGKAKQOYTH-pBDABYCoDTAZgKgNMBmDSABM-dxM5fjsuwdw90DVUAoqANhm0KUObCrQ3xP5FLzi7tPNfOGCe6hjmy2TgthpMo8acPJtiOR2maktQ5CqsQ10_jhqq4bQ82YbVH8Wq6SsnjD25LWrfNrXzw_NdsVoM3J5YifFnUDXNq_kJNXtJTQ"><span class="s170">Zhou Kou Teaching Univ Submits Patent Application for Distribution Robust Optimization Method Based on <b>Wasserstein</b>...</span></a><br>
</span><span class="s18">Global IP News. Measurement &amp; Testing Patent News, Nov 26, 2022</span><span class="s2"><br>
</span><span class="s18"><b>Newspaper Article</b><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV3JTsMwELUoXLgVAWKrNAduUQpJmi5SQWIpAiFEJYKQuFQmccSipFUX_om_5I2dNCkHlgOHWKlTOe7zdDy2Z94I4bn1Q_uLTvBc6cuIubh8Gcew2pseFkfNjsLi7MkJ23n0mHGHMpkZJws-Uv868qjD2HMk7R9Gf94oKnAPGUAJKUD5Kzl4fB7OrGtcQe43yb4YrDASPjPow9ZMp8YYDQvHw3Pm081SYbH39WwytW6hXZIsbNO60ZmnrVNMghEfODxIHbfJuTPxbL7vqM8mrtU4VdCu7CsPm78HrZIUAvFaTj5gXfW13q0vNMLiGTAdCHqfdbgcnsE7FljsOo5twuK1jOkcJJYm38LX57t_Vv99Wte-TEx6nkQv4fRIpfb9XUVU3E57ca70s_ksqIoqv3AkR2pMJwbkNbGk0nXxwQATAKYcYGKAKQOYTH-pBDABYCoDTAZgKgNMBmDSABM-dxM5fjsuwdw90DVUAoqANhm0KUObCrQ3xP5FLzi7tPNfOGCe6hjmy2TgthpMo8acPJtiOR2maktQ5CqsQ10_jhqq4bQ82YbVH8Wq6SsnjD25LWrfNrXzw_NdsVoM3J5YifFnUDXNq_kJNXtJTQ"><span class="s145">Citation Online</span></a></span></p>
<p class="p167"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p168"><span class="s15"><br>
</span><span class="s12">2022 49<span class="Apple-converted-space">  </span>patent news </span><span class="s15"><br>
<a href="https://duke.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV1bT8IwFG5EX3zDqPGanBd9mUPYBmMJmoAB5EGzRIy-kTI6uYSNsOFf8G97Tju2YWKC8aVpmrZpv2877c7OhTHTKJX1HzKBom7VPMsUVW5atuE5ZmVk8CreN4Z4gsnsbzkfMZX5MPrV1Soxd_434diGlJMD7R9ITyfFBqwj9Vgi-VhuRX9LTKbKGCBNzUE2GCgbxCyiwPwyKFO4RNpjjlJnEY-1djCmZ0CaBzzJzNJaCw-5Ef1QeOs2n_Wuq7qrWNXx2pLZDZE9rHdW0ZrlaT6jgNZzpTAl7UPi_iTHZmr99YLyThekh8BP2EpFNzI9hMwsosmQWtg91elp7mdcSi2UNsJdv_fszUYVhpcuVCgYLOeagp_PRxMvvhOB_vpSYAXDqSdHJ56XdnIJ6BdZkZa34AuxhKZC_IDtiOCQfSVoQ4Y2ENog0Qa1OcCNA8EHEm3IoQ0KbZBoQxhAY86Xs3vCvHErqwi9GptBDwg9JNCDgv6I3XTa_YdHndY-SPKLYhGRBib64KsoGmQ7Lx-z3SAMxAkDu2o43KxZvC7Klu8LRwx9urMNa5YnHJOfsqutpjzbst8528_IvWB7Pr4P4lJlyvgGQWhBqQ"><span class="s178">Beijing Industrial Univ Seeks Patent for Data Depth Enhancement Method Based on <b>WGAN</b>-GP Data...</span></a><br>
</span><span class="s30">Global IP News: Information Technology Patent News, Nov 21, 2022</span><span class="s15"><br>
</span><span class="s30"><b>Newspaper Article</b><a href="https://duke.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwpV1bT8IwFG5EX3zDqPGanBd9mUPYBmMJmoAB5EGzRIy-kTI6uYSNsOFf8G97Tju2YWKC8aVpmrZpv2877c7OhTHTKJX1HzKBom7VPMsUVW5atuE5ZmVk8CreN4Z4gsnsbzkfMZX5MPrV1Soxd_434diGlJMD7R9ITyfFBqwj9Vgi-VhuRX9LTKbKGCBNzUE2GCgbxCyiwPwyKFO4RNpjjlJnEY-1djCmZ0CaBzzJzNJaCw-5Ef1QeOs2n_Wuq7qrWNXx2pLZDZE9rHdW0ZrlaT6jgNZzpTAl7UPi_iTHZmr99YLyThekh8BP2EpFNzI9hMwsosmQWtg91elp7mdcSi2UNsJdv_fszUYVhpcuVCgYLOeagp_PRxMvvhOB_vpSYAXDqSdHJ56XdnIJ6BdZkZa34AuxhKZC_IDtiOCQfSVoQ4Y2ENog0Qa1OcCNA8EHEm3IoQ0KbZBoQxhAY86Xs3vCvHErqwi9GptBDwg9JNCDgv6I3XTa_YdHndY-SPKLYhGRBib64KsoGmQ7Lx-z3SAMxAkDu2o43KxZvC7Klu8LRwx9urMNa5YnHJOfsqutpjzbst8528_IvWB7Pr4P4lJlyvgGQWhBqQ"><span class="s172">Citation Online</span></a></span><span class="s100"><br>
</span><span class="s15"><br>
<span class="Apple-converted-space"> </span></span><span class="s30"><span class="Apple-tab-span">	</span><span class="Apple-tab-span">	</span>8</span><span class="s15"><br>
</span><span class="s12">2022 50<span class="Apple-converted-space">  </span>patent news </span><span class="s15"><br>
<a href="https://duke.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV1LT8JAEN4oXDyJUeMLMgevBdptaZsQDUiLiZHUR2LihSztNihxW6HcvPu3nWlpEA968dJs0_Sx2ck3X2dn5mOMG8229gMTqOtWJzS5tAQ3bSN0uR4ZwkK-MUEPlqu_fa8RuytLY1bLXaJkDt1RElLUvEVFJYiuyEcu03eNdKRov7UU1RArsQXas7FcZ5tV8V_GpKQvx_c2gddZeRN_l32UL85TqZtFKkkRVNjIsS6bNf7rN9ZYjZAtFamcQ68wnD22JdU---zLl1f0ZbAW9ADK3IAHKWcLCJCXqgyQ5sJAZAIGMs2m4KkpWQ5FGeE216OGPrrGCBIF3Tcxn108DXujbisfasOguLdod01WAUJFECRoADj2lxS9O2Dnvvd4da2Vsx1TR-UYHe1ivJ4rP2QVlSh5xMC2DFfwjikc2TbjWLpyEhPnmHTMULpcHLP6r486-eP6KdsxqCBB1zVDP2OVbL6U9ULYoZEvdYNV-94ouMezG1vDY2A9fwEne82D"><span class="s178">Beijing Industrial Univ Seeks Patent for Data Depth Enhancement Method Based on <b>WGAN</b>-GP Data...</span></a><br>
</span><span class="s30">Global IP News. Information Technology Patent News, Nov 21, 2022</span><span class="s15"><br>
</span><span class="s30"><b>Newspaper Article</b> <a href="https://duke.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV1LT8JAEN4oXDyJUeMLMgevBdptaZsQDUiLiZHUR2LihSztNihxW6HcvPu3nWlpEA968dJs0_Sx2ck3X2dn5mOMG8229gMTqOtWJzS5tAQ3bSN0uR4ZwkK-MUEPlqu_fa8RuytLY1bLXaJkDt1RElLUvEVFJYiuyEcu03eNdKRov7UU1RArsQXas7FcZ5tV8V_GpKQvx_c2gddZeRN_l32UL85TqZtFKkkRVNjIsS6bNf7rN9ZYjZAtFamcQ68wnD22JdU---zLl1f0ZbAW9ADK3IAHKWcLCJCXqgyQ5sJAZAIGMs2m4KkpWQ5FGeE216OGPrrGCBIF3Tcxn108DXujbisfasOguLdod01WAUJFECRoADj2lxS9O2Dnvvd4da2Vsx1TR-UYHe1ivJ4rP2QVlSh5xMC2DFfwjikc2TbjWLpyEhPnmHTMULpcHLP6r486-eP6KdsxqCBB1zVDP2OVbL6U9ULYoZEvdYNV-94ouMezG1vDY2A9fwEne82D"><span class="s172"> Full Text Online</span></a></span><span class="s15"><br>
</span></p>
<p class="p117"><span class="s30">2022<span class="Apple-converted-space">  </span>51 Wire Feed patent news</span><span class="s15"><br>
<a href="https://www.proquest.com/docview/2749316793/6C78903ACE2243B0PQ/8?accountid=13158"><span class="s179">State Intellectual Property Office of China Releases Hangzhou Electronics Science and Technology Univ's Patent Application for Network Security Unbalanced Data Set Analysis Method Based on </span><span class="s180">WGAN</span><span class="s179"> Dynamic Penalty</span></a><br>
</span><span class="s30"><b>Global IP News. Security &amp; Protection Patent News; New Delhi</b> [New Delhi]. 10 Dec 2</span></p>
<p class="p117"><span class="s2"><span class="Apple-converted-space"> </span><a href="javascript:void(0)"><span class="s181">Cite</span></a></span></p>
<p class="p117"><span class="s2"><br>
</span></p>
<ul class="ul1">
  <li class="li169"></li>
</ul>
<p class="p115"><span class="s4">2022<span class="Apple-converted-space">  </span>52<span class="Apple-converted-space">  </span>patent news Wire Feed<br>
<a href="https://www.proquest.com/docview/2755471652/AF01846E06FC4127PQ/24?accountid=13158"><span class="s94">State Intellectual Property Office of China Receives River and Sea Univ's Patent Application for Power System Bad Data Identification Method Based on Improved </span><span class="s182">Wasserstein</span><span class="s94"> Gan</span></a></span><span class="s15"><br>
</span><span class="s4"><b>Global IP News. Electrical Patent News; New Delhi</b> [New Delhi]. 17 Dec 2022.  <br>
<a href="javascript:void(0)"><span class="s94">Cite</span></a></span><span class="s183"><span class="Apple-converted-space">  </span><a href="javascript:void(0)"><span class="s184">Email</span></a><span class="Apple-converted-space">  </span></span><span class="s4">Full Text<br>
<a href="https://www.proquest.com/docview/2755471652/citation/AF01846E06FC4127PQ/24?accountid=13158"><span class="s94">Details</span></a><a href="https://www.proquest.com/docview/2755471652/fulltext/AF01846E06FC4127PQ/24?accountid=13158"><span class="s94">Full text</span></a></span></p>
<p class="p44"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s185"><a href="https://mathscinet-ams-org.ezaccess.libraries.psu.edu/mathscinet/search/publdoc.html?arg3=2022&amp;co4=AND&amp;co5=AND&amp;co6=AND&amp;co7=AND&amp;dr=pubyear&amp;pg4=AUCN&amp;pg5=TI&amp;pg6=PC&amp;pg7=ALLF&amp;pg8=ET&amp;review_format=html&amp;s4=&amp;s5=wasserstein&amp;s6=&amp;s7=&amp;s8=All&amp;sort=Newest&amp;vfpref=html&amp;yearRangeFirst=&amp;yearRangeSecond=&amp;yrop=eq&amp;r=20&amp;mx-pid=4495278"><b><span class="Apple-converted-space"> </span></b></a></span><span class="s2"><span class="Apple-converted-space"> </span><a href="https://www.worldcat.org/title/9396425321"><span class="s181"><b> </b></span></a>2022 53<span class="Apple-converted-space">  </span>paint news<br>
<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtZ07T8MwEIAtHgsbCBBP6RZgCC1p0tSJBEi86QBEogi2ymkcQIgUkQCCH8tv4c52HmUqA4sVOY5j-bs4p_P5jjHXadqNX2tC5LmeLZNBS3hR4rQ6ke1EPPATlADJO51BcXpMu0NNfBRHY6rKfyWPdcieTtL-gX7ZKVbgNcoAligFWI4lB0qbHD0tEpIB_hW17yuKHyGNR0YqyDOOdmsy61yk918PwzfrpMySk5XLAJnaK4u8cu1QVv8QX5TmWq8dVD6Ml9rR3Fj2c3ogIn9Kcjw4FrnAG3kVG-VCZbS2DnEYMW1k3J4dXFrHn6lQPvwSm-UjG9E6Z4HVDdVyTfaN8j0k1KEOQ0FjMcOrn-sgU4ejsq4Yp1cSTpW8xFJRu7B5aTa0wve8WTpBjUTUvuvy0Uod6ZdTwi4PVbdNiq_-HD8O8j2ZNm6uJ9mkE_jm74y_ZM_oGb1ZNkvDexGIBw40yzk2IdN59q04Qp0jFBxBc4RhAoojFByh4Ag1jmA4AnKEiiMQx60M9DRBjSIgRTAUoZhdqCgCUcQb-JChCJoiKIqAPew-i9enfWK5u6MuwSAFg3SBbZ-e9I7OGzQlfZMZFYuMbEfZvXjLsn41ofYim0qHqVxi4Me-7ycc9R_Hbbt2FAQJd2O_HcuAR5yLZbYxVpcrY7ZbZTOVzKyx6QQ_YLmuYoH-AJjLhxY"><span class="s170">State Intellectual Property Office of China Releases Hangzhou Electronics Science and Technology Univ's Patent Application for Network Security Unbalanced Data Set Analysis Method Based on <b>WGAN</b>...</span></a></span><span class="s18"> </span><span class="s2"><br>
</span><span class="s18">Global IP News: Security &amp; Protection Patent News, Dec 10, 2022</span><span class="s2"><br>
</span><span class="s18"><b>Newspaper Article</b> </span><span class="s2"><br>
<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV1LS8NAEF60XjxZUfFVmYPgqTbJNi-oSrWtvVjjAwQvZZPdVJEmNUkP7cGf6m9xdptYK6IXIYfAZh9shm92ZmfmI4Qax1r1Gyb4JjU1EQY6M_3Q0C1fM3zbdUKUAGFbVlBkj-XhUDdFakz-uwuUVNDN40B6zWtoT7kyj9ulZ6PXquSRkvetBakGy8kW-IlOddNZJisoeqYM-vLMx0XgtXJt0lkjb8XEYsoUYeEPVutiucZ_XWWZlCW2jdhIJNCcic46WRLRBnlXh0_4mlwCnvTXJ9kErmW5CQFxCIp1G25RZaESTKHLosH0KR5D-5NUJ4UcNYBFHOYOfJCRIEcpeDhNlEFzfn8OeHyG3iwqHe5yWj383JfBl4Hg0GIZwwbslBdSgStFfw3nuAgOOEJjyJKX04fLZq9RU6_QmkRs-ByAJ7BPNtkkh532_UW3WmxiX5ZqDlGDp_35FtItUoriSGwTcDja7qGN6tWgdar5rhvalDt1Llzbt222Qyq_DrX7R_seWTVkpoOOj7ZPSlkyFhVVWfJAidAH8S7sfw"><span class="s170">State Intellectual Property Office of China Releases Hangzhou Electronics Science and Technology Univ's Patent Application for Network Security Unbalanced Data Set Analysis Method Based on <b>WGAN</b>...</span></a></span><span class="s18"> </span><span class="s2"><br>
</span><span class="s18">Global IP News. Security &amp; Protection Patent News, Dec 10, 2022</span><span class="s2"><br>
</span><span class="s18"><b>Newspaper Article</b> <a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV1LS8NAEF60XjxZUfFVmYPgqTbJNi-oSrWtvVjjAwQvZZPdVJEmNUkP7cGf6m9xdptYK6IXIYfAZh9shm92ZmfmI4Qax1r1Gyb4JjU1EQY6M_3Q0C1fM3zbdUKUAGFbVlBkj-XhUDdFakz-uwuUVNDN40B6zWtoT7kyj9ulZ6PXquSRkvetBakGy8kW-IlOddNZJisoeqYM-vLMx0XgtXJt0lkjb8XEYsoUYeEPVutiucZ_XWWZlCW2jdhIJNCcic46WRLRBnlXh0_4mlwCnvTXJ9kErmW5CQFxCIp1G25RZaESTKHLosH0KR5D-5NUJ4UcNYBFHOYOfJCRIEcpeDhNlEFzfn8OeHyG3iwqHe5yWj383JfBl4Hg0GIZwwbslBdSgStFfw3nuAgOOEJjyJKX04fLZq9RU6_QmkRs-ByAJ7BPNtkkh532_UW3WmxiX5ZqDlGDp_35FtItUoriSGwTcDja7qGN6tWgdar5rhvalDt1Llzbt222Qyq_DrX7R_seWTVkpoOOj7ZPSlkyFhVVWfJAidAH8S7sfw"><span class="s186">Full Text Online </span></a></span><span class="s12"><br>
</span></p>
<p class="p133"><span class="s2"><br>
</span></p>
<p class="p119"><span class="s2">2022 54 patent</span></p>
<p class="p120"><span class="s17"><a href="https://patents.google.com/patent/CN116248344A/en?q=TI%3d(wgan)&amp;oq=TI%3d(wgan)&amp;sort=new">Cloud environment intrusion detection method based on <span class="s147"><b>WGAN</b> and LightGBM</span></a></span></p>
<p class="p121"><span class="s18">CN116248344A </span><span class="s19">裴廷睿</span><span class="s18"> </span><span class="s19">湘潭大学</span></p>
<p class="p122"><span class="s18">Filed 2022-12-28 • Published 2023-06-09</span></p>
<p class="p119"><span class="s18">6. The cloud environment intrusion detection method according to claim 1, wherein S33 includes the <b>WGAN</b> model taking the preprocessing data as an input of the discrimination model, the random noise as an input of the generation model, performing a reciprocal game using the generation model and the …</span></p>
<p class="p119"><span class="s2"><br>
</span></p>
<p class="p119"><span class="s2">2022 55 patent</span></p>
<p class="p120"><span class="s17"><a href="https://patents.google.com/patent/CN115546257A/en?q=TI%3d(wgan)&amp;oq=TI%3d(wgan)&amp;sort=new&amp;page=1">Grid deformation data enhancement method based on <span class="s147"><b>WGAN</b>-GP model</span></a></span></p>
<p class="p170"><span class="s187">CN <a href="https://patentimages.storage.googleapis.com/64/9d/72/9814f01ab89a0d/CN115937038A.pdf"><span class="s188">CN115937038A </span></a></span><span class="s189">李静</span><span class="s187"> </span><span class="s189">上海大学</span></p>
<p class="p122"><span class="s18">Priority 2022-12-27 • Filed 2022-12-27 • Published 2023-04-07</span></p>
<p class="p119"><span class="s18">The invention discloses a method for enhancing grid deformation data based on a <b>WGAN</b>-GP model, which relates to the technical field of image processing and data enhancement and comprises the following steps: constructing a training data set and a test data set; constructing a <b>WGAN</b>-GP model;</span></p>
<p class="p119"><span class="s2"><br>
</span></p>
<p class="p119"><span class="s2">2022 56patent</span></p>
<p class="p120"><span class="s17"><a href="https://patents.google.com/patent/CN115859889A/en?q=TI%3d(wgan)&amp;oq=TI%3d(wgan)&amp;sort=new">Method for selecting drive resistor of <span class="s147"><b>eGaN</b> HEMT power converter</span></a></span></p>
<p class="p121"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/67/0b/fa/6677801276a881/CN115859889A.pdf"><span class="s148">CN115859889A </span></a></span><span class="s19">贺远航</span><span class="s18"> </span><span class="s19">广东工业大学</span></p>
<p class="p122"><span class="s18">Priority 2022-11-16 • Filed 2022-11-16 • Published 2023-03-28</span></p>
<p class="p119"><span class="s18">10. The method for selecting the drive resistor of the <b>eGaN</b> HEMT power converter according to claim 1, wherein S3.6 specifically comprises: the method for improving the overall efficiency of the converter is to select a reasonable driving resistor to obtain a reasonable driving waveform, reduce the …</span></p>
<p class="p119"><span class="s2"><br>
</span></p>
<p class="p119"><span class="s190"><span class="Apple-converted-space"> </span></span><span class="s191"><br>
</span><span class="s2">2022 57 patent</span></p>
<p class="p120"><span class="s17"><a href="https://patents.google.com/patent/CN114936149A/en?q=TI%3d(wgan)&amp;oq=TI%3d(wgan)&amp;sort=new&amp;page=1">Antagonistic sample generation method and system based on <span class="s147"><b>WGAN</b>-Unet</span></a></span></p>
<p class="p170"><span class="s187">CN <a href="https://patentimages.storage.googleapis.com/37/64/70/05c3c93e3cf1ca/CN115761399A.pdf"><span class="s188">CN115761399A </span></a></span><span class="s189">秦中元</span><span class="s187"> </span><span class="s189">东南大学</span></p>
<p class="p122"><span class="s18">Priority 2022-11-01 • Filed 2022-11-01 • Published 2023-03-07</span></p>
<p class="p119"><span class="s18">s3, constructing a <b>WGAN</b>-Unet-based anti-attack network model: the anti-attack network model consists of a generator, a discriminator and the target network model obtained in the step S2, wherein the generator is constructed according to original sample data based on a Unet framework, performs …</span></p>
<p class="p119"><span class="s2"><br>
</span></p>
<p class="p171"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p119"><span class="s2">2022 58 patent</span></p>
<p class="p172"><span class="s192"><a href="https://patents.google.com/patent/CN115544864A/en?q=TI%3d(wgan)&amp;oq=TI%3d(wgan)&amp;sort=new"><b>WGAN</b><span class="s147">-based FRP sheet and concrete interface bonding slippage model generation …</span></a></span></p>
<p class="p170"><span class="s187">CN <a href="https://patentimages.storage.googleapis.com/63/04/93/a41f78bb966677/CN115544864A.pdf"><span class="s188">CN115544864A </span></a></span><span class="s189">贺畅</span><span class="s187"> </span><span class="s189">同济大学</span></p>
<p class="p122"><span class="s18">Priority 2022-09-16 • Filed 2022-09-16 • Published 2022-12-30</span></p>
<p class="p119"><span class="s18">2. The method for generating the <b>WGAN</b>-based FRP sheet and concrete interface bonding slip model according to claim 1, wherein the step 1: strain data acquisition is realized by modeling through finite element software LS-DYNA, and data corresponding to strain at every two seconds, namely average …</span></p>
<p class="p119"><span class="s2"><br>
</span></p>
<p class="p119"><span class="s2">2022</span></p>
<p class="p119"><span class="s2"><br>
</span></p>
<p class="p119"><span class="s2">2022 59 patent</span></p>
<p class="p120"><span class="s17"><a href="https://patents.google.com/patent/CN114301667A/en?q=TI%3d(wgan)&amp;oq=TI%3d(wgan)&amp;sort=new&amp;page=1">Vehicle following behavior modeling method based on Transformer-<span class="s147"><b>WGAN</b></span></a></span></p>
<p class="p121"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/99/fc/d3/fdadd7e0b84442/CN115630683A.pdf"><span class="s148">CN115630683A </span></a></span><span class="s19">徐东伟</span><span class="s18"> </span><span class="s19">浙江工业大学</span></p>
<p class="p122"><span class="s18">Priority 2022-09-14 • Filed 2022-09-14 • Published 2023-01-20</span></p>
<p class="p173"><span class="s2">2. The method of claim 1, wherein the method for modeling vehicle-following behavior based on Transformer-<b>WGAN</b> is characterized in that: acquiring state sequence data of a plurality of groups of following vehicles and vehicle</span></p>
<p class="p174"><span class="s18"><b><span class="Apple-converted-space">  </span></b></span></p>
<p class="p119"><span class="s2">2022<span class="Apple-converted-space">  </span>60 atent</span></p>
<p class="p120"><span class="s17"><a href="https://patents.google.com/patent/CN115600089A/en?q=TI%3d(wgan)&amp;oq=TI%3d(wgan)&amp;sort=new&amp;page=1">Micro-seismic signal denoising method combining <span class="s147"><b>WGAN</b>-GP and SADNet</span></a></span></p>
<p class="p121"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/7e/38/8e/19e80f6e7f04dd/CN115600089A.pdf"><span class="s148">CN115600089A </span></a></span><span class="s19">余梅</span><span class="s18"> </span><span class="s19">三峡大学（</span><span class="s18">Cn</span><span class="s19">）</span></p>
<p class="p122"><span class="s18">Priority 2022-09-02 • Filed 2022-09-02 • Published 2023-01-13</span></p>
<p class="p119"><span class="s18">1. A micro-seismic signal denoising method combining <b>WGAN</b>-GP and SADNet is characterized by comprising the following steps: inputting a microseism signal sample into a <b>WGAN</b>-GP network, adding a noise signal condition, generating a large number of training sample sets by generating a confrontation …</span></p>
<p class="p119"><span class="s2"><br>
</span></p>
<p class="p119"><span class="s2">2022 61 patent</span></p>
<p class="p120"><span class="s17"><a href="https://patents.google.com/patent/CN115310361A/en?q=TI%3d(wgan)&amp;oq=TI%3d(wgan)&amp;sort=new&amp;page=1">… system for predicting underground dust concentration of coal mine based on <span class="s147"><b>WGAN</b> …</span></a></span></p>
<p class="p121"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/0b/51/17/48d61dbb0ad179/CN115310361A.pdf"><span class="s148">CN115310361A </span></a></span><span class="s19">秦波涛</span><span class="s18"> </span><span class="s19">中国矿业大学</span></p>
<p class="p122"><span class="s18">Priority 2022-08-16 • Filed 2022-08-16 • Published 2022-11-08</span></p>
<p class="p119"><span class="s18">9. The <b>WGAN</b>-CNN-based coal mine dust concentration prediction system of claim 8, the prediction model building module further comprises: and the reliability inspection unit is used for inputting the test data set into the coal mine underground dust concentration prediction model to obtain a …</span></p>
<p class="p119"><span class="s2">2022 -atent</span></p>
<p class="p120"><span class="s17"><a href="https://patents.google.com/patent/CN115546257A/en?q=TI%3d(wgan)&amp;oq=TI%3d(wgan)&amp;sort=new&amp;page=1">Satellite cloud picture prediction method based on <span class="s147"><b>WGAN</b>-GP network and optical …</span></a></span></p>
<p class="p121"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/d5/e7/50/d4be0bfc632926/CN115546257A.pdf"><span class="s148">CN115546257A </span></a></span><span class="s19">谈玲</span><span class="s18"> </span><span class="s19">南京信息工程大学</span></p>
<p class="p122"><span class="s18">Priority 2022-08-09 • Filed 2022-08-09 • Published 2022-12-30</span></p>
<p class="p119"><span class="s18">5. The <b>W</b></span><span class="s191"><br>
</span></p>
<p class="p119"><span class="s2">2022 62 patent</span></p>
<p class="p120"><span class="s17"><a href="https://patents.google.com/patent/CN115859889A/en?q=TI%3d(wgan)&amp;oq=TI%3d(wgan)&amp;sort=new">Semi-supervised malicious flow detection method based on improved <span class="s147"><b>WGAN</b>-GP</span></a></span></p>
<p class="p175"><span class="s79">CN <a href="https://patentimages.storage.googleapis.com/3b/f3/be/845d4372968aec/CN115314254A.pdf"><span class="s148">CN115314254A </span></a></span><span class="s18">刘胜利</span><span class="s79"> </span><span class="s18">中国人民解放军战略支援部队信息工程大学</span></p>
<p class="p122"><span class="s18">Priority 2022-07-07 • Filed 2022-07-07 • Published 2022-11-08</span></p>
<p class="p119"><span class="s18">The invention belongs to the technical field of malicious traffic detection, and particularly relates to a semi-supervised malicious traffic detection method based on improved <b>WGAN</b>-GP. The method carries out detection according to the established semi-supervised malicious flow detection model.</span></p>
<p class="p119"><span class="s2"><br>
</span></p>
<p class="p119"><span class="s2">2022 63 iatent</span></p>
<p class="p132"><span class="s18">XRF-<b>EGAN</b> model-based soil XRF spectrogram background subtraction method</span></p>
<p class="p121"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/d3/5b/9b/97d64f1cdf48df/CN114861541A.pdf"><span class="s148">CN114861541A </span></a></span><span class="s19">赵彦春</span><span class="s18"> </span><span class="s19">电子科技大学长三角研究院</span><span class="s18">(</span><span class="s19">湖州</span><span class="s18">)</span></p>
<p class="p122"><span class="s18">Priority 2022-05-13 • Filed 2022-05-13 • Published 2022-08-05</span></p>
<p class="p119"><span class="s18">and step 3: and loading an XRF-<b>EGAN</b> generator network model, carrying out XRF spectrum background deduction on new soil XRF spectrum data measured by an XRF fluorescence analyzer by using the XRF-<b>EGAN</b> generator network, and obtaining output after background deduction. 4. The XRF-<b>EGAN</b> model-based …</span></p>
<p class="p42"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p176"><span class="s2">2023 64<span class="Apple-converted-space">  </span>patent<span class="Apple-tab-span">	</span><span class="Apple-tab-span">	</span><span class="Apple-tab-span">	</span><span class="Apple-tab-span">	</span><span class="Apple-tab-span">	</span><span class="Apple-tab-span">	</span><span class="Apple-tab-span">	</span><span class="Apple-tab-span">	</span><span class="Apple-tab-span">	</span>55</span></p>
<p class="p177"><span class="s193"><a href="https://patents.google.com/patent/CN116152372A/en?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new">Laplace noise and <span class="s194"><b>Wasserstein</b> regularization-based multi-test EEG source …</span></a></span></p>
<p class="p178"><span class="s195">CN <a href="https://patentimages.storage.googleapis.com/3d/b8/0b/1957591e69f5a6/CN116152372A.pdf"><span class="s196">CN116152372A </span></a></span><span class="s197">刘柯</span><span class="s195"> </span><span class="s197">重庆邮电大学</span></p>
<p class="p179"><span class="s18">Priority 2023-02-07 • Filed 2023-02-07 • Published 2023-05-23</span></p>
<p class="p176"><span class="s18">s4, establishing a multi-test robust EEG diffuse source imaging model based on Laplace noise and <b>Wasserstein</b> regularization in a projection space according to the lead matrix, the difference operator and the minimum distance matrix, and obtaining a multi-test estimated source by utilizing an ADMM …</span></p>
<p class="p176"><span class="s2"><br>
</span></p>
<p class="p176"><span class="s2">2022 65. patent</span></p>
<p class="p180"><span class="s17"><a href="https://patents.google.com/?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new#">… recognition domain self-adaption method and system combining <span class="s198"><b>Wasserstein</b> …</span></a></span></p>
<p class="p181"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/e3/07/29/fceee385ea799c/CN115601535A.pdf"><span class="s199">CN115601535A </span></a></span><span class="s151">陈元姣</span><span class="s18"> </span><span class="s151">杭州电子科技大学（</span><span class="s18">Cn</span><span class="s151">）</span></p>
<p class="p179"><span class="s18">Priority 2022-11-08 • Filed 2022-11-08 • Published 2023-01-13</span></p>
<p class="p176"><span class="s18">5. The chest radiograph abnormality recognition domain adaptation method combining <b>Wasserstein</b> distance and difference measure of claim 4, wherein the construction of the total objective function through the obtained <b>Wasserstein</b> distance and contrast domain difference in step S3 comprises the …</span></p>
<p class="p176"><span class="s2"><br>
</span></p>
<p class="p176"><span class="s2">2022 66</span></p>
<p class="p180"><span class="s17"><a href="https://patents.google.com/?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new#">Telecom customer churn prediction method based on condition <span class="s198"><b>Wasserstein</b> GAN</span></a></span></p>
<p class="p178"><span class="s195">CN <a href="https://patentimages.storage.googleapis.com/da/d3/ae/8c7c0a63b99ed9/CN115688048A.pdf"><span class="s196">CN115688048A </span></a></span><span class="s197">苏畅</span><span class="s195"> </span><span class="s197">重庆邮电大学</span></p>
<p class="p179"><span class="s18">Priority 2022-10-31 • Filed 2022-10-31 • Published 2023-02-03</span></p>
<p class="p176"><span class="s18">3. the method of claim 2, wherein the conditional <b>Wasserstein</b> GAN-based telecommunications customer churn prediction method comprises: in S2, the mixed attention mechanism CBAM includes two parts: channel attention module CAM and spatial attention module SAM; the overall attention process for CBAM …</span></p>
<p class="p176"><span class="s2"><br>
</span></p>
<p class="p176"><span class="s2">2022 67</span></p>
<p class="p177"><span class="s193"><a href="https://patents.google.com/?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new#">Road network pixelation-based <span class="s194"><b>Wasserstein</b> generation countermeasure flow data …</span></a></span></p>
<p class="p178"><span class="s195">CN <a href="https://patentimages.storage.googleapis.com/c0/85/f4/d7b5e0e045455e/CN115510174A.pdf"><span class="s196">CN115510174A </span></a></span><span class="s197">王蓉</span><span class="s195"> </span><span class="s197">重庆邮电大学</span></p>
<p class="p179"><span class="s18">Priority 2022-09-29 • Filed 2022-09-29 • Published 2022-12-23</span></p>
<p class="p176"><span class="s18">6. The road network pixelation-based <b>Wasserstein</b> generation countermeasure network traffic data interpolation method as claimed in claim 1, wherein the process of repairing missing data by a road network traffic data generation countermeasure network model comprises: splicing traffic flow data to …</span></p>
<p class="p176"><span class="s2"><br>
</span></p>
<p class="p176"><span class="s2">2022 68</span></p>
<p class="p177"><span class="s193"><a href="https://patents.google.com/?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new#">Maximum slice <span class="s194"><b>Wasserstein</b> measurement-based pedestrian target association …</span></a></span></p>
<p class="p181"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/c2/fc/61/80157c81c2b6ab/CN115630190A.pdf"><span class="s199">CN115630190A </span></a></span><span class="s151">陈亮</span><span class="s18"> </span><span class="s151">南京信息技术研究院</span></p>
<p class="p179"><span class="s18">Priority 2022-09-07 • Filed 2022-09-07 • Published 2023-01-20</span></p>
<p class="p176"><span class="s18">5. The method for monitoring network pedestrian target association based on maximum slice <b>Wasserstein</b> measurement as claimed in claim 1, wherein said step S4 specifically comprises the steps of: s401: associating R' according to cross-mirror pedestrian target " j According to (C) i1 </span><span class="s151">，</span><span class="s18">T i1,j1 </span><span class="s151">，</span><span class="s18">T i, …</span></p>
<p class="p176"><span class="s2"><br>
</span></p>
<p class="p176"><span class="s2">2022 69<span class="Apple-converted-space">  </span>see 2018 patent <span class="Apple-converted-space"> </span></span></p>
<p class="p177"><span class="s193"><a href="https://patents.google.com/?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new#"><b>Wasserstein</b><span class="s194"> distance-based battery SOH estimation method and device</span></a></span></p>
<p class="p181"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/c9/d5/c4/4032d6fa28ea41/CN114839552A.pdf"><span class="s199">CN114839552A </span></a></span><span class="s151">林名强</span><span class="s18"> </span><span class="s151">泉州装备制造研究所</span></p>
<p class="p179"><span class="s18">Priority 2022-04-08 • Filed 2022-04-08 • Published 2022-08-02</span></p>
<p class="p176"><span class="s18">3. The <b>wasserstein</b> distance-based battery SOH estimation method according to claim 1, wherein: in S1, the aging data of the pouch batteries is specifically aging data of eight nominal 740Ma · h pouch batteries recorded in advance. 4. A <b>wasserstein</b> distance-based ba</span><span class="s37"><br>
</span></p>
<p class="p5"><span class="s2">&lt;—312 till 2021<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space">    </span>+ 69<span class="Apple-converted-space">  </span>patents in 2022</span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space">  </span>= 381<span class="Apple-converted-space">  </span>patents<span class="Apple-converted-space">  </span>till<span class="Apple-converted-space">  </span>2022</span></p>
<p class="p5"><span class="s2">end 2022 e22</span></p>
<p class="p5"><span class="s2">Start 2023<br>
</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2023<span class="Apple-converted-space">  </span>1<span class="Apple-converted-space">  </span>patent news</span></p>
<p class="p182"><span class="s1"><a href="https://www.proquest.com/docview/2761099719/AF01846E06FC4127PQ/1?accountid=13158">Chongqing Post and Telecommunication Univ's Patent Application for Theme Modeling Method Based on Wasserstein Auto-Encoder and Gaussian Mixture Distribution as Prior</a></span><span class="s12"><br>
Global IP News. Telecom Patent News; New Delhi [New Delhi]. 06 Jan 2023.  <br>
<a href="javascript:void(0)"><span class="s200">Cite</span></a><span class="Apple-converted-space">  </span><a href="javascript:void(0)"><span class="s200">Email</span><span class="s201"><br>
</span></a></span><span class="s30">Full Text</span><span class="s15"> <span class="Apple-converted-space">  </span><a href="https://www.proquest.com/docview/2761099719/citation/AF01846E06FC4127PQ/1?accountid=13158"><span class="s179">Details</span></a><a href="https://www.proquest.com/docview/2761099719/fulltext/AF01846E06FC4127PQ/1?accountid=13158"><span class="s179">Full text</span></a></span></p>
<p class="p117"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2"><span class="Apple-converted-space"> </span></span><span class="s100"><br>
</span><span class="s18">2023 2<span class="Apple-converted-space">  </span>patent news </span><span class="s2"> <br>
<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV1NS8NAEF20XjxZUfGrMgfBU6zJJk0CVana6qVYoSB4KdtkV0pp0m5TUA_-Xf-GM2tCWxG9eMwHu8vuMDO7s-89xrhzemZ98wm4K_CCPueuZ8sg8kMVYWRTbsQ9t-_UPFGgx_LrUA8FNCZf7sJLGtcdpxGdmlcdn6jCQ98OL8cTi3SkqN5aiGqIXGwhPrc59r3K1tD0PLr01fGelh0vz51ma4O9Fx3LN2EEC3_YtS7TNf7rKMusTL5tLMZSQ-PLdDbZiky22IdJPmERXAIdOq_X2SvcE92EhFSBUd0GTDklsdbiY5o8TzAIAmn_gkhi6JK-ziL4BOgKyMkUOth-kkFjXjgHzJsBzXUkgZTZCB8PbSNsDVcYY2PAX-ojoYcXj8KAQ0mgs141b6Axy1KrmRAyX5uOb8VsSsBQaA9eqDoCN0QNnKt6gcAB6EGqt9lxq9m9vrOK2ewRZ7PCUD7tzeeS77BSkiZyl4HylHDcWEWY2bqBLUMHJ9UXoR-KALfctT1W-bWp_T--H7B1kpg3xy61Q1bK9ExWDMXkkbGlT2L-8MU"><span class="s170">State Intellectual Property Office of China Receives Chongqing Post and Telecommunication Univ's Patent Application for Theme Modeling Method Based on <b>Wasserstein</b> Auto-Encoder and Gaussian...</span></a><br>
</span><span class="s18">Global IP News. Telecom Patent News, Jan 6, 2023</span><span class="s2"><br>
</span><span class="s18"><b>Newspaper Article</b> <a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV1NS8NAEF20XjxZUfGrMgfBU6zJJk0CVana6qVYoSB4KdtkV0pp0m5TUA_-Xf-GM2tCWxG9eMwHu8vuMDO7s-89xrhzemZ98wm4K_CCPueuZ8sg8kMVYWRTbsQ9t-_UPFGgx_LrUA8FNCZf7sJLGtcdpxGdmlcdn6jCQ98OL8cTi3SkqN5aiGqIXGwhPrc59r3K1tD0PLr01fGelh0vz51ma4O9Fx3LN2EEC3_YtS7TNf7rKMusTL5tLMZSQ-PLdDbZiky22IdJPmERXAIdOq_X2SvcE92EhFSBUd0GTDklsdbiY5o8TzAIAmn_gkhi6JK-ziL4BOgKyMkUOth-kkFjXjgHzJsBzXUkgZTZCB8PbSNsDVcYY2PAX-ojoYcXj8KAQ0mgs141b6Axy1KrmRAyX5uOb8VsSsBQaA9eqDoCN0QNnKt6gcAB6EGqt9lxq9m9vrOK2ewRZ7PCUD7tzeeS77BSkiZyl4HylHDcWEWY2bqBLUMHJ9UXoR-KALfctT1W-bWp_T--H7B1kpg3xy61Q1bK9ExWDMXkkbGlT2L-8MU"><span class="s145"> Full Text Online</span></a></span><span class="s12"><br>
<span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s2">2023 3<span class="Apple-converted-space">  </span>patent</span></p>
<p class="p117"><span class="s202"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwY2AwNtIz0EUrE5KNLVMtQLs6k5LMk0xSzQ2TLU2SzBJNjE3SzEwTTeC7x6DLobJgW2PAx4aWg89KBGawZGD2LwEX3wWIMS0X8FLLYv2kTKBQvr1biK2LGrSzDGxeA5OwmouTrWuAv4u_s5qzs62zn5pfkC3oiBlgRWZp6cjMwAo6ox20GtA1zAm0SaUAVMNYQmsYN0EGtgCgaXklQgxMVRnCDJzOsIvYhBk4fKHz38IM7OAFm8nFQEFopiwWYXB7sqPh-fLep_N3PdnVZ5ObWJRtF-7u6GejD2bqhgJ983xWy9P1O591TX-2YPuzOWueT5n_rGPCs2k7n22e-rS_6_nm3c93zxdlUHRzDXH20AU6LR4eDvHOfghfGIsxsOTl56VKMCgYmpgbGxqmmJtbppqYJJkmAyPJ3DzZzCwpEejNtOQUSQYp3OZI4ZOUZuAChSl4BZa5DANLSVFpqiz4sEU5cOABAPn7n1o">一种基于<span class="s3"><b>WGAN</b>-Unet...</span></a></span><span class="s15"><br>
</span><span class="s30">03/2023</span><span class="s15"><br>
</span><span class="s30"><b>Patent</b> <a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwY2AwNtIz0EUrE5KNLVMtQLs6k5LMk0xSzQ2TLU2SzBJNjE3SzEwTTeC7x6DLobJgW2PAx4aWg89KBGawZGD2LwEX3wWIMS0X8FLLYv2kTKBQvr1biK2LGrSzDGxeA5OwmouTrWuAv4u_s5qzs62zn5pfkC3oiBlgRWZp6cjMwAo6ox20GtA1zAm0SaUAVMNYQmsYN0EGtgCgaXklQgxMVRnCDJzOsIvYhBk4fKHz38IM7OAFm8nFQEFopiwWYXB7sqPh-fLep_N3PdnVZ5ObWJRtF-7u6GejD2bqhgJ983xWy9P1O591TX-2YPuzOWueT5n_rGPCs2k7n22e-rS_6_nm3c93zxdlUHRzDXH20AU6LR4eDvHOfghfGIsxsOTl56VKMCgYmpgbGxqmmJtbppqYJJkmAyPJ3DzZzCwpEejNtOQUSQYp3OZI4ZOUZuAChSl4BZa5DANLSVFpqiz4sEU5cOABAPn7n1o"><span class="s172"> Available Online</span></a></span></p>
<p class="p14"><span class="s203">Open Access</span><span class="s138"><br>
[Chinese.</span><span class="s204">A WGAN-Unet based...</span><span class="s89">|</span></p>
<p class="p183"><span class="s2"><br>
</span></p>
<p class="p184"><span class="s205"><br>
<span class="Apple-converted-space"> </span></span><span class="s206">2023 4. patent news</span><span class="s207"><br>
<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV3dS8MwEA9OX_amqPg1uAffyuq2ZusCU1BxqCAMnPg40iyV6VbBVd_9z727dFn1wY8HX0Kbtunxy3EJl7vfCRG1wkb9i00wkbJdyupMkjiRNm4aJZOOlpFMO20tffaYC4dyJdzmn2Kk_nXmsQ_nnjJp_zD7flDswGvUAWxRC7D9lR5Q5EVwPSFvxoOrlk3GYkbnBXRn55Zo-iki4HR5ls3Bh477uK9fpzmapdy6ouI3XHI6OMPVb0wnDfeaEzapaCZReeZeix7LRQWCqwHb0xC_905JVrsh0XygaIUQ5bQL8kS0IgrFcrmYrDtcWyRgUi183Xv1gsFbHnKMEpGZz8YTkx_brH53WxGVuCh449fAuFi3huuiSj-cck7Thlix2aZ4J8SgQAwYMSgQgwIxcMJCCTFAxIARA0YMPGLgEANGDPC-N9MvTycl3HpH3AML-LbEYf9ieH5ZX4g8IkLpFPcZ81ELTR9ulztt1dgWq9lzZncE2KbpGtxVahlbmaZSRUaqprQqUqk2Zrwrat8OtffD831RXc7EgVhLUWttjQkwPwDPOShe"><span class="s208">Univ Jiliang China Submits Chinese Patent Application for Early Fault Detection Method Based on <b>Wasserstein</b>...</span></a><br>
</span><span class="s209">Global IP News. Measurement &amp; Testing Patent News, 03/2023</span><span class="s210"><br>
</span><span class="s211"><b>Newsletter</b><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV3dS8MwEA9OX_amqPg1uAffyuq2ZusCU1BxqCAMnPg40iyV6VbBVd_9z727dFn1wY8HX0Kbtunxy3EJl7vfCRG1wkb9i00wkbJdyupMkjiRNm4aJZOOlpFMO20tffaYC4dyJdzmn2Kk_nXmsQ_nnjJp_zD7flDswGvUAWxRC7D9lR5Q5EVwPSFvxoOrlk3GYkbnBXRn55Zo-iki4HR5ls3Bh477uK9fpzmapdy6ouI3XHI6OMPVb0wnDfeaEzapaCZReeZeix7LRQWCqwHb0xC_905JVrsh0XygaIUQ5bQL8kS0IgrFcrmYrDtcWyRgUi183Xv1gsFbHnKMEpGZz8YTkx_brH53WxGVuCh449fAuFi3huuiSj-cck7Thlix2aZ4J8SgQAwYMSgQgwIxcMJCCTFAxIARA0YMPGLgEANGDPC-N9MvTycl3HpH3AML-LbEYf9ieH5ZX4g8IkLpFPcZ81ELTR9ulztt1dgWq9lzZncE2KbpGtxVahlbmaZSRUaqprQqUqk2Zrwrat8OtffD831RXc7EgVhLUWttjQkwPwDPOShe"><span class="s212">Citation Online</span></a></span><span class="s207"><br>
<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV1LT8MwDI4YXHYDAeI1yQdu0QZbw7pKgwMIBAekAUUcpzZLGdrWTu0A8QP439hu2g0OPA5coiqtkuiz61iJ7U8Ip9U4rH-xCdrxTIeyOsPQDZVxm9pTYTtQjoraR4Eqs8fycKicwi37FCP1r5LHPpQ9ZdL-QfrloNiBz6gD2KIWYPsrPaDIC3mDG9TwOUDLYEYZleXnkkxJKm8TuoqPH4mAaEgOJzuf9k_n0LxrppiWp7jbDehm4SHgBE0iyURjNZ0N6Y6KmEek_0pXRWnM_GrjRa83JxaQVz22qQ3pJ8k4syEePG36VixqMe2CTiJazjwUi3WHuUUkF9XCz8tTPdl7mTU4RomKmU8GT3p2bOL6_V1FVFxLeFPugR27b_mrokoTjjmnaU0smXhdvBNiYBEDRgzyxQEiBgViYJcOjBjMEYMcMWDEIImhOwnS0ckCbt0D7gGGDyx8UMAHDN-G2L84988u68Wy-1RUOkJfI-u3KG8XnWp0IzfFcpzEZkuAaeqORs8yUK5RUaQ8RyuvqYzneFGg9WBb1L4daueH97uiOpfGnliJUHNNjYtgfgCgViof"><span class="s208">Univ Qinghua Seeks Patent for Rotating Machine State Monitoring Method Based on <b>Wasserstein</b>...</span></a><br>
</span><span class="s209">Global IP News. Tools and Machinery Patent News, 03/2023</span><span class="s210"><br>
</span><span class="s211"><b>Newsletter</b><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV1LT8MwDI4YXHYDAeI1yQdu0QZbw7pKgwMIBAekAUUcpzZLGdrWTu0A8QP439hu2g0OPA5coiqtkuiz61iJ7U8Ip9U4rH-xCdrxTIeyOsPQDZVxm9pTYTtQjoraR4Eqs8fycKicwi37FCP1r5LHPpQ9ZdL-QfrloNiBz6gD2KIWYPsrPaDIC3mDG9TwOUDLYEYZleXnkkxJKm8TuoqPH4mAaEgOJzuf9k_n0LxrppiWp7jbDehm4SHgBE0iyURjNZ0N6Y6KmEek_0pXRWnM_GrjRa83JxaQVz22qQ3pJ8k4syEePG36VixqMe2CTiJazjwUi3WHuUUkF9XCz8tTPdl7mTU4RomKmU8GT3p2bOL6_V1FVFxLeFPugR27b_mrokoTjjmnaU0smXhdvBNiYBEDRgzyxQEiBgViYJcOjBjMEYMcMWDEIImhOwnS0ckCbt0D7gGGDyx8UMAHDN-G2L84988u68Wy-1RUOkJfI-u3KG8XnWp0IzfFcpzEZkuAaeqORs8yUK5RUaQ8RyuvqYzneFGg9WBb1L4daueH97uiOpfGnliJUHNNjYtgfgCgViof"><span class="s212">Citation Online</span></a></span><span class="s207"><br>
</span><span class="s213"> Quick Look</span><span class="s207"><br>
<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV3NT8IwFG9EL94wavxM3kUvEwRWGE3QBI1ETEhIxOiNdKUjqJuEDe_-577Xzm14woOXZm2apv31rW3ex-8x5jaqtcqvM0G5QrcpqtP3PZ9rr64E91uSuzxoNSXPosesO5TNhBev-Ej9685jG-49RdL-YfezQbEBv1EGsEQpwHItOSDPC-dhRtqMqc2WTYdFSPYCqulYE00_eQR0c1u2cT603Mc9uXxP8FhKtE0qPjApp50bvP0mZGl4liZgk5JmEpVnkknRazGpgNMfmvOUFBCDXC1pBG9ERB84uXQaxcAL0kU0XHLGstGYRnpMdhHH0Gph90yv5ww_k2rmpbRCef3S91YbLRUvPXPIPtQ8JwL0cDJTyZWOKk-PJVZqiHZ6feKdKdJ7blRmZZreXM71AroW7B22oaNd9kVAQwo0GKAhBRpSoMGuEApAAwINBmgwQEMGNFigwQANWO-EcvF2XYC7c2la4Af1PXbRuxvd3ldo1uM0uygWMelf4qlcxvE4X3Ntn21GH5E-YKDrqq3wUSq5p3kQcOEqLupcC1cEUqnJITtba8ijNfsds-18W0_YVoA_gT41fJrfyKVCxw"><span class="s208">Univ Jiliang China Submits Chinese Patent Application for Early Fault Detection Method Based on <b>Wasserstein</b>...</span></a><br>
</span><span class="s209">Global IP News: Measurement &amp; Testing Patent News, Mar 15, 2023</span><span class="s210"><br>
</span><span class="s211"><b>Newspaper Article</b><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV3NT8IwFG9EL94wavxM3kUvEwRWGE3QBI1ETEhIxOiNdKUjqJuEDe_-577Xzm14woOXZm2apv31rW3ex-8x5jaqtcqvM0G5QrcpqtP3PZ9rr64E91uSuzxoNSXPosesO5TNhBev-Ej9685jG-49RdL-YfezQbEBv1EGsEQpwHItOSDPC-dhRtqMqc2WTYdFSPYCqulYE00_eQR0c1u2cT603Mc9uXxP8FhKtE0qPjApp50bvP0mZGl4liZgk5JmEpVnkknRazGpgNMfmvOUFBCDXC1pBG9ERB84uXQaxcAL0kU0XHLGstGYRnpMdhHH0Gph90yv5ww_k2rmpbRCef3S91YbLRUvPXPIPtQ8JwL0cDJTyZWOKk-PJVZqiHZ6feKdKdJ7blRmZZreXM71AroW7B22oaNd9kVAQwo0GKAhBRpSoMGuEApAAwINBmgwQEMGNFigwQANWO-EcvF2XYC7c2la4Af1PXbRuxvd3ldo1uM0uygWMelf4qlcxvE4X3Ntn21GH5E-YKDrqq3wUSq5p3kQcOEqLupcC1cEUqnJITtba8ijNfsds-18W0_YVoA_gT41fJrfyKVCxw"><span class="s212">Citation Online</span></a></span><span class="s207"><br>
<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV1LT8JAEN74uBgvGDU-k7nopYJAF0oTNFGjkYMJKkZvZFu2YICWtKDxB_i_nZkuBTzhwcum2Wy2u99ud6azM_MJYZcLxfyvM8G3XV2jqE7PczypnZLvSq-qpC2DakXJLHosdYdKmfCSBR-pf115rMO1p0jaP6x-1ilW4DPuASxxF2C51D4gzwvrEQVUb6LwZND9hNLyc0qmKLaeIrqKD7tEQNQjhZOVT_Ols2veA1NMW9co7Tp0s_CqOECTSDLxsBqNe3RHRcwjVuuTrorikPnVBvNab0osYDWafKayRT-KBolx8uAXx1_TYc0HXpAtomzPnLF49zC7iMVptbB5Ztezmh_jQualtJDy-q3hLFamqXgd1NrsCv4enlIC9GHn3R9f6DD_8rwqVstuzYjPTZKXRtC1ciJH4xupkY7hKkV7S6zocFt8E9JgkAZGGtIpASINU6TBTBgYaZghDSnSwEhDFEJ9qOL-5Rze9XOuAYYdDOwwhR0Y9h1xdnfburnP09DbhmIUi4SMMElXTZKkPZt4cVeshVGo9wTokl_zUTNV0tEyCKRr-9ItSe3abqB8v7MvTpbq8mDJdodiY7a2R2I9wC9BH3NSzR8waUTS"><span class="s208">Univ Qinghua Seeks Patent for Rotating Machine State Monitoring Method Based on <b>Wasserstein</b>...</span></a><br>
</span><span class="s209">Global IP News: Tools and Machinery Patent News, Mar 1, 2023</span><span class="s210"><br>
</span><span class="s211"><b>Newspaper Article</b><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV1LT8JAEN74uBgvGDU-k7nopYJAF0oTNFGjkYMJKkZvZFu2YICWtKDxB_i_nZkuBTzhwcum2Wy2u99ud6azM_MJYZcLxfyvM8G3XV2jqE7PczypnZLvSq-qpC2DakXJLHosdYdKmfCSBR-pf115rMO1p0jaP6x-1ilW4DPuASxxF2C51D4gzwvrEQVUb6LwZND9hNLyc0qmKLaeIrqKD7tEQNQjhZOVT_Ols2veA1NMW9co7Tp0s_CqOECTSDLxsBqNe3RHRcwjVuuTrorikPnVBvNab0osYDWafKayRT-KBolx8uAXx1_TYc0HXpAtomzPnLF49zC7iMVptbB5Ztezmh_jQualtJDy-q3hLFamqXgd1NrsCv4enlIC9GHn3R9f6DD_8rwqVstuzYjPTZKXRtC1ciJH4xupkY7hKkV7S6zocFt8E9JgkAZGGtIpASINU6TBTBgYaZghDSnSwEhDFEJ9qOL-5Rze9XOuAYYdDOwwhR0Y9h1xdnfburnP09DbhmIUi4SMMElXTZKkPZt4cVeshVGo9wTokl_zUTNV0tEyCKRr-9ItSe3abqB8v7MvTpbq8mDJdodiY7a2R2I9wC9BH3NSzR8waUTS"><span class="s212">Citation Online</span></a></span><span class="s214"><br>
<span class="Apple-converted-space"> </span></span><span class="s115"><span class="Apple-tab-span">	</span></span></p>
<p class="p115"><span class="s215"><a href="https://www.proquest.com/docview/2789678053/7511C9CB3E7B468FPQ/13?accountid=13158"><br>
</a></span><span class="s124">2023 5. -patent news Wire Feed</span><span class="s4"><br>
<a href="https://www.proquest.com/docview/2789678053/7511C9CB3E7B468FPQ/13?accountid=13158"><span class="s216">Wuxi Cansonic Medical Science &amp; Tech Seeks Patent for FC-VoVNet and WGAN-Based B Ultrasonic Image Denoising Method</span></a></span><span class="s15"><br>
</span><span class="s124"><b>Global IP News. Optics &amp; Imaging Patent News; New Delhi</b> [New Delhi]. 23 Mar 2023.  </span></p>
<p class="p185"><span class="s1"><a href="https://www.proquest.com/docview/2789678053/citation/7511C9CB3E7B468FPQ/13?accountid=13158">Details</a><a href="https://www.proquest.com/docview/2789678053/fulltext/7511C9CB3E7B468FPQ/13?accountid=13158"><span class="s217">Full text</span></a></span></p>
<p class="p14"><span class="s18">Wuxi Cansonic Medical Science &amp; Tech Seeks Patent for FC-VoVNet and WGAN-Based B Ultrasonic Image Denoising Method</span></p>
<p class="p77"><span class="s218"><a href="https://www.proquest.com/pubidlinkhandler/sng/pubtitle/Global+IP+News.+Optics+$26+Imaging+Patent+News/$N/2028757/DocView/2789678053/fulltext/F49EFE3589B2400BPQ/1?accountid=13158"><b>Global IP News. Optics &amp; Imaging Patent News</b></a></span><span class="s129"><b>; New Delhi</b> [</span><span class="s4"><br>
</span><span class="s129">The patent application number is CN202011617451 2</span><span class="s4"><br>
<span class="Apple-converted-space"> </span><br>
</span><span class="s219"><span class="Apple-converted-space"> </span></span><span class="s135"><br>
</span><span class="s220"><span class="Apple-converted-space"> </span>2023 6 patent news see journal article</span><span class="s135"><br>
<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV1NT8JAEJ0oXjipUeMXZg4e9FBpu6X0gBoVCBciRBMTL2TpTpUgrXz0oAf_kf_RnYWKGKMXr52ku9lO3s50Zt4DEO6JbX3DBJ2AybArAlt4QZc4JyFP2sRaSbIrTU_N13aodjYaM_vcGUoa6FZJyH_Ni26Zazo6ZXDOn4cW60hxvTUT1ZAzsQV16ginFCzDCrses-u3SveLwOvNQLK-Cm_ZwvQqjWDhD1nrIl3jv-5yDfKMbU9mkmcdlijegPd2qqPExyTFz_YBTCKsDdOe6SjCZvSAGmUGvckYWXSbxoQtHahq08W8CI46BsbKQI76Z3fSTHKymmalaJ5glYNV7WXWpb47FU65PV_w5rqBRybq5SWng1HHWNPbmM5VYtPIXKOMFVaJoW0TDuu126uGlR1GhymXI30TjzvzoxBbkIuTmLYBtcWTZVK-cMgL7ZJ0PeEGkfIj4YeK_B0o_Pqq3T_se5BnhXguADn2PuQmo5QKhiHywLjCB4P42Io"><span class="s221">Quanzhou Institute of Equipment Mfg Submits Chinese Patent Application for Wasserstein...</span></a><br>
</span><span class="s129">Global IP News. Electrical Patent News, 04/2023</span><span class="s135"><br>
</span><span class="s129">Newsletter <a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwrV1NT8JAEJ0oXjipUeMXZg4e9FBpu6X0gBoVCBciRBMTL2TpTpUgrXz0oAf_kf_RnYWKGKMXr52ku9lO3s50Zt4DEO6JbX3DBJ2AybArAlt4QZc4JyFP2sRaSbIrTU_N13aodjYaM_vcGUoa6FZJyH_Ni26Zazo6ZXDOn4cW60hxvTUT1ZAzsQV16ginFCzDCrses-u3SveLwOvNQLK-Cm_ZwvQqjWDhD1nrIl3jv-5yDfKMbU9mkmcdlijegPd2qqPExyTFz_YBTCKsDdOe6SjCZvSAGmUGvckYWXSbxoQtHahq08W8CI46BsbKQI76Z3fSTHKymmalaJ5glYNV7WXWpb47FU65PV_w5rqBRybq5SWng1HHWNPbmM5VYtPIXKOMFVaJoW0TDuu126uGlR1GhymXI30TjzvzoxBbkIuTmLYBtcWTZVK-cMgL7ZJ0PeEGkfIj4YeK_B0o_Pqq3T_se5BnhXguADn2PuQmo5QKhiHywLjCB4P42Io"><span class="s143"> Full Text Online</span></a></span><span class="s135"><br>
</span><span class="s124"><b>Wasserstein PAC-Bayes Learning: A Bridge Between Generalisation and Optimisation</b></span></p>
<p class="p8"><span class="s17"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtZ1NT8JAEIY3ohdvGDV-JnPRaGqxtrXUBE3Q1MCBiBGjN7LQLRJDQUr5V_5HZ3aX0nrCg5cNWZp-8Ay709l3Zxhz7Ipl_hoT8AWM93uObzmu3xP0TiJcbgmqlcR7XGpqcnIoVfUuKWik_pU89iF72kn7B_rZSbEDP6MNYItWgO1KdvCcovf3MU6LsoDgKx1KpZDRigY0eoxoAYGKaYtEUN5--qq-XNyWasQ3LvdmUn1Myto5I4Mx73EaDA2VphPHoacG-azShZVrBFJeRqGHAK-utkkaLVm1Woug51p8t_CQVRECo9mW4y8FLAJZqUcak76x_N4MClfYDq28aOEqGZgsQGLIzFt4eBb6M9rzWSUTMhWyYr83q8VOla236qInW0UP45RypI_CYX92K2Lz9aXESvaNr2dYnFY9PQV2yqxMtzfhEzGFuuKxxdZEvM2-FywgYwHjCDIWgCxAswDNAtQjQ44FIAuojfj08y5HpHYpe6AIBjQYQDBwJrHQJRWWc1hCAQUFEAooKDvs4jHoPDRMesKuLlaKTULhnGTA0yTpLn8fa5etx-NY7DFAf8jlVRF6zpVw-9Y1t13H9qPQixyvHwpvn52sdMqDFY87ZJtLEzhiGxH-p8SxTM_5A4ZPXz4">Quanzhou Institute of Equipment Mfg Submits Chinese Patent Application for Wasserstein...</a></span><span class="s20"><br>
</span><span class="s93">Global IP News: Electrical Patent News, Apr 10, 2023</span><span class="s20"><br>
</span><span class="s93">Newspaper Article</span><span class="s89"><br>
</span></p>
<p class="p77"><span class="s222"><span class="Apple-converted-space"> </span>2023 7 patent news see2022 patent</span><span class="s2"><br>
<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV3NS8MwFA9OL94UFT8hF73UzdpmbQdTGOJwt8Em7jayNp1F1461U_wb_Kd9L8my1tM8eAnlER7p773kJY_3QYjrNOz6rzMBHmA8nLiB7bJgIvBNIhi3BfZK4hMuY2pK4VCqvWNeiZH6V8kDDWSPmbR_kL5hCgT4Bh2AEbQAxo30YJTwzOouv5awkdWVU1ZgwNr8MgxAU0NzdVz1GbVeuEzFxHaYWKSzkMkFnfdptkiK15l0lMg8TRnRAcdKliJDlfkba4blu69qL2D1-vJkRVfEAGzAJ4ae6cWUcy7QDeG4MnqlaRRHNhaxZEUtmG5celb_o2iYAKVKtetRz68SVRVenzHmwxurdYW1z2dREhZ3Iq0_D2qk5rQCbTnBXDa1aRvukT1c3pzPxYJ2FM77ZEukB-QbMaYKY6oxpoAxVb9FM01VkNAspiuMaXvGF2_3JaTbN5JCV4BTAzhNgI0EHDkYwGkV8ENy3X0cPjzVcf1j3WIUhhydMPmUL_N8vP57-4hsp8DmmFC4xTDui8hzbwUL7SZ3mOsEceTFrhdGwjshlxuxPN1w3hnZXQv4nOzEsBPEhSyq-QMtE0Z0"><span class="s223">Xiao Fuyuan Applies for Patent on Application of Evidence Wasserstein...</span></a><br>
</span><span class="s18">Global IP News: Software Patent News, Apr 5, 2023</span><span class="s2"><br>
</span><span class="s18">Newspaper Article<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV3NS8MwFA9OL94UFT8hF73UzdpmbQdTGOJwt8Em7jayNp1F1461U_wb_Kd9L8my1tM8eAnlER7p773kJY_3QYjrNOz6rzMBHmA8nLiB7bJgIvBNIhi3BfZK4hMuY2pK4VCqvWNeiZH6V8kDDWSPmbR_kL5hCgT4Bh2AEbQAxo30YJTwzOouv5awkdWVU1ZgwNr8MgxAU0NzdVz1GbVeuEzFxHaYWKSzkMkFnfdptkiK15l0lMg8TRnRAcdKliJDlfkba4blu69qL2D1-vJkRVfEAGzAJ4ae6cWUcy7QDeG4MnqlaRRHNhaxZEUtmG5celb_o2iYAKVKtetRz68SVRVenzHmwxurdYW1z2dREhZ3Iq0_D2qk5rQCbTnBXDa1aRvukT1c3pzPxYJ2FM77ZEukB-QbMaYKY6oxpoAxVb9FM01VkNAspiuMaXvGF2_3JaTbN5JCV4BTAzhNgI0EHDkYwGkV8ENy3X0cPjzVcf1j3WIUhhydMPmUL_N8vP57-4hsp8DmmFC4xTDui8hzbwUL7SZ3mOsEceTFrhdGwjshlxuxPN1w3hnZXQv4nOzEsBPEhSyq-QMtE0Z0"><span class="s143">Citation Online</span></a></span><span class="s89"><br>
</span><span class="s224"> Evidence Wasserstein Distance Algorithm in Aspect of Component</span></p>
<p class="p117"><span class="s15"><br>
2023 8. patent news. Wire Feed<br>
<a href="https://www.proquest.com/docview/2799012821/F3D05E593AF74FCBPQ/7?accountid=13158"><span class="s145">Quanzhou Institute of Equipment Mfg Submits Chinese Patent Application for Wasserstein Distance-Based Battery SOH (State of Health) Estimation Method and Device</span></a><br>
<b>Global IP News. Electrical Patent News; New Delhi</b> [New Delhi]. 10 Apr 2023.  <br>
</span><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p117"><span class="s15">2023 9. patent news Wire Feed<br>
<a href="https://www.proquest.com/docview/2795967135/F3D05E593AF74FCBPQ/10?accountid=13158"><span class="s145">Xiao Fuyuan Applies for Patent on Application of Evidence Wasserstein Distance Algorithm in Aspect of Component Identification</span></a><br>
<b>Global IP News. Software Patent</b></span></p>
<p class="p42"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s2">2023 10<span class="Apple-converted-space">  </span>patent<br>
<a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV1LT8JAEN6IXrhp1PgimRBNNASFbZdHgiaGIHjwYkGPZOmWBIWCvPQf-TedmT6wHnwcvDRkaZb222X6dWe_b4Sw5Hkh_yUmGHwO2kg1JFe5UmWN7x2W6euSqtqWq02kHgu2QwUlNGeJPVL_OvLYhmNPSto_jH7cKTbgZ5wDeMRZgMdfzYOOQzb8lPHnQnuGyGa92cw5jfuH23rDoWzB9WQ6GOak4j2HJ1LecVnpwL3ZeBxLyN-Y-C1rGo2e8I6jl4U2U7Z8fdQs26TSmTla0c-_6qVH5-cG_jJYksN-ic62vTc9Y3sPnwr9RCsRT_HV3uA1UuiNwlgYxYYLlt_gCcyPE_oMWrKQFmVfAl08T7JWm7JnVBOFU-_kPBGpucjvfGQG7vzS8_MdJyVSCXf_iqyqQjH52FQhF2hvijT99JBlUFtizfO3xXvHgQBkCECG-RgQZIhAhrEPDDJIBQgLZEOIASGGEGJYQQwRxBBDDLWRnj5ffQK6dsEtkMAbYryzcMpYQ4z12Y44vmm06618dGNdcqruI4GZdWUFSapVKlt2YVes-2Pf2xPgKq2k3asUXeTAxHHxtd7VWvV6rls0yt4XmW-7Ovjh-0ORXo3ckdjo49_By7Cz5geRk0CT"><span class="s26">US Patent Issued to CGG SERVICES on April 25 for<span class="Apple-converted-space"> </span></span></a></span></p>
<p class="p186"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwtV1LT8JAEN6IXrhp1PgimRBNNASFbZdHgiaGIHjwYkGPZOmWBIWCvPQf-TedmT6wHnwcvDRkaZb222X6dWe_b4Sw5Hkh_yUmGHwO2kg1JFe5UmWN7x2W6euSqtqWq02kHgu2QwUlNGeJPVL_OvLYhmNPSto_jH7cKTbgZ5wDeMRZgMdfzYOOQzb8lPHnQnuGyGa92cw5jfuH23rDoWzB9WQ6GOak4j2HJ1LecVnpwL3ZeBxLyN-Y-C1rGo2e8I6jl4U2U7Z8fdQs26TSmTla0c-_6qVH5-cG_jJYksN-ic62vTc9Y3sPnwr9RCsRT_HV3uA1UuiNwlgYxYYLlt_gCcyPE_oMWrKQFmVfAl08T7JWm7JnVBOFU-_kPBGpucjvfGQG7vzS8_MdJyVSCXf_iqyqQjH52FQhF2hvijT99JBlUFtizfO3xXvHgQBkCECG-RgQZIhAhrEPDDJIBQgLZEOIASGGEGJYQQwRxBBDDLWRnj5ffQK6dsEtkMAbYryzcMpYQ4z12Y44vmm06618dGNdcqruI4GZdWUFSapVKlt2YVes-2Pf2xPgKq2k3asUXeTAxHHxtd7VWvV6rls0yt4XmW-7Ovjh-0ORXo3ckdjo49_By7Cz5geRk0CT">"Methods and devices performing adaptive quadratic <span class="s225"><b>Wasserstein</b>...</span></a></span></p>
<p class="p73"><span class="s2">US Fed News Service, Including US State News, 04/2023</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s226">023 11<span class="Apple-converted-space">  </span>patent news<span class="Apple-converted-space">  </span>Wire Feed</span></p>
<p class="p187"><span class="s227"><a href="https://www.proquest.com/docview/2807322175/7B9F05AD20F1461EPQ/4?accountid=13158">CGG Services SAS Gets Patent for Methods and Devices Performing Adaptive Quadratic Wasserstein Full-Waveform Inversion<span class="s1"></span></a></span></p>
<p class="p5"><span class="s226"><b>Global IP News. Information Technology Patent News; New Delhi</b> [New Delhi]. 28 Apr 2023.  </span></p>
<p class="p188"><span class="s228"><span class="Apple-converted-space"> </span><a href="https://www.proquest.com/docview/2807322175/citation/7B9F05AD20F1461EPQ/4?accountid=13158"><span class="s229">Details</span></a><a href="https://www.proquest.com/docview/2807322175/fulltext/7B9F05AD20F1461EPQ/4?accountid=13158"><span class="s229">Full text</span></a></span></p>
<p class="p5"><span class="s15"><br>
</span><span class="s2"><br>
</span></p>
<p class="p14"><span class="s18">2023 12 <span class="Apple-converted-space">  </span>patent</span></p>
<p class="p189"><span class="s230"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:202342316D">Method for enhancing grid deformation data based on <span class="s231">Wasserstein</span><span class="s232"> generative adversarial network gradient penalty model used in image processing and data enhancement field, involves respectively warping medical endoscope image and deformation grid to obtain data enhanced medical endoscope image</span></a></span></p>
<p class="p5"><span class="s18">CN115937038-A</span></p>
<p class="p77"><span class="s129"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22SHEN%20N%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s232">SHEN N</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22HU%20P%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s229">HU P</span></a> and <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22LI%20J%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s229">LI J</span></a></span></p>
<p class="p5"><span class="s30"><b>Assignee(s) </b></span><span class="s18">UNIV SHANGHAI</span></p>
<p class="p14"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p104"><span class="s2">2023-42316D</span></p>
<p class="p168"><span class="s15"><br>
<br>
2023 13 patent news<br>
<a href="https://duke.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwvV1NT8JAEJ0oXDipUeMXZA5eCw0t7TZBCSJgYjRVTEi8kG27XoSCLfgH_Bf-Wme2bhQPevPYbTvJtpM3s7vz3gA4zbpt_cAEx28FLFUVsCKgjChoRTJSrmhJ37Njzav9zhGbG2rM5-82KKmhO5nHvGveYB0XckeKf53Fi8V9pPi81TTVMBY0CyCeEnTougCz5KShfNbJ8iw-cx2C8DI7Jmvvh63HNVgmSDYoPNiCd2NWl1rXi1KTYtNhrQbbiDn-4xy2ocK4ONUsoB3YUOkuvPWGQzSgg6PuCIdqmWNIaWy6RMqK8Ub3qc5RpglequK5sKAsUOjEbiIXDLt4t5IJu2SM7ZnMns_HUrNBuSNnu6FHkNfM1li-Kn4ZWSZEb_jtwemg_9C7sswHmLAI8xPF5nzyNX1nH0rpPFUHgI4QSeD5ru3EtutzvBSeH0VPXkLpWiDsQ6j-auroj_vHUOGe8Xwk1BQnUFpmK1UtekHUYFMM-jUoX_Rvw3u6uvatmvaJD2DX4TE"><span class="s178">CGG Services SAS Gets Patent for Methods and Devices Performing Adaptive Quadratic <b>Wasserstein</b> Full-Waveform Inversion</span></a><br>
</span><span class="s30">Global IP News. Information Technology Patent News, 04/2023</span><span class="s15"><br>
</span><span class="s30"><b>Newsletter</b> <a href="https://duke.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwvV1NT8JAEJ0oXDipUeMXZA5eCw0t7TZBCSJgYjRVTEi8kG27XoSCLfgH_Bf-Wme2bhQPevPYbTvJtpM3s7vz3gA4zbpt_cAEx28FLFUVsCKgjChoRTJSrmhJ37Njzav9zhGbG2rM5-82KKmhO5nHvGveYB0XckeKf53Fi8V9pPi81TTVMBY0CyCeEnTougCz5KShfNbJ8iw-cx2C8DI7Jmvvh63HNVgmSDYoPNiCd2NWl1rXi1KTYtNhrQbbiDn-4xy2ocK4ONUsoB3YUOkuvPWGQzSgg6PuCIdqmWNIaWy6RMqK8Ub3qc5RpglequK5sKAsUOjEbiIXDLt4t5IJu2SM7ZnMns_HUrNBuSNnu6FHkNfM1li-Kn4ZWSZEb_jtwemg_9C7sswHmLAI8xPF5nzyNX1nH0rpPFUHgI4QSeD5ru3EtutzvBSeH0VPXkLpWiDsQ6j-auroj_vHUOGe8Xwk1BQnUFpmK1UtekHUYFMM-jUoX_Rvw3u6uvatmvaJD2DX4TE"><span class="s233"> Full Text Online</span></a></span><span class="s15"><br>
<br>
<span class="Apple-converted-space"> </span></span></p>
<p class="p168"><span class="s30">2023 14 patent news</span><span class="s15"> <br>
<a href="https://duke.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwvV1LSwMxEB5se-lJRcVXyxy89rnPQLVY20UEpajgsaRpVortVne3P8C_4a81MzVURfTmMVkYGHb4ZpJ8Mx-A0643a98wwQk8QaOqBE0ElGOTtMZyrN3Qk4HfVNxX-7lHbGFbYz5-t0VJhu7JQtGteaNtYs3UJ74nus8vNdKRovdWK6phLXAXgJoZ6GBegD1ymq1s3k2zVJ26jluAEgWmx9S_ux9gmTA32oQ3a5WZ1vUV02R15_CFgm1nOf6jC1tQJliccRPQNmzoZAdeidyBV1O6MHlEFuRGg0fzaZ7xSmcah6akTXI8Xz-Xo6mWkccrYySXsxz7OmdaWILXrGqNPZNgJ2jWnblMn84eJHeGkjpnp8E72Kfi10TtLpxEg_uLy5p1f0QTmGOTmLPR2nlnD4rJItH7gMqRvuOHcUvEsTsROhQq0IEypzKvKcNYHEDlV1OHf3w_gjIJxhOLrOUdQzFPl7qyEoKoQiGMBlUo9QY3w9sqh8I76UzhDQ"><span class="s178">Univ Jiliang China Submits Chinese Patent Application for Early Fault Detection Method Based on <b>Wasserstein</b> Distanc</span></a><br>
</span><span class="s30">Global IP News. Measurement &amp; Testing Patent News, 03/2023</span><span class="s15"><br>
</span><span class="s30"><b>Newsletter</b> <a href="https://duke.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwvV1LSwMxEB5se-lJRcVXyxy89rnPQLVY20UEpajgsaRpVortVne3P8C_4a81MzVURfTmMVkYGHb4ZpJ8Mx-A0643a98wwQk8QaOqBE0ElGOTtMZyrN3Qk4HfVNxX-7lHbGFbYz5-t0VJhu7JQtGteaNtYs3UJ74nus8vNdKRovdWK6phLXAXgJoZ6GBegD1ymq1s3k2zVJ26jluAEgWmx9S_ux9gmTA32oQ3a5WZ1vUV02R15_CFgm1nOf6jC1tQJliccRPQNmzoZAdeidyBV1O6MHlEFuRGg0fzaZ7xSmcah6akTXI8Xz-Xo6mWkccrYySXsxz7OmdaWILXrGqNPZNgJ2jWnblMn84eJHeGkjpnp8E72Kfi10TtLpxEg_uLy5p1f0QTmGOTmLPR2nlnD4rJItH7gMqRvuOHcUvEsTsROhQq0IEypzKvKcNYHEDlV1OHf3w_gjIJxhOLrOUdQzFPl7qyEoKoQiGMBlUo9QY3w9sqh8I76UzhDQ"><span class="s233"> Full Text Online</span></a></span><span class="s15"><br>
<br>
2023 15 patent news <br>
<a href="https://duke.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwvV3JTsMwEB1Be-kJECC2Rj5wTRvirFKhYmmEhIQqhATiUjluDBVZIGkPfAN_wNficWJBOcCNY5zkKXGs57Ezbx4AtXuW-YMTqO-GWKoqxIqALJaTVszixAlc5nsWV7ra7xqxQktjms-tWVJR97TguGvet9Em20OLueHLq4k-Uvi_VZtqaASlAuCppA6VF6CXnLKpyoZlVfJjh0oKb-PAxNr7Y_dhmZZtzcbRGnxoVJVp3aszTeo9h6UUbF3L8R9fYR06SIupEgFtwEqSb8L7_YwVJFq8LVhO6qi2IjIWJmMZx-ZzUjSt9eYgKQTRVqZkkLHy-eSOKc0n-m4O-qqFXGBYi1ecpo_ygedPGZlJGKULRQSksSJH9FppLBr0LTiMRrfnl6buiAnWYhZyiq4mX91At6GVy9t3gHDKPOoF4igUwpmGSRByP_G5XJ-5FgtEuAvdX6H2_ji_Dx20jldZOO4BtOblIunWlhAGrAbRyID22eh6fCOPrnzTUEPjE2bz5ic"><span class="s178">Xiao Fuyuan Applies for Patent on Application of Evidence <b>Wasserstein</b> Distance Algorithm in Aspect of Component Identification</span></a><br>
</span><span class="s30">Global IP News. Software Patent News, 04/2023</span><span class="s15"><br>
</span><span class="s30"><b>Newsletter</b> <a href="https://duke.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwvV3JTsMwEB1Be-kJECC2Rj5wTRvirFKhYmmEhIQqhATiUjluDBVZIGkPfAN_wNficWJBOcCNY5zkKXGs57Ezbx4AtXuW-YMTqO-GWKoqxIqALJaTVszixAlc5nsWV7ra7xqxQktjms-tWVJR97TguGvet9Em20OLueHLq4k-Uvi_VZtqaASlAuCppA6VF6CXnLKpyoZlVfJjh0oKb-PAxNr7Y_dhmZZtzcbRGnxoVJVp3aszTeo9h6UUbF3L8R9fYR06SIupEgFtwEqSb8L7_YwVJFq8LVhO6qi2IjIWJmMZx-ZzUjSt9eYgKQTRVqZkkLHy-eSOKc0n-m4O-qqFXGBYi1ecpo_ygedPGZlJGKULRQSksSJH9FppLBr0LTiMRrfnl6buiAnWYhZyiq4mX91At6GVy9t3gHDKPOoF4igUwpmGSRByP_G5XJ-5FgtEuAvdX6H2_ji_Dx20jldZOO4BtOblIunWlhAGrAbRyID22eh6fCOPrnzTUEPjE2bz5ic"><span class="s233"> Full Text Online</span></a></span><span class="s15"><br>
<span class="Apple-converted-space"> </span><br>
2023 16 patent news <br>
<a href="https://duke.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwvV1NTwIxEJ0IXDipUeMXZA5e-ZD9TlASBOJFg0DikZTSBcPSxV2Iv8A_4a-107UqHvTmtU0m2W7zZtq-Nw_AalTrlR-YYHlOQK2qAuoIyCYqaU3YRNi-wzy3zrWu9rtGLDbSmI_fbVBSQ_c05nRrXmuQSFJVMI7bWj1XyEeK3luNqYaJoFUAPFLQoXkB5siphtJlK0kTfmVbdg4KtDEdTf0bbsPyJxr3duHNRNVM62rGNMnuHLYo2KaX4z9-wh4UCRYjLQLahx0hD-CVyB34oHLgfMNwKMQixb4qYeUaVUWMg5he--UM7zRvU6CubzEDk0RPaBdrbKuEOsVYYnPJksX1I9NKUHLjbNb0CHbEaj3HztOMnE5w9EJPU4lE8nOLDuGi1x3d3FbMEoypC3OoknM6_loA6wjyMpbiGJBbzLVcP7wMwtCeBsIPuCc8rk5mTp35YXACpV9Dnf4xfwZFMo3PmGTnkF8nG1HKzCDKkPN73TIU2t37_qCst8M7YsniJQ"><span class="s178">Univ Qinghua Seeks Patent for Rotating Machine State Monitoring Method Based on <b>Wasserstein</b> Depth Digital Twinborn Model</span></a><br>
</span><span class="s30">Global IP News. Tools and Machinery Patent News, 03/2023</span><span class="s15"><br>
</span><span class="s30"><b>Newsletter</b> <a href="https://duke.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwvV1NTwIxEJ0IXDipUeMXZA5e-ZD9TlASBOJFg0DikZTSBcPSxV2Iv8A_4a-107UqHvTmtU0m2W7zZtq-Nw_AalTrlR-YYHlOQK2qAuoIyCYqaU3YRNi-wzy3zrWu9rtGLDbSmI_fbVBSQ_c05nRrXmuQSFJVMI7bWj1XyEeK3luNqYaJoFUAPFLQoXkB5siphtJlK0kTfmVbdg4KtDEdTf0bbsPyJxr3duHNRNVM62rGNMnuHLYo2KaX4z9-wh4UCRYjLQLahx0hD-CVyB34oHLgfMNwKMQixb4qYeUaVUWMg5he--UM7zRvU6CubzEDk0RPaBdrbKuEOsVYYnPJksX1I9NKUHLjbNb0CHbEaj3HztOMnE5w9EJPU4lE8nOLDuGi1x3d3FbMEoypC3OoknM6_loA6wjyMpbiGJBbzLVcP7wMwtCeBsIPuCc8rk5mTp35YXACpV9Dnf4xfwZFMo3PmGTnkF8nG1HKzCDKkPN73TIU2t37_qCst8M7YsniJQ"><span class="s233"> Full Text Online</span></a></span><span class="s15"><br>
</span></p>
<p class="p168"><span class="s30"><span class="Apple-converted-space"> </span></span><span class="s15"><br>
2023 17 patent news <br>
<a href="https://duke.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwvV1NT8JAEN0YuHBSo8YvyIR40EOhtJS2CUqUFOSAIqAeydJuEyK0pQX0t_gH_JvubN0IHvTmdZpu0-30ze7OvHmE6FpJVX5ggm4aNraqsrEjIB3zoDWmY1a1DGrWVFfwatc5YqGkxnx9bomSArq90MVT87Jm8eCt10y92ojmCupIYb5VimrIEQQLwJ1y6BB1AXLLyU3JrBEnsXupI0c9y13bwD-kq92vh0fbUCubMF2V6NzaJu_yKaLyupRWnqRnEBsl2bK34z--0g7JIUxOBSlol2yxYI98PA6gx5ewwQKEtp8HixCa7TYMnP5Tp-kMIAzgOoonU9AM4ItmKHaFjnUCNPDAYwK8IEopDTy0AvVohLAM8yX10GVdqM9o_HL1TAVbFBU762VhAcwnKK90xfBmmASr9ECwCOdD9kYT6Igq-zBOLvbJWcsZNm8VOUkj7Nvs83CejL6nSD8gmSAM2CEBV6fcZvkV2_erns0s2zWZ6fK9nKFSy7ePSP7XoY7_uH5Ccigzj1kkrXZKMot4yfKpfESBZG-cu16_wF2n8lAQDvQJTaLw_Q"><span class="s178">US Patent Issued to CGG SERVICES on April 25 for "Methods and devices performing adaptive quadratic <b>Wasserstein</b> full-waveform...</span></a><br>
</span><span class="s30">US Fed News Service, Including US State News, 04/2023</span><span class="s15"><br>
</span><span class="s30"><b>Newsletter</b> <a href="https://duke.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwvV1NT8JAEN0YuHBSo8YvyIR40EOhtJS2CUqUFOSAIqAeydJuEyK0pQX0t_gH_JvubN0IHvTmdZpu0-30ze7OvHmE6FpJVX5ggm4aNraqsrEjIB3zoDWmY1a1DGrWVFfwatc5YqGkxnx9bomSArq90MVT87Jm8eCt10y92ojmCupIYb5VimrIEQQLwJ1y6BB1AXLLyU3JrBEnsXupI0c9y13bwD-kq92vh0fbUCubMF2V6NzaJu_yKaLyupRWnqRnEBsl2bK34z--0g7JIUxOBSlol2yxYI98PA6gx5ewwQKEtp8HixCa7TYMnP5Tp-kMIAzgOoonU9AM4ItmKHaFjnUCNPDAYwK8IEopDTy0AvVohLAM8yX10GVdqM9o_HL1TAVbFBU762VhAcwnKK90xfBmmASr9ECwCOdD9kYT6Igq-zBOLvbJWcsZNm8VOUkj7Nvs83CejL6nSD8gmSAM2CEBV6fcZvkV2_erns0s2zWZ6fK9nKFSy7ePSP7XoY7_uH5Ccigzj1kkrXZKMot4yfKpfESBZG-cu16_wF2n8lAQDvQJTaLw_Q"><span class="s233"> Full Text Online</span></a></span><span class="s234"><br>
</span><span class="s15"><span class="Apple-converted-space"> </span><br>
2023 18 patent news <br>
<a href="https://duke.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwvV1NT8JAEN0oXDipUeMXzRw86KFQKKVtghKREi4oiomJF7KUrRKhlZYe_Cv-B_-jM1tXxIPevO4m23a7eTu78948xsxqydB_YIJpWy6VqnKpIiAf4aY14iNRcyxu1w1f6mq_a8QiJY35_N0KJSV0jyOfbs3LVZtyOnhkqDRf5jr5SFG-VZlqqBGkCsCfInRIXoA6cmJTMmvGSeyf1UyE8DwtTKq937ceVmHZUmjc2WBvalTJtC5lTJPszmGFgq1qOf7jJ2yyAsHiVIqAttiaCLfZ-02KAeZTlMIX8wCiALx5OpFkJOgFj4AANZssEiC_bpEI6GOMi10Xy_w5YPgMjRmPn8_vuRSBkhFnoyxboE1xLi5QvYXb7hiysqCvMLjuwokMmOmRmabqFDx8jUySCT3pkA08HENbECrusOOOd3fZ1dVUDalac4CbeDJcTpS5y3JhFIo9Br7J62bdCSpuENTGrnBc3xa2jyc4y-BO4O6z4q9DHfzRf8gKZC5PuaOKccRyizgVxcw0QmPrTsfTWL7lXfVvNWKMDjS5eD4AsYbxsw"><span class="s178">Quanzhou Institute of Equipment Mfg Submits Chinese Patent Application for <b>Wasserstein</b> Distance-Based Battery SOH (State of...</span></a><br>
</span><span class="s30">Global IP News. Electrical Patent News, 04/2023</span><span class="s15"><br>
</span><span class="s30"><b>Newsletter</b> <a href="https://duke.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwvV1NT8JAEN0oXDipUeMXzRw86KFQKKVtghKREi4oiomJF7KUrRKhlZYe_Cv-B_-jM1tXxIPevO4m23a7eTu78948xsxqydB_YIJpWy6VqnKpIiAf4aY14iNRcyxu1w1f6mq_a8QiJY35_N0KJSV0jyOfbs3LVZtyOnhkqDRf5jr5SFG-VZlqqBGkCsCfInRIXoA6cmJTMmvGSeyf1UyE8DwtTKq937ceVmHZUmjc2WBvalTJtC5lTJPszmGFgq1qOf7jJ2yyAsHiVIqAttiaCLfZ-02KAeZTlMIX8wCiALx5OpFkJOgFj4AANZssEiC_bpEI6GOMi10Xy_w5YPgMjRmPn8_vuRSBkhFnoyxboE1xLi5QvYXb7hiysqCvMLjuwokMmOmRmabqFDx8jUySCT3pkA08HENbECrusOOOd3fZ1dVUDalac4CbeDJcTpS5y3JhFIo9Br7J62bdCSpuENTGrnBc3xa2jyc4y-BO4O6z4q9DHfzRf8gKZC5PuaOKccRyizgVxcw0QmPrTsfTWL7lXfVvNWKMDjS5eD4AsYbxsw"><span class="s233"> Full Text Online</span></a></span><span class="s15"><br>
<br>
2023 19<span class="Apple-converted-space">  </span>patent news <br>
<a href="https://duke.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwY2AwNtIz0EUrE4zNTS1BR1VZgk4ETEwCVlpJiUmpJhamieZmBsngfbXIe8TyYVtjoNENKyXBRXdKfjJo1FzfyMLAwsTIxMLA2L6gUBd0jxRovhV2qQbMBPAugOQcYNEBXhcA63IChYpz7YuKi5JtjUF71FkNTYA1OWjpn5E_arFsBiuN3QQYZsFMBa-01oOsNIGMOaAswYad5UhHLwgyCIKKxYLEgtQiBUdIqhNiYErNE2GwcAIN3QAb9sBC9FHDzGIFn_yyVAXw0ckKwUA3KXhkFiv4g9qbCt6ZKcUKwNaygoqhgYGvKIOGm2uIs4cuzPHxwLQHmlBIzEvNLy2ORzjfWIyBJS8_L1WCQSHZONHM2MwizdAyLc0kxTLVwjLZPNU8GdivMjVItEizlGRQJGicFBFqpBm4QFe_gxcfGskwsJQUlabKQq50kAP2zV2d5RhYnVz9AoKAtGuYn6OrHDhyAYiRzpw"><span class="s178">Billionaire’s Love Child Sues His Other Kids for $100M: Bruce <b>Wasserstein</b> died in 2009, but a feud over his assets rages on</span></a><br>
</span><span class="s30">by </span><span class="s18">Kirsch, Noah</span><span class="s15"><br>
</span><span class="s30">The Daily Beast, May 2, 2023</span><span class="s15"><br>
</span><span class="s30"><b>Newspaper Article</b> <a href="https://duke.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwY2AwNtIz0EUrE4zNTS1BR1VZgk4ETEwCVlpJiUmpJhamieZmBsngfbXIe8TyYVtjoNENKyXBRXdKfjJo1FzfyMLAwsTIxMLA2L6gUBd0jxRovhV2qQbMBPAugOQcYNEBXhcA63IChYpz7YuKi5JtjUF71FkNTYA1OWjpn5E_arFsBiuN3QQYZsFMBa-01oOsNIGMOaAswYad5UhHLwgyCIKKxYLEgtQiBUdIqhNiYErNE2GwcAIN3QAb9sBC9FHDzGIFn_yyVAXw0ckKwUA3KXhkFiv4g9qbCt6ZKcUKwNaygoqhgYGvKIOGm2uIs4cuzPHxwLQHmlBIzEvNLy2ORzjfWIyBJS8_L1WCQSHZONHM2MwizdAyLc0kxTLVwjLZPNU8GdivMjVItEizlGRQJGicFBFqpBm4QFe_gxcfGskwsJQUlabKQq50kAP2zV2d5RhYnVz9AoKAtGuYn6OrHDhyAYiRzpw"><span class="s233"> Full Text Online</span></a></span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2023. 20 PATENT</span></p>
<p class="p5"><span class="s2">Monitoring network pedestrian target association method based on maximum slice Wasserstein measurement</span></p>
<p class="p5"><span class="s2">JU LIWEI ; CHEN LIANG ; LI QI ; ZHANG JING</span></p>
<p class="p5"><span class="s2">2023</span></p>
<p class="p5"><span class="s2">OPEN ACCESS</span></p>
<p class="p190"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwfV3dT8IwEL8ofr4pahQ_Ul_2hmzdAJcwjXQQXwRiiD6Sri0RzQZhEI1P_uleO3DERF-vyyXX5nq_3n53B-DSK7v8606oykhgtFG8LqOa79Oq5J7DVdW_lkoqUy29Sod6XZbGmLah76ZXIjqYQPefmet7kue0QkO1TCvRCEXj23Y_CK3FYxnhtUNtK2wGrV437DKLsYB1rM5jgDio5uoy6rt12KC6RYlGUk9NXaQyWY0w7T3Y7KG2ZLYPa58vRdhhy0FsRdh-WPz_LsKWIWyKFIULp0wP4KsR8-nbTeadOk1HkozbTSZotZnLkZCM8U14fhokGx5NdByTjYrRQVCcaYv5xyiexwRhqFDkmZuqTD0Zc_llnCcXD-Gy3eqz-zIaNfjZwQHr5Pa7R1BIxok6BiKEcD3hUi7tyKtxxA6OihCg2ENhi7pDT6D0t57Sf4unsKtPQ6cuqH0Ghdl0rs5Nm8YLs-3fYrKmog">Monitoring network pedestrian target association method based on maximum slice Wasserstein measurement<span class="s235"></span></a></span></p>
<p class="p14"><span class="s138"><span class="Apple-converted-space"> </span></span><span class="s2"><br>
</span><span class="s4"><span class="Apple-converted-space"> </span></span></p>
<p class="p75"><span class="s2">2023 21<span class="Apple-converted-space">  </span>PATENT</span></p>
<p class="p75"><span class="s2">METHOD AND APPARATUS FOR CONDITIONAL DATA GENRATION USING CONDITIONAL WASSERSTEIN GENERATOR</span></p>
<p class="p75"><span class="s2">CHO MYUNG HEE ; LEE KYUNG BOK ; KIM YOUNG GEUN</span></p>
<p class="p75"><span class="s2">2023</span></p>
<p class="p75"><span class="s2">OPEN ACCESS</span></p>
<p class="p17"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwfV3dT4MwEL_o_HzTqfFjmiYmvM1tUDZJNk1H2UeWAYGqjwsUTMx0W7YZ3_3LLQWU-LAHHnpXmnDNtdfjd78CaOpdvfpvTdCjkIvdJg5aUdg0DFWPAtwIYt24j-IoltXSRTjUe14aI2lDvyRXonAwLtx_LZfvxV9Oi0qo5aoWvgnR_LHHOlTJDssivBYRt0K7Hct1qGMqptkZeYrtpTrx4CYm27CjJiQlSSz13E3KVBbFPaZ3BLuuGG-2Poat6bwMB2Z-FVsZ9sfZH_Ay7EnIJl8JYeaWqxP4bn8Ey-nD2GIDh7ZrsoGITVEqJ65LPMKe_FwlTn6ZynRsOkz5cBEljKC-ZadpK5RcyNFHhQ752y_E9y3PZ9bQRinyjTneKdz2LGYOquKzJr9WnIy8og20MyjN5rP4HJCOgyZuRKGYFg0br_Ug5gbnoa7iJONR5xdQ2TTS5Wb1FRwmzQT33GhVoLRefsbXkrDxRpr_B_Fynn4">METHOD AND APPARATUS FOR CONDITIONAL DATA GENRATION USING CONDITIONAL WASSERSTEIN GENERATOR<span class="s95"></span></a></span></p>
<p class="p5"><span class="s15"><span class="Apple-converted-space"> </span></span><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2023 22<span class="Apple-converted-space">  </span>PATENT</span></p>
<p class="p5"><span class="s2">Wasserstein distance and difference measurement-combined chest radiograph anomaly recognition domain self-adaptive method and Wasserstein distance and difference measurement-combined chest radiograph anomaly recognition domain self-adaptive system</span></p>
<p class="p5"><span class="s2">CHEN YUANJIAO ; HE BISHI ; WANG DIAO ; XU ZHE ; CHEN HUI</span></p>
<p class="p5"><span class="s2">2023</span></p>
<p class="p5"><span class="s2">OPEN ACCESS</span></p>
<p class="p8"><span class="s1"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwzR1dT8Iw8FT8fFPEKH6kvuzFTNjGgCVMIx3EF4EYoo-kW7uIwkYYxuiv99qNj5jos4_r5a7renft3e4DwDKvy_oPnWBzP8DTRrAa96uOY9qcVQwmbKfOBRcqW3o1HOp1nhqjyoZ-qFqJKGABiv9Mqe_J0qflqVDLpOQPcSi-bfddT8uMZVNyr6V5TbfV63pdqlHq0o7WeXQNmUCMwm7fbcCmKUuUyJvUU1MmqUxWT5j2Pmz1kFo0O4D1r5c87NJ5I7Y87Dxk_7_zsK0CNoMEBzOhTA7XrhpjNn27eWYqc1J2ryRc3goRSljEybwHCj6Olx7BRklh6SkyrhZNZMGJ6p9FpowP01rWSCEes9EnWUQaxVGGSjhCcLJEjEKdcTaRmpOkLanVxP_qvdKS1QW4bLf69F7H7z9YbPaAdpZbZR1BLoojcQzEN4zADnm9HAZoXwa2YznVWlWEdb9SY9zhJ1D8nU7xL-Ap7EnGkV4WwzqD3Gz6Ls5VRckLxSHfiSDmfA">Wasserstein distance and difference measurement-combined chest radiograph anomaly recognition domain self-adaptive method and Wasserstein distance and difference measurement-combined chest radiograph anomaly recognition...<span class="s61"></span></a></span></p>
<p class="p42"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p75"><span class="s2">2023 23 payent</span></p>
<p class="p75"><span class="s11">一种基于</span><span class="s2">Laplace</span><span class="s11">噪声和</span><span class="s2">Wasserstein</span><span class="s11">正则的多试次</span><span class="s2">EEG</span><span class="s11">源成像方法</span></p>
<p class="p75"><span class="s2">2023</span></p>
<p class="p75"><span class="s2">OPEN ACCESS</span></p>
<p class="p17"><span class="s57"><a href="https://psu.summon.serialssolutions.com/2.0.0/link/0/eLvHCXMwY2AwNtIz0EUrE0xTkpKBtU1qonlKkpmlpZFpSqKJYWKqqaVFSmpKKni3NPJyqCzY1hjwsaHl4LMSgRksGZj9S8DFdwFiTMsFvNSyWD8pEyiUb-8WYuuiBu0sA5vXwH6WmouTrWuAv4u_s5qzs62zn5pfkK0hqKFjZGxu5MjMwGoEOqIE1JIKcwJtUilArmHcBBnYAoCm5ZUIMTBVZQgzcDrDLmITZuDwhc5_CzOwgxdsJhcDBaGZsliEIcImN7Eo2-7Jjobny3ufzt_1ZFefTyJ4rdXTmaueLt7wdFJPeCJ4VyXoZstnaxc_7Zj5fFbL0yWzXqyf-mzNQldX92e7JjzrmPC0uf_ZtJ3PNk-10QebKMqg6OYa4uyhC3RsPDxk4p39EP4yFmNgycvPS5VgUDA1STIzT7FISTK3NDQBthAsUgwNQPeAJaWaA5GZuSSDFG5zpPBJSjNwgUIZNJtuZCzDwFJSVJoqCz5-UQ4cnADcZ6jn">一种基于<span class="s95">Laplace</span><span class="s25">噪声和</span><span class="s95">Wasserstein</span><span class="s25">正则的多试次</span><span class="s95">EEG</span><span class="s25">源成像方法</span></a></span></p>
<p class="p75"><span class="s2"><span class="Apple-converted-space"> </span>[Chinese A Multi-trial EEG Source Imaging Method Based on Laplace Noise and Wasserstein Regularization]</span></p>
<p class="p14"><span class="s2"><br>
</span><span class="s236"><span class="Apple-converted-space"> </span></span></p>
<p class="p191"><span class="s2"><br>
</span></p>
<p class="p192"><span class="s2"><br>
</span></p>
<p class="p193"><span class="s2"><span class="Apple-converted-space">  </span></span></p>
<p class="p191"><span class="s2">2023 24. patent news. NEWSLETTER ARTICLE</span></p>
<p class="p194"><span class="s1"><a href="https://search.library.ucla.edu/discovery/fulldisplay?docid=cdi_proquest_wirefeeds_2789678053&amp;context=PC&amp;vid=01UCS_LAL:UCLA&amp;lang=en&amp;search_scope=ArticlesBooksMore&amp;adaptor=Primo%20Central&amp;tab=Articles_books_more_slot&amp;query=any%2Ccontains%2CWuxi%20Cansonic%20Medical%20Science%20%26%20Tech%20Seeks%20Patent%20for%20FC-VoVNet%20and%2CAND&amp;mode=advanced&amp;offset=0">Wuxi Cansonic Medical Science &amp; Tech Seeks Patent for FC-VoVNet and </a></span><span class="s20">WGAN-Based B Ultrasonic Image Denoising Method</span></p>
<p class="p191"><span class="s2">New Delhi: Pedia Content Solutions Pvt. Ltd</span></p>
<p class="p191"><span class="s2">Global IP News. Optics &amp; Imaging Patent News, 2023</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2023 25. patent news. </span><span class="s237"><b>NEWSLETTER ARTICLE</b></span></p>
<p class="p17"><span class="s238"><a href="https://search.library.ucla.edu/discovery/fulldisplay?docid=cdi_proquest_wirefeeds_2789678053&amp;context=PC&amp;vid=01UCS_LAL:UCLA&amp;lang=en&amp;search_scope=ArticlesBooksMore&amp;adaptor=Primo%20Central&amp;tab=Articles_books_more_slot&amp;query=any%2Ccontains%2CWuxi%20Cansonic%20Medical%20Science%2CAND&amp;mode=advanced&amp;offset=0"><b>Wuxi Cansonic Medical Science &amp; Tech Seeks Patent for FC-VoVNet and WGAN-Based B Ultrasonic Image Denoising Method</b><span class="s1"><b></b></span></a></span></p>
<p class="p14"><span class="s239">New Delhi: Pedia Content Solutions Pvt. LtdGlobal IP News. Optics &amp; Imaging Patent News, 2023</span></p>
<p class="p14"><span class="s239"><i> ... Status: Application Beijing, March 23 -- Wuxi Cansonic Medical Science &amp; Tech has sought patent for FC-VoVNet and WGAN-based B ultrasonic image denoising method...</i></span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p42"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p195"><span class="s2">2023 26. PATENT</span></p>
<p class="p196"><span class="s1"><a href="https://search.library.ucla.edu/discovery/fulldisplay?docid=cdi_epo_espacenet_CN115761399A&amp;context=PC&amp;vid=01UCS_LAL:UCLA&amp;lang=en&amp;search_scope=ArticlesBooksMore&amp;adaptor=Primo%20Central&amp;tab=Articles_books_more_slot&amp;query=any%2Ccontains%2Cdversarial%20sample%20generation%20method%20and%20system%20based%20on%20WGAN-Une%2CAND&amp;mode=advanced&amp;offset=0">Adversarial sample generation method and system based on WGAN-Unet<span class="s240"></span></a></span></p>
<p class="p195"><span class="s2">CHEN YUQING ; SUN LEI ; QIN ZHONGYUAN ; YAO TIAN ; ZHANG QUNFANG</span></p>
<p class="p195"><span class="s2">2023</span></p>
<p class="p195"><span class="s2">OPEN ACCESS</span></p>
<p class="p197"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p195"><span class="s2">2023.27<span class="Apple-converted-space">  </span>PATENT</span></p>
<p class="p195"><span class="s2">Transform-<a href="https://search.library.ucla.edu/discovery/fulldisplay?docid=cdi_epo_espacenet_CN115630683A&amp;context=PC&amp;vid=01UCS_LAL:UCLA&amp;lang=en&amp;search_scope=ArticlesBooksMore&amp;adaptor=Primo%20Central&amp;tab=Articles_books_more_slot&amp;query=any%2Ccontains%2CTransform-WGAN-based%20vehicle%20following%20behavior%20modeling%20method%2CAND&amp;mode=advanced&amp;offset=0"><span class="s241">WGAN-based vehicle following behavior modeling method</span></a></span></p>
<p class="p195"><span class="s2">XU DONGWEI ; GAO GUANGYAN ; LI JIANGPENG ; LI CHENGBIN</span></p>
<p class="p195"><span class="s2">2023</span></p>
<p class="p195"><span class="s2">OPEN ACCESS</span></p>
<p class="p195"><span class="s2"><br>
</span></p>
<p class="p195"><span class="s2">2023 28. PATENT</span></p>
<p class="p196"><span class="s1"><a href="https://search.library.ucla.edu/discovery/fulldisplay?docid=cdi_epo_espacenet_CN115600089A&amp;context=PC&amp;vid=01UCS_LAL:UCLA&amp;lang=en&amp;search_scope=ArticlesBooksMore&amp;adaptor=Primo%20Central&amp;tab=Articles_books_more_slot&amp;query=any%2Ccontains%2CWGAN-GP%20and%20SADNet%20combined%20microseismic%20signal%20denoising%20method%2CAND&amp;mode=advanced&amp;offset=0">WGAN-GP and SADNet combined microseismic signal denoising method<span class="s240"></span></a></span></p>
<p class="p195"><span class="s2">SHENG GUANQUN ; MA KAI ; JING TANG ; WANG XIANGYU ; ZHENG YUELIN ; YU MEI</span></p>
<p class="p195"><span class="s2">2023</span></p>
<p class="p195"><span class="s2">OPEN ACCESS</span></p>
<p class="p195"><span class="s2"><br>
</span></p>
<p class="p195"><span class="s2">2023. 29. PATENT</span></p>
<p class="p196"><span class="s1"><a href="https://search.library.ucla.edu/discovery/fulldisplay?docid=cdi_epo_espacenet_CN115688982A&amp;context=PC&amp;vid=01UCS_LAL:UCLA&amp;lang=en&amp;search_scope=ArticlesBooksMore&amp;adaptor=Primo%20Central&amp;tab=Articles_books_more_slot&amp;query=any%2Ccontains%2CBuilding%20photovoltaic%20data%20completion%20method%20based%20on%2CAND&amp;mode=advanced&amp;offset=0+">Building photovoltaic data completion method based on WGAN and whale </a></span><span class="s20">optimization algorithm</span></p>
<p class="p195"><span class="s2">CUI LEI ; LI FENG ; YANG YANG ; YIN JIE ; CAO QINGWEI ; LI DONG ; GUO XI ; CAO KENAN</span></p>
<p class="p195"><span class="s2">2023</span></p>
<p class="p195"><span class="s2">OPEN ACCESS</span></p>
<p class="p195"><span class="s2"><br>
</span></p>
<p class="p195"><span class="s2">2023.30 <span class="Apple-converted-space">  </span>PATENT</span></p>
<p class="p196"><span class="s1"><a href="https://search.library.ucla.edu/discovery/fulldisplay?docid=cdi_epo_espacenet_CN115630612A&amp;context=PC&amp;vid=01UCS_LAL:UCLA&amp;lang=en&amp;search_scope=ArticlesBooksMore&amp;adaptor=Primo%20Central&amp;tab=Articles_books_more_slot&amp;query=any%2Ccontains%2CSoftware%20measurement%20defect%20data%20augmentation%20method%20based%20on%20V%2CAND&amp;mode=advanced&amp;offset=0">Software measurement defect data augmentation method based on VAE </a></span><span class="s20">and WGAN</span></p>
<p class="p195"><span class="s2">GUO ZHAOYANG</span></p>
<p class="p195"><span class="s2">2023</span></p>
<p class="p195"><span class="s2">OPEN ACCESS</span></p>
<p class="p42"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2023 31 PATENT</span></p>
<p class="p21"><span class="s7"><a href="https://search.library.ucla.edu/discovery/fulldisplay?docid=cdi_epo_espacenet_CN116223038A&amp;context=PC&amp;vid=01UCS_LAL:UCLA&amp;lang=en&amp;search_scope=ArticlesBooksMore&amp;adaptor=Primo%20Central&amp;tab=Articles_books_more_slot&amp;query=any%2Ccontains%2C%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E6%94%B9%E8%BF%9BWGAN%E7%BD%91%E7%BB%9C%E7%9A%84%E8%BD%B4%E6%89%BF%E6%95%85%E9%9A%9C%E8%AF%8A%E6%96%AD%E6%96%B9%E6%B3%95%2CAND&amp;mode=advanced&amp;offset=0">一种基于改进<span class="s176">WGAN网络的轴承故障诊断方法</span></a></span></p>
<p class="p14"><span class="s2">2023</span></p>
<p class="p14"><span class="s2">OPEN ACCESS</span></p>
<p class="p14"><span class="s2">[Chinese. Bearing Fault Diagnosis Method Based on Improved WGAN Network]</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2023 32. PATENT</span></p>
<p class="p21"><span class="s7"><a href="https://search.library.ucla.edu/discovery/fulldisplay?docid=cdi_epo_espacenet_CN111460367BB&amp;context=PC&amp;vid=01UCS_LAL:UCLA&amp;lang=en&amp;search_scope=ArticlesBooksMore&amp;adaptor=Primo%20Central&amp;tab=Articles_books_more_slot&amp;query=any%2Ccontains%2C%E7%A7%8D%E5%9F%BA%E4%BA%8ES%E5%8F%98%E6%8D%A2%2FWGAN%E8%A7%A3%E5%86%B3%E8%BE%93%E5%8D%A4%E7%AE%A1%E9%81%93%E6%B3%84%E6%BC%8F%E6%95%B0%E6%8D%AE%E4%B8%8D%E5%B9%B3%E8%A1%A1%E7%9A%84%E7%AE%97%E6%B3%95%2CAND&amp;mode=advanced&amp;offset=0">一种基于<span class="s176">S变换/WGAN解决输卤管道泄漏数据不平衡的算法</span></a></span></p>
<p class="p14"><span class="s2">2023</span></p>
<p class="p14"><span class="s2">OPEN ACCESS</span></p>
<p class="p14"><span class="s2">[Chinese. An Algorithm Based on S-Transform/WGAN to Solve the Data Imbalance of Brine Pipeline Leakage]</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2">2023. 33. PATENT</span></p>
<p class="p21"><span class="s7"><a href="https://search.library.ucla.edu/discovery/fulldisplay?docid=cdi_epo_espacenet_CN116029088A&amp;context=PC&amp;vid=01UCS_LAL:UCLA&amp;lang=en&amp;search_scope=ArticlesBooksMore&amp;adaptor=Primo%20Central&amp;tab=Articles_books_more_slot&amp;query=any%2Ccontains%2C%E5%9F%BA%E4%BA%8ESVAE-WGAN%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%B1%80%E9%83%A8%E6%94%BE%E7%94%B5%E6%95%85%E9%9A%9C%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95%E5%8F%8A%E8%A3%85%E7%BD%AE%2CAND&amp;mode=advanced&amp;offset=0">基于<span class="s176">SVAE-WGAN模型的局部放电故障数据增强处理方法及装置</span></a></span></p>
<p class="p14"><span class="s2">2023</span></p>
<p class="p14"><span class="s2">OPEN ACCESS</span></p>
<p class="p14"><span class="s2">[Chinese. Partial discharge fault data enhancement processing method and device based on SVAE-WGAN model]</span></p>
<p class="p42"><span class="s2"><span class="Apple-converted-space"> </span><a href="https://patents.google.com/patent/CN115937038A/zh?q=(%E5%9F%BA%E4%BA%8E+WGAN-GP+%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%BD%91%E6%A0%BC%E5%BD%A2%E5%8F%98%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95)&amp;oq=%E5%9F%BA%E4%BA%8EWGAN-GP%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%BD%91%E6%A0%BC%E5%BD%A2%E5%8F%98%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95"><span class="s242"><span class="Apple-converted-space"> </span></span></a></span></p>
<p class="p14"><span class="s2">2023. 34. PATENT</span></p>
<p class="p21"><span class="s2">基于改进</span><span class="s9">WGAN-GP</span><span class="s2">和</span><span class="s9">Alxnet</span><span class="s2">的轴承故障诊断方法</span></p>
<p class="p14"><span class="s2">2023</span></p>
<p class="p14"><span class="s2">OPEN ACCESS</span></p>
<p class="p14"><span class="s2">[Chinese. ]</span></p>
<p class="p198"><span class="s18">CN <a href="https://patentimages.storage.googleapis.com/b3/14/d9/a86de150538f89/CN115962946A.pdf"><span class="s243">CN115962946A </span></a></span><span class="s19">付文龙</span><span class="s18"> </span><span class="s19">三峡大学</span><span class="s20"><br>
</span></p>
<p class="p14"><span class="s2">2023. 35. PATENT</span></p>
<p class="p21"><span class="s7"><a href="https://search.library.ucla.edu/discovery/fulldisplay?docid=cdi_epo_espacenet_CN115937038A&amp;context=PC&amp;vid=01UCS_LAL:UCLA&amp;lang=en&amp;search_scope=ArticlesBooksMore&amp;adaptor=Primo%20Central&amp;tab=Articles_books_more_slot&amp;query=any%2Ccontains%2C%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8EWGAN-GP%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%BD%91%E6%A0%BC%E5%BD%A2%E5%8F%98%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95%2CAND&amp;mode=advanced&amp;offset=0">一种基于<span class="s176">WGAN-GP模型的网格形变数据增强方法</span></a></span></p>
<p class="p14"><span class="s2">2023</span></p>
<p class="p14"><span class="s2">OPEN ACCESS</span></p>
<p class="p14"><span class="s2">[Chinese. Bearing fault diagnosis method based on improved WGAN-GP and Alxnet] </span><span class="s19">置，</span><span class="s18">Δg</span><span class="s19">＝</span><span class="s18">g-g 0 </span><span class="s19">，</span><span class="s18">g 0 </span><span class="s19">为原图</span><span class="s18">-</span><span class="s19">原图的形变网格。</span><span class="s18"> 8.</span><span class="s19">根据权利要求</span><span class="s18">6</span><span class="s19">所述<b>的一种</b></span><span class="s2"><br>
<br>
<br>
</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p199"><span class="s2"><br>
</span></p>
<p class="p200"><span class="s1"><a href="https://mathscinet-ams-org.ezaccess.libraries.psu.edu/mathscinet/2006/mathscinet/search/publdoc.html?arg3=2023&amp;co4=AND&amp;co5=AND&amp;co6=AND&amp;co7=AND&amp;dr=pubyear&amp;pg4=AUCN&amp;pg5=TI&amp;pg6=PC&amp;pg7=ALLF&amp;pg8=ET&amp;review_format=html&amp;s4=&amp;s5=wasserstein&amp;s6=&amp;s7=&amp;s8=All&amp;sort=Newest&amp;vfpref=html&amp;yearRangeFirst=&amp;yearRangeSecond=&amp;yrop=eq&amp;r=5&amp;mx-pid=4599319"><b>2023 36 patent</b><span class="s244"><b></b></span></a></span></p>
<p class="p200"><span class="s1"><a href="https://mathscinet-ams-org.ezaccess.libraries.psu.edu/mathscinet/2006/mathscinet/search/publdoc.html?arg3=2023&amp;co4=AND&amp;co5=AND&amp;co6=AND&amp;co7=AND&amp;dr=pubyear&amp;pg4=AUCN&amp;pg5=TI&amp;pg6=PC&amp;pg7=ALLF&amp;pg8=ET&amp;review_format=html&amp;s4=&amp;s5=wasserstein&amp;s6=&amp;s7=&amp;s8=All&amp;sort=Newest&amp;vfpref=html&amp;yearRangeFirst=&amp;yearRangeSecond=&amp;yrop=eq&amp;r=5&amp;mx-pid=4599319"><b>Method for detecting abnormality of water supply pipe network by using computer device, involves calculating Wasserstein similarity between node monitoring value vector and predicted value vector, and performing pipe network abnormality judgment according to Wamerstein similarity</b><span class="s244"><b></b></span></a></span></p>
<p class="p200"><span class="s1"><a href="https://mathscinet-ams-org.ezaccess.libraries.psu.edu/mathscinet/2006/mathscinet/search/publdoc.html?arg3=2023&amp;co4=AND&amp;co5=AND&amp;co6=AND&amp;co7=AND&amp;dr=pubyear&amp;pg4=AUCN&amp;pg5=TI&amp;pg6=PC&amp;pg7=ALLF&amp;pg8=ET&amp;review_format=html&amp;s4=&amp;s5=wasserstein&amp;s6=&amp;s7=&amp;s8=All&amp;sort=Newest&amp;vfpref=html&amp;yearRangeFirst=&amp;yearRangeSecond=&amp;yrop=eq&amp;r=5&amp;mx-pid=4599319"><b>CN116108604-A</b><span class="s244"><b></b></span></a></span></p>
<p class="p200"><span class="s1"><a href="https://mathscinet-ams-org.ezaccess.libraries.psu.edu/mathscinet/2006/mathscinet/search/publdoc.html?arg3=2023&amp;co4=AND&amp;co5=AND&amp;co6=AND&amp;co7=AND&amp;dr=pubyear&amp;pg4=AUCN&amp;pg5=TI&amp;pg6=PC&amp;pg7=ALLF&amp;pg8=ET&amp;review_format=html&amp;s4=&amp;s5=wasserstein&amp;s6=&amp;s7=&amp;s8=All&amp;sort=Newest&amp;vfpref=html&amp;yearRangeFirst=&amp;yearRangeSecond=&amp;yrop=eq&amp;r=5&amp;mx-pid=4599319"><b>Inventor(s) XIA Z and WANG J</b><span class="s244"><b></b></span></a></span></p>
<p class="p200"><span class="s1"><a href="https://mathscinet-ams-org.ezaccess.libraries.psu.edu/mathscinet/2006/mathscinet/search/publdoc.html?arg3=2023&amp;co4=AND&amp;co5=AND&amp;co6=AND&amp;co7=AND&amp;dr=pubyear&amp;pg4=AUCN&amp;pg5=TI&amp;pg6=PC&amp;pg7=ALLF&amp;pg8=ET&amp;review_format=html&amp;s4=&amp;s5=wasserstein&amp;s6=&amp;s7=&amp;s8=All&amp;sort=Newest&amp;vfpref=html&amp;yearRangeFirst=&amp;yearRangeSecond=&amp;yrop=eq&amp;r=5&amp;mx-pid=4599319"><b>Assignee(s) SICHUAN AOTU ENVIRONMENTAL PROTECTION</b><span class="s244"><b></b></span></a></span></p>
<p class="p200"><span class="s1"><a href="https://mathscinet-ams-org.ezaccess.libraries.psu.edu/mathscinet/2006/mathscinet/search/publdoc.html?arg3=2023&amp;co4=AND&amp;co5=AND&amp;co6=AND&amp;co7=AND&amp;dr=pubyear&amp;pg4=AUCN&amp;pg5=TI&amp;pg6=PC&amp;pg7=ALLF&amp;pg8=ET&amp;review_format=html&amp;s4=&amp;s5=wasserstein&amp;s6=&amp;s7=&amp;s8=All&amp;sort=Newest&amp;vfpref=html&amp;yearRangeFirst=&amp;yearRangeSecond=&amp;yrop=eq&amp;r=5&amp;mx-pid=4599319"><b>Derwent Primary Accession Number </b><span class="s244"><b></b></span></a></span></p>
<p class="p200"><span class="s1"><a href="https://mathscinet-ams-org.ezaccess.libraries.psu.edu/mathscinet/2006/mathscinet/search/publdoc.html?arg3=2023&amp;co4=AND&amp;co5=AND&amp;co6=AND&amp;co7=AND&amp;dr=pubyear&amp;pg4=AUCN&amp;pg5=TI&amp;pg6=PC&amp;pg7=ALLF&amp;pg8=ET&amp;review_format=html&amp;s4=&amp;s5=wasserstein&amp;s6=&amp;s7=&amp;s8=All&amp;sort=Newest&amp;vfpref=html&amp;yearRangeFirst=&amp;yearRangeSecond=&amp;yrop=eq&amp;r=5&amp;mx-pid=4599319"><b>2023-54767T</b></a></span><span class="s245"><br>
</span></p>
<p class="p199"><span class="s18"><b><span class="Apple-converted-space"> </span></b></span><span class="s2"><br>
2023 37</span></p>
<p class="p201"><span class="s246"><a href="javascript:void(0)"><span class="Apple-converted-space"> </span></a><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:202313424N"><span class="s247">Method for modeling a vehicle following behavior based on </span><span class="s248">WGAN</span><span class="s247">, involves making discriminator difficult to judge result of prediction is false, so as to minimize error between prediction result and real result</span></a></span></p>
<p class="p104"><span class="s2">CN115630683-A</span></p>
<p class="p202"><span class="s18"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22LI%20J%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s249">LI J</span></a></span><span class="s120">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22LI%20C%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s249">LI C</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22XU%20D%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s249">XU D</span></a></span></p>
<p class="p5"><span class="s45"><b>Assignee(s) </b></span><span class="s18">UNIV ZHEJIANG TECHNOLOGY</span></p>
<p class="p202"><span class="s18"><b>Derwet Primary Accession Number </b></span></p>
<p class="p104"><span class="s2">2023-13424N</span></p>
<p class="p203"><span class="s2"><br>
</span></p>
<p class="p203"><span class="s2">2023 38</span></p>
<p class="p204"><span class="s23"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:202305050N">Satellite cloud image prediction method based on <span class="s250">WGAN</span><span class="s251">-GP network and optical flow method, involves inputting historical satellite cloud imge data into generator of trained dual-discriminator network to obtain prediction result</span></a></span></p>
<p class="p5"><span class="s18">CN115546257-A</span></p>
<p class="p204"><span class="s252"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22XIA%20J%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s253">XIA J</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22KANG%20R%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s253">KANG R</span></a> and <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22TAN%20L%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s253">TAN L</span></a></span></p>
<p class="p5"><span class="s252"><b>Assignee(s) </b></span><span class="s18">UNIV NANJING INFORMATION SCI &amp; TECHNOLOG</span></p>
<p class="p205"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2023-05050N</span></p>
<p class="p205"><span class="s2"><br>
</span></p>
<p class="p205"><span class="s18">2023 39</span></p>
<p class="p204"><span class="s23"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:202326661P">Anti-sample generating system based on <span class="s250">WGAN</span><span class="s251">-Unet for intelligent traffic, has generator for constructing Unet architecture according to original sample data, performing feature extraction on input sample, pool and up-sampling, and outputting confrontation disturbance corresponding to original sample</span></a></span></p>
<p class="p5"><span class="s18">CN115761399-A</span></p>
<p class="p204"><span class="s252"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22CHEN%20Y%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s253">CHEN Y</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22SUN%20L%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s253">SUN L</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22QIN%20Z%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s253">QIN Z</span></a></span></p>
<p class="p5"><span class="s252"><b>Assignee(s) </b></span><span class="s18">UNIV SOUTHEAST</span></p>
<p class="p205"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2023-26661P</span></p>
<p class="p205"><span class="s2"><br>
</span></p>
<p class="p205"><span class="s18">2023 40</span></p>
<p class="p204"><span class="s23"><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/full-record/DIIDW:2023195556">Building photovoltaic data completion method based on <span class="s250">WGAN</span><span class="s251"> and whale optimization algorithm for a residential building, a commercial building, an office building, and an industrial building, involves obtaining historical photovoltaic output data on building roofs and preprocessing the data</span></a></span></p>
<p class="p5"><span class="s18">CN115688982-A</span></p>
<p class="p204"><span class="s252"><b>Inventor(s) </b><a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22YANG%20Y%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s253">YANG Y</span></a></span><span class="s124">; <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22CAO%20K%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s253">CAO K</span></a>; (...); <a href="https://www-webofscience-com.ezaccess.libraries.psu.edu/wos/alldb/general-summary?queryJson=%5B%7B%22rowField%22:%22AU%22,%22rowText%22:%22CUI%20L%22%7D%5D&amp;eventMode=oneClickSearch"><span class="s253">CUI L</span></a></span></p>
<p class="p5"><span class="s252"><b>Assignee(s) </b></span><span class="s18">HUANENG JIANGSU INTEGRATED ENERGY SERVIC</span></p>
<p class="p205"><span class="s18"><b>Derwent Primary Accession Number </b></span></p>
<p class="p5"><span class="s18">2023-195556</span></p>
<p class="p58"><span class="s2"><br>
</span></p>
<p class="p206"><span class="s2">2023 41 patent</span></p>
<p class="p207"><span class="s17"><a href="https://patents.google.com/patent/CN116223038A/en?q=(wgan)&amp;before=priority:20231231&amp;after=priority:20230101&amp;oq=wgan+2023">Bearing fault diagnosis method based on improved <span class="s254"><b>WGAN</b> network</span></a></span></p>
<p class="p208"><span class="s18">CN CN116223038A </span><span class="s19">张辉</span><span class="s18"> </span><span class="s19">江苏科技大学</span></p>
<p class="p209"><span class="s18">Priority 2023-01-09 • Filed 2023-01-09 • Published 2023-06-06</span></p>
<p class="p210"><span class="s18">5. The method for diagnosing bearing failure based on the improved <b>WGAN</b> network as claimed in claim 4, wherein: the R-FCN network model is built in the step (3.2) as a discriminator model for improving the <b>WGAN</b> network, the discriminator model is utilized to judge the picture generated by the …</span></p>
<p class="p210"><span class="s2"><br>
</span></p>
<p class="p210"><span class="s2">2023 42 patent</span></p>
<p class="p207"><span class="s17"><a href="https://patents.google.com/patent/CN115962946A/en?q=(wgan)&amp;before=priority:20231231&amp;after=priority:20230101&amp;oq=wgan+2023">Bearing fault diagnosis method based on improved <span class="s254"><b>WGAN</b>-GP and Alxnet</span></a></span></p>
<p class="p211"><span class="s255">CN <a href="https://patentimages.storage.googleapis.com/b3/14/d9/a86de150538f89/CN115962946A.pdf"><span class="s256">CN115962946A </span></a></span><span class="s257">付文龙</span><span class="s255"> </span><span class="s257">三峡大学</span></p>
<p class="p209"><span class="s18">Priority 2023-01-18 • Filed 2023-01-18 • Published 2023-04-14</span></p>
<p class="p210"><span class="s18">8. The bearing fault diagnosis method based on improved <b>WGAN</b>-GP and Alxnet according to claim 1, characterized in that: the step 5 comprises the following steps: s5.1: taking the expanded balanced data set as input, and extracting deep features through the convolutional layer, the Relu activation …</span></p>
<p class="p210"><span class="s2"><br>
</span></p>
<p class="p210"><span class="s2">2023 43</span></p>
<p class="p207"><span class="s17"><a href="https://patents.google.com/?q=(wgan)&amp;before=priority:20231231&amp;after=priority:20230101&amp;oq=wgan+2023#">Electronic device for colorizing black and white image using gan based model …<span class="s258"></span></a></span></p>
<p class="p208"><span class="s18"><i>KR</i> <a href="https://patentimages.storage.googleapis.com/01/51/c0/c0ec1c8d133bab/KR20230025676A.pdf"><span class="s259">KR20230025676A </span></a></span><span class="s78">이범식</span><span class="s18"> </span><span class="s78">조선대학교산학협력단</span></p>
<p class="p209"><span class="s18">Priority 2023-02-03 • Filed 2023-02-03 • Published 2023-02-22</span></p>
<p class="p210"><span class="s18">According to claim 4, The GAN-based model is trained using a total loss (L total ) considering all pixel wise (L1) loss function (L L1 ), VGG loss function (L VGG ), and <b>WGAN</b> loss function (L <b>wgan</b> ), The pixel wise (L1) loss function (L L1 ), the VGG loss function (L VGG ), the <b>WGAN</b> loss function ( …</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p212"><span class="s2"><br>
2023 44 patent see 2022</span></p>
<p class="p120"><span class="s17"><a href="https://patents.google.com/patent/CN115962946A/en?q=TI%3d(wgan)&amp;oq=TI%3d(wgan)&amp;sort=new">Bearing fault diagnosis method based on improved <span class="s254"><b>WGAN</b>-GP and Alxnet</span></a></span></p>
<p class="p170"><span class="s255">CN <a href="https://patentimages.storage.googleapis.com/b3/14/d9/a86de150538f89/CN115962946A.pdf"><span class="s188">CN115962946A </span></a></span><span class="s257">付文龙</span><span class="s255"> </span><span class="s257">三峡大学</span></p>
<p class="p209"><span class="s18">Priority 2023-01-18 • Filed 2023-01-18 • Published 2023-04-14</span></p>
<p class="p210"><span class="s18">8. The bearing fault diagnosis method based on improved <b>WGAN</b>-GP and Alxnet according to claim 1, characterized in that: the step 5 comprises the following steps: s5.1: taking the expanded balanced data set as input, an</span></p>
<p class="p213"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p176"><span class="s2">2023 45. patent<span class="Apple-tab-span">	</span><span class="Apple-tab-span">	</span><span class="Apple-tab-span">	</span><span class="Apple-tab-span">	</span><span class="Apple-tab-span">	</span><span class="Apple-tab-span">	</span><span class="Apple-tab-span">	</span><span class="Apple-tab-span">	</span><span class="Apple-tab-span">	</span>55</span></p>
<p class="p177"><span class="s193"><a href="https://patents.google.com/patent/CN116152372A/en?q=TI%3d(wasserstein)&amp;num=25&amp;oq=TI%3d(wasserstein)&amp;sort=new">Laplace noise and <span class="s194"><b>Wasserstein</b> regularization-based multi-test EEG source …</span></a></span></p>
<p class="p178"><span class="s195">CN <a href="https://patentimages.storage.googleapis.com/3d/b8/0b/1957591e69f5a6/CN116152372A.pdf"><span class="s196">CN116152372A </span></a></span><span class="s197">刘柯</span><span class="s195"> </span><span class="s197">重庆邮电大学</span></p>
<p class="p179"><span class="s18">Priority 2023-02-07 • Filed 2023-02-07 • Published 2023-05-23</span></p>
<p class="p176"><span class="s18">s4, establishing a multi-test robust EEG diffuse source imaging model based on Laplace noise and <b>Wasserstein</b> regularization in a projection space according to the lead matrix, the difference operator and the minimum distance matrix, and obtaining a multi-test estimated source by utilizing an ADMM …</span></p>
<p class="p212"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">&lt;—381 titles <span class="Apple-converted-space">  </span>before 2023</span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space">     </span>+ 45<span class="Apple-converted-space">  </span>patents in 2023</span></p>
<p class="p5"><span class="s2"><span class="Apple-converted-space">    </span>= 426<span class="Apple-converted-space">  </span>patents<span class="Apple-converted-space">  </span>till 2013</span></p>
<p class="p5"><span class="s2">end 2023. E23<br>
</span></p>
<p class="p68"><span class="s2">426<span class="Apple-converted-space">  </span>patents <span class="Apple-converted-space"> </span></span><span class="s12"> till 2023</span></p>
<p class="p68"><span class="s2">+ 30 unsorted titles below</span></p>
<p class="p68"><span class="s2"><span class="Apple-converted-space"> </span>=<span class="Apple-converted-space">  </span>456 total<span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s2"><span class="Apple-converted-space">    </span></span><span class="s12"><br>
</span></p>
<p class="p5"><span class="s2">————————————— 30 titles not sorted by year—&gt;</span></p>
<p class="p10"><span class="s12"><br>
</span><span class="s2">start unsorted by year titles</span></p>
<p class="p214"><span class="s2">——31 patent titles from Web of Science —&gt;</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s98">1</span><span class="s2"><b>.</b></span></p>
<p class="p77"><span class="s56"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=1&amp;SID=7D5Fv3zP6jUfjcaXwDy&amp;page=1&amp;doc=18"><b>Wavelet transformation local characteristic scale decomposition </b><span class="s137"><b>Wasserstein</b></span><span class="s136"><b> distance based pipeline leakage signal de-noising method, involves reconstructing effective component, and expressing leakage signal after removing noise component</b></span></a></span></p>
<p class="p14"><span class="s2"><b>Patent Number: CN112539887-A</b></span></p>
<p class="p14"><span class="s2"><b>Patent Assignee: UNIV NORTHEAST PETROLEUM</b></span></p>
<p class="p14"><span class="s2"><b>Inventor(s): DONG H; ZHOU Y; LU J; et al.</b></span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">2.</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=2">Anti-domain adaptive model training method comprises e.g. configuring source domain embedding extractor and target domain embedding extractor share some layer parameters to speaker discriminator to obtain speaker loss and Wasserstein loss<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN111797844-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: SUZHOU AISPEECH INFORMATION TECHNOLOGY C<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): QIAN Y; CHEN Z; WANG S.<br>
</span></p>
<p class="p5"><span class="s2">3</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=3">Generative adversarial network based single-stage target detection method, involves calculating target detection loss value of loss function constructed based on Wasserstein distance based on predicted target image and sample label<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN111767962-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: CHINESE ACAD SCI AUTOMATION INST<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): TANG S; ZHENG Q; ZHU H; et al.<br>
</span></p>
<p class="p5"><span class="s2">4</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=4">Method for training condition generating type countermeasure network of an electronic device, involves providing condition generating type countermeasure network with generator, discriminator and Wasserstein generative adversarial network<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN111582348-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV WUHAN POLYTECHNIC<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): LI Y; XU X; YUAN C.</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">5.</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=5">Auto encoder Wasserstein generative adversarial network based voice noise reduction method, involves obtaining and converting one-dimensional speech signals into one-dimensional discrete speech signals in test phase<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN111564160-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV CHONGQING POSTS &amp; TELECOM<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): HU Z; XU X; LUO Y; et al.</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p44"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">6.</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=6">World harmonized light-duty vehicles test procedure face recognition algorithm, comprises preprocessing human face image e.g. white balance and pixel compression and calculating Wasserstein distance<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN111488763-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV TIANJIN QINGDAO OCEAN TECHNOLOGY<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): XU J; SHI X; WANG R; et al.<br>
</span></p>
<p class="p5"><span class="s2">7</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=7">Wasserstein distance based rapid image enhancing method, involves inputting constructed data set into deep learning model, and inputting to-be-processed motion blur image into deep learning model to obtain clear and full-color image<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN111476721-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV CHONGQING POSTS &amp; TELECOM<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): FENG J; QI S; WU S.</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p44"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">8.</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=8">Algorithm based on S-transform/Wasserstein GAN to solve unbalanced data leakage of brine pipeline, comprises e.g. transforming fault data to time-frequency-modular three-dimensional leak point picture through S transformation<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN111460367-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: HUAIYIN TECHNOLOGY INST<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): XU M; DING W; ZHAO J; et al.</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p44"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">9.</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=9">Method for performing adaptive image classification in depth domain based on Wasserstein distance, involves removing domain adaptation layer, and inputting target domain samples into model for classification to get accuracy<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN111428803-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV SHANDONG<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): WU Q; SUN S; LIU J; et al.</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p44"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">10.</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=10">Aluminum electrolysis fire eye image repair method for Wasserstein deep convolution generating an anti-network, involves extracting the center of the fire eye as the center, where distance is used to define the loss of the generator<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN111192221-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV CENT SOUTH<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): CHEN X; PAN M; XIE Y; et al.</span></p>
<p class="p44"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">11.</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=11">Method for deep self-coding embedded clustering based on Sliced-Wasserstein distance, involves processing self-encoding embedded clustering network when clustering network reaches preset threshold, and completing final clustering<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN111178427-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV HANGZHOU DIANZI<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): GUO C; RONG P; CHEN H; et al.</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p44"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">12.</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=12">Face gender discrimination algorithm based on Wasserstein distance involves building comparison libraries, calculating distance between target distribution and different distributions and selecting type closest to comparison library<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN111046708-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV TIANJIN QINGDAO OCEAN TECHNOLOGY<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): XU J; SHI X; WANG R; et al.</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p44"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">13.</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=13">Wasserstein distance and auto-encoder based semi-supervised deep learning fault diagnosis method, involves acquiring industrial continuous process data of fault category, inputting standardized data set to-be-tested into WASS-AE model<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN111026058-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV ZHEJIANG<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): GE Z; ZHANG H; SONG Z.</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p44"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">14.</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=14">BIRCH clustering and Wasserstein distance based wind power output typical scene generation method, involves obtaining non-leaf node branch parameter, leaf node branch parameter and wind electric scene maximum cluster radius threshold<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN110929399-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: STATE GRID JIANGSU ELECTRIC POWER CO LTD<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): TANG X; LI Q; WANG S; et al.</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p44"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">15.</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=15">Fault diagnosis method for deep combat migration network based on Wasserstein distance, involves obtaining data set of source domain, an establishment is made that feature-based transfer learning fault diagnosis model has feature extractor<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN110907176-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV HEFEI TECHNOLOGY<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): XU J; HUANG J; ZHOU L; et al.</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">16.</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=16">Training method for guaranteeing stable convergence of maximum and minimum loss function of generative confrontation network model (GAN) model, involves calculating countermeasure loss function Wasserstein format<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN110826688-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: JIANGSU AIJIA HOUSEHOLD PROD CO LTD<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): CHEN X; LV C; LIN S.</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">17.</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=17">Clean energy source power supply planning method involves constructing output uncertainty set, which is based on wind of the Wasserstein, and a power plan model is established under distributed robust optimization distance<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN110797919-A CN110797919-B<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: STATE GRID SICHUAN ELECTRIC POWER CO ECO; STATE GRID HENAN ELECTRIC POWER CO ECONO<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): WANG R; LIU Y; ZHU M; et al.</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">18.</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=18">Deep learning and Wasserstein distance metric based finger vein identification method, involves performing encoding operation on images, and utilizing similarity of Wasserstein distance metric as result of search identification<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN110555382-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV ZHEJIANG SCI-TECH<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): ZHANG N; TU X; BAO X; et al.</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p44"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">19.</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=19">Wasserstein distance based convolution neural network anti-transfer learning method, involves completing countermeasure migration learning of convolution neural network according to convergence criterion<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN110414383-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV HUAZHONG SCI &amp; TECHNOLOGY<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): YUAN Y; ZHOU B; CHENG C; et al.</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">20.</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=20">Generated confrontation network based mushroom phenotype image generation method, involves obtaining Wasserstein distance similarity measurement index for establishing high-quality mushroom surface type image generating model<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN110197514-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV NANJING AGRIC<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): YUAN P; WU M; XU H; et al.</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p44"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">21.</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=21">Method for realizing data association in pedestrian tracking process based on Wasserstein metric, involves calculating Wasserstein distance of neural network, and performing data association operation in pedestrian tracking process<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN110110670-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV HANGZHOU DIANZI<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): GUO C; LIU Y; YING N; et al.</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p44"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">22.</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=22">Wasserstein anti-network based three- dimensional MRI image de-noising model establishing method, involves optimizing Wasserstein anti-network model, obtaining loss LRED-WGAN convergence value, and constructing optimized de-noising model<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN110097512-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV SICHUAN<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): ZHANG Y; RAN M; ZHOU J.</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">23.</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=23">Wasserstein GAN based photovoltaic array fault diagnosing method, involves diagnosing working condition time sequence voltage current and time data of photovoltaic array to judge whether array system is in failure state and fault type<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN109660206-A CN109660206-B<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV FUZHOU<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): LIN P; CHENG S; LU X; et al.</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">24.</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=24">Wasserstein histogram euclidean metric based image overlapping area blind detecting method, involves searching image block around initial block, locating image repeating area, and obtaining repeating area detecting result of image<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN109360199-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV NANJING TECHNOLOGY<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): DU Z; YE C; LI X; et al.</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">25.</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=25">Method for generating 3D pulmonary nodules, involves outputting 3D nodule, and obtaining 3D nodule generation model by training true nodule data against network DCGAN by depth convolution generation based on Wasserstein distance<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN109146868-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: BEIJING QINGYAN XIANGYUN TECHNOLOGY CO<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): WU J; ZHANG Q; HU F.</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">26.</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=26">Differential Wasserstein generative adversarial network based network safety state predicting method, involves performing core principle description and algorithm description processes to perform network safety state prediction process<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN109120652-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV CHONGQING POSTS &amp; TELECOM<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): WANG Y; WANG T; ZHU J.</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p44"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">27.</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=27">Fusion Faster-RCNN Wasserstein encoder based image retrieval method, involves constructing local characteristic image database, and encrypting local feature map from encoder to finish fine granularity search operation of image<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN109086437-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV CHONGQING; UNIV GUILIN ELECTRONIC TECHNOLOGY<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): FENG Y; ZHANG Y; SHANG J; et al.</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p10"><span class="s15">28—&gt;2018 1<br>
<a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=1&amp;SID=7D5Fv3zP6jUfjcaXwDy&amp;page=1&amp;doc=10"><span class="s13"><b>Method for generating digital handwriting based on double arbiter weight generating countermeasure network, involves performing theoretical analysis to dual discriminator </b></span><span class="s260"><b>Wasserstein</b></span><span class="s16"><b> generative adversarial network model</b></span></a>33.</span></p>
<p class="p14"><span class="s2"><b>Patent Number: CN112598125-A</b></span></p>
<p class="p14"><span class="s2"><b>Patent Assignee: UNIV XIAN SCI &amp; TECHNOLOGY; SHAANXI ZHONGYI TIMES TECHNOLOGY CO LTD</b></span></p>
<p class="p14"><span class="s2"><b>Inventor(s): LIU B; GAO N; HUANG M; et al.</b></span></p>
<p class="p215"><span class="s2">Handwritten number generation method for generating countermeasure network based on double-discriminator weighting</span><span class="s261"><br>
</span></p>
<p class="p9"><span class="s4">29. <a href="https://patents.google.com/patent/US20150293884A1/en?q=Method+for+computing+Wasserstein+barycenters+of+set+of+histograms+under+approximate+dual+primal+optimal+variables%2c&amp;oq=Method+for+computing+Wasserstein+barycenters+of+set+of+histograms+under+approximate+dual+and+primal+optimal+variables%2c+"><span class="s5">2014-2016</span></a></span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=31">Method for computing Wasserstein barycenters of set of histograms under approximate dual and primal optimal variables, involves using numerical approximation of optimal transport distance incorporates entropic smoothing term of weight<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: US2015293884-A1 JP2015203946-A<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV KYOTO<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): CUTURI CAMETO M; CUTURI M.</span></p>
<p class="p5"><span class="s2"><br>
</span></p>
<p class="p5"><span class="s2">30. 2012-2014</span></p>
<p class="p6"><span class="s1"><a href="http://apps.webofknowledge.com.ezaccess.libraries.psu.edu/full_record.do?product=UA&amp;search_mode=GeneralSearch&amp;qid=9&amp;SID=7FTQOzTAHE5AfvOZzOy&amp;page=1&amp;doc=32">Method for enhancing and segmenting computed tomography angiography image of liver blood vessel, involves obtaining anisotropic characteristics of neighborhood image point based on liver and blood vessel Wasserstein distance<span class="Apple-converted-space"> </span><span class="s3"></span></a></span></p>
<p class="p5"><span class="s2">Patent Number: CN102609913-A CN102609913-B<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Patent Assignee: UNIV ZHEJIANG<span class="Apple-converted-space"> </span></span></p>
<p class="p5"><span class="s2">Inventor(s): KONG D; PENG J; WANG J; et al.</span></p>
<p class="p216"><span class="s17"><a href="https://patents.google.com/patent/CN102609913B/en">https://patents.google.com<span class="s262"> › patent › CN102609913B</span></a></span></p>
<p class="p217"><span class="s17"><a href="https://patents.google.com/patent/CN102609913B/en">CN102609913B - Method for enhancing liver blood vessel and ...<span class="s263"></span></a></span></p>
<p class="p218"><span class="s18">Priority to CN201210014249.9A. 2012-07-25. Publication of CN102609913A. 2014-07-09. Application granted. 2014-07-09. Publication of <b>CN102609913B</b> ...</span></p>
<p class="p5"><span class="s264"><br>
</span><span class="s2"><br>
</span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p42"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s2"><br>
<br>
<span class="Apple-converted-space"> </span></span></p>
<p class="p219"><span class="s2">—————</span></p>
<p class="p220"><span class="s2">Search links</span></p>
<p class="p219"><span class="s2"><br>
</span></p>
<p class="p219"><span class="s2">Web of Science</span></p>
<p class="p219"><span class="s2">Google books<span class="Apple-converted-space"> </span></span></p>
<p class="p219"><span class="s7"><a href="https://patents.google.com/">Google patent</a></span><span class="s1">s<span class="Apple-converted-space">     </span></span><span class="s2"> <a href="https://patents.google.com/?q=wasserstein+&amp;after=priority:20220101"><span class="s265">advanced search</span></a></span></p>
<p class="p221"><span class="s1"><a href="https://patents.google.com/?q=wasserstein&amp;page=3">Google patent<span class="s66"></span></a></span></p>
<p class="p219"><span class="s2">PSU ;library</span></p>
<p class="p214"><span class="s9"><span class="Apple-converted-space"> </span><a href="https://www.proquest.com/advanced?accountid=13158"><span class="s266">ProQuest</span></a></span><span class="s2"> Advanced Search<span class="Apple-converted-space"> </span></span></p>
<p class="p219"><span class="s2">————————————————</span></p>
<p class="p74"><span class="s9"><span class="Apple-converted-space"> </span></span><span class="s203"><span class="Apple-tab-span">	</span><span class="Apple-tab-span">	</span></span><span class="s18">8 results sorted by </span><span class="s267">relevance</span><span class="s268"><br>
</span><span class="s2"><br>
<br>
</span><span class="s18"><span class="Apple-converted-space"> </span></span></p>
<p class="p222"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p74"><span class="s2"><br>
aaa bbb</span></p>
<p class="p74"><span class="s2"><br>
</span></p>
<p class="p14"><span class="s269"><span class="Apple-converted-space"> </span></span><span class="s2"><br>
</span></p>
<p class="p223"><span class="s17"><a href="https://patents.google.com/patent/CN111046708A/en?q=wasserstein&amp;page=1"><span class="Apple-converted-space"> </span><span class="s270"></span></a></span></p>
<p class="p223"><span class="s17"><a href="https://patents.google.com/patent/CN113276119B/en?q=wasserstein&amp;page=1"><span class="Apple-converted-space"> </span><span class="s270"></span></a></span></p>
<p class="p42"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p223"><span class="s17"><a href="https://patents.google.com/patent/US9275645B2/en?q=wasserstein&amp;page=1"><span class="Apple-converted-space"> </span><span class="s270"></span></a></span></p>
<p class="p42"><span class="s2"><span class="Apple-converted-space"> </span></span></p>
<p class="p14"><span class="s2"><br>
</span></p>
<p class="p223"><span class="s17"><a href="https://patents.google.com/patent/US20200342361A1/en?q=wasserstein"><b><span class="Apple-converted-space"> </span></b></a></span><span class="s15"><span class="Apple-converted-space"> </span></span></p>
</body>
</html>
